{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOiLtMLnUgZpifwd8BSA/x8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Datarian723/AutoHPO/blob/main/AutoHPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO"
      ],
      "metadata": {
        "id": "jsclqRyJhDXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "(1)FIGURE_OUT: WHY ON EARTH Wrapper's retrieval of 'dls_func' is returning [get_sig] INSTEAD of get_sig.\n",
        "   MODIFY: UNTIL Wrapper Testing passes.\n",
        "(2)MODIFY: HpoTrainer, Auto.\n",
        "   TEST: The entire Auto-HPO process.\n",
        "(3)START: The new Kaggle competition(check your recent Gmail notification about it)\n",
        "   TEST: The entire Auto-HPO process ON: 3D Image reconstruction Challenge\n",
        "   TEST: The entire Auto-HPO process ON: 3D Image reconstruction Challenge + CapsuleNetwork\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rWuRvNI7hGC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "bcb976bc-227b-4974-afe5-1e348707263a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n(1)FIGURE_OUT: WHY ON EARTH Wrapper's retrieval of 'dls_func' is returning [get_sig] INSTEAD of get_sig.\\n   MODIFY: UNTIL Wrapper Testing passes.\\n(2)MODIFY: HpoTrainer, Auto.\\n   TEST: The entire Auto-HPO process.\\n(3)START: The new Kaggle competition(check your recent Gmail notification about it)\\n   TEST: The entire Auto-HPO process ON: 3D Image reconstruction Challenge\\n   TEST: The entire Auto-HPO process ON: 3D Image reconstruction Challenge + CapsuleNetwork\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prep"
      ],
      "metadata": {
        "id": "LiJWSPy8mFr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Special Imports\n",
        "# ---------------------------\n",
        "from __future__ import annotations  # Enable forward references for type hints\n",
        "\n",
        "# ---------------------------\n",
        "# Standard Libraries\n",
        "# ---------------------------\n",
        "import os  # Operating system utilities\n",
        "import gc  # Garbage collection for memory management\n",
        "import logging  # Logging utilities\n",
        "import sys  # System-specific parameters and functions\n",
        "import unittest  # For unit-testing Python code\n",
        "import copy  # For deep and shallow copying of objects\n",
        "import math  # Math operations\n",
        "import random  # Random number generation\n",
        "import gzip  # For compressing and decompressing data\n",
        "from functools import partial  # Partial function application\n",
        "from collections import defaultdict  # Dictionary subclass with default values\n",
        "from sortedcontainers import SortedSet  # Sorted set implementation\n",
        "from unittest.mock import Mock, patch  # For mocking and patching in unit tests\n",
        "from inspect import signature  # Inspecting callable signatures\n",
        "from typing import Callable, Union  # Type annotations for type hints\n",
        "from ast import Is  # Abstract syntax tree utilities\n",
        "from abc import ABC, abstractmethod  # Abstract Base Classes for inheritance\n",
        "\n",
        "# ---------------------------\n",
        "# Scientific Libraries\n",
        "# ---------------------------\n",
        "import numpy as np  # Array and matrix operations\n",
        "import pandas as pd  # Data manipulation and analysis\n",
        "import matplotlib.pyplot as plt  # Plotting and visualization\n",
        "\n",
        "# ---------------------------\n",
        "# PyTorch and Related Modules\n",
        "# ---------------------------\n",
        "import torch  # Core PyTorch library for tensor operations\n",
        "import torch.nn as nn  # Neural network modules\n",
        "import torch.nn.functional as F  # Functional API for neural networks\n",
        "import torchvision.models as models  # Pre-trained models from torchvision\n",
        "from torch.multiprocessing import Pool, set_start_method  # Multiprocessing utilities for PyTorch\n",
        "\n",
        "# ---------------------------\n",
        "# FastAI Libraries\n",
        "# ---------------------------\n",
        "from fastai.vision.all import *  # All-in-one import for vision-specific modules\n",
        "from fastai.metrics import *  # Evaluation metrics for model performance\n",
        "from fastai.callback.hook import *  # Hooks for capturing intermediate model states\n",
        "from fastai.callback.tracker import *  # Training callback trackers (e.g., early stopping)\n",
        "from fastai.learner import Learner  # Core Learner object for model training\n",
        "\n",
        "# ---------------------------\n",
        "# Optuna for Hyperparameter Optimization\n",
        "# ---------------------------\n",
        "import optuna  # Core Optuna library for optimization\n",
        "from optuna.integration import FastAIPruningCallback  # Pruning callback for FastAI integration\n",
        "from optuna.trial import Trial, FrozenTrial  # Trial classes for defining and managing trials\n",
        "\n",
        "# ---------------------------\n",
        "# Google Colab Utilities\n",
        "# ---------------------------\n",
        "from google.colab import files  # File utilities for Colab\n",
        "from google.colab import drive  # Mounting Google Drive in Colab"
      ],
      "metadata": {
        "id": "JCc3ckuVaO6v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: Var"
      ],
      "metadata": {
        "id": "VwK_hENk-VzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Var:\n",
        "    def __init__(self, var_type: str, source: dict):\n",
        "        #Extract distribution, sample_method for error checking.\n",
        "        sample_method = source['sample']\n",
        "        distribution = source['params']['choices'] if sample_method=='categorical' else source['params']\n",
        "        #ERROR CHECK:\n",
        "        self._error_check(distribution, sample_method)\n",
        "\n",
        "        #Member initializations:\n",
        "        self.var_type = var_type\n",
        "        self.sample_method = sample_method\n",
        "        #frozen_dist is used for value conversion, in case value NOT currently in 'self.get_dist()' is requested for conversion.\n",
        "        self._frozen_dist = distribution.copy()\n",
        "        self._dist = list(range(len(self._frozen_dist))) if sample_method=='categorical' else distribution.copy()\n",
        "        #fixed <- IF (categorical distribution has one element) OR (low==high)\n",
        "        self.fixed = (self.sample_method=='categorical' and len(self._dist)==1) or (self.sample_method!='categorical' and self._dist['low']==self._dist['high'])\n",
        "\n",
        "    def _error_check(self, distribution, sample_method: str):\n",
        "        if not isinstance(distribution, (list,dict)):\n",
        "            raise ValueError(f\"Input 'distribution' MUST be of type in (list,dict) but found: {type(distribution)}\")\n",
        "        if sample_method not in ['categorical', 'float', 'int']:\n",
        "            raise ValueError(f\"sample method MUST be one of ['categorical', 'float', 'int'] but found: {sample_method}\")\n",
        "        if sample_method!='categorical' and not isinstance(distribution, dict) or sample_method=='categorical' and not isinstance(distribution, list):\n",
        "            raise ValueError(f\"sample_method: {sample_method} is not compatible with distribution: {distribution}. Categorical sampling requires a list, rest requires a dictionary\")\n",
        "        cat_valid_params = sample_method!='categorical' or len(distribution)\n",
        "        non_cat_valid_params = sample_method=='categorical' or (distribution.get('low', 0) <= distribution.get('high', -1))\n",
        "        if not cat_valid_params or not non_cat_valid_params:\n",
        "            msg = f\"Categorical distribution needs at least one value in it: {distribution}\" if sample_method=='categorical' else f\"distribution needs (low,high) as keys and distribution[low]<=distribution[high] but found: {distribution}\"\n",
        "            raise ValueError(msg)\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self.var_type, self.sample_method))\n",
        "\n",
        "    def __eq__(self, other: Var):\n",
        "        \"\"\"Two Var objects are considered 'equal'\n",
        "           IFF (1)other is Var object\n",
        "               (2)self.var_type == other.var_type\n",
        "               (3)self.params == other.params\n",
        "        \"\"\"\n",
        "        return all([\n",
        "            isinstance(other, Var),\n",
        "            self.var_type == other.var_type,\n",
        "            self.sample_method == other.sample_method,\n",
        "            self._frozen_dist == other._frozen_dist,\n",
        "            self._dist == other._dist\n",
        "        ])\n",
        "\n",
        "    def __str__(self):\n",
        "        if self.sample_method == 'categorical':\n",
        "            config_space = f\"'choices' = {[self._frozen_dist[idx] for idx in self._dist]}\"\n",
        "        else:\n",
        "            config_space = (\n",
        "                f\"'low': {self._dist['low']}, \"\n",
        "                f\"'high': {self._dist['high']}, \"\n",
        "                f\"'log': {self._dist.get('log', False)}, \"\n",
        "                f\"'step': {self._dist.get('step', 'unspecified')}\"\n",
        "            )\n",
        "        output = f\"Var of type: {self.var_type}\\nConfiguration Space:\\n{config_space}\\n\"\n",
        "        return output\n",
        "\n",
        "    def contain_idx(self, idx, current: bool = False):\n",
        "        if self.sample_method!='categorical' and type(idx)!=eval(self.sample_method) or self.sample_method=='categorical' and type(idx)!=int:\n",
        "            return False\n",
        "        if self.sample_method!='categorical':\n",
        "            dist = self._dist if current else self._frozen_dist\n",
        "            return dist['low'] <= idx <= dist['high']\n",
        "        return idx in self._dist if current else 0 <= idx < len(self._frozen_dist)\n",
        "\n",
        "    def contain_val(self, val, current: bool = False):\n",
        "        if self.sample_method != 'categorical':\n",
        "            return self.contain_idx(idx=val, current=current)\n",
        "        if self.var_type=='action_func' and isinstance(val, Action):\n",
        "            val = val.action_func\n",
        "        return val in self.distribution() if current else val in self._frozen_dist\n",
        "\n",
        "    def convert_idx_to_val(self, idx):\n",
        "        if not self.contain_idx(idx=idx, current=False):\n",
        "            raise ValueError(f\"Input index 'idx' is NOT a proper index for conversion via Var:{self.var_type}'s distribution: {list(range(len(self._frozen_dist))) if self.sample_method=='categorical' else self._frozen_dist}\")\n",
        "        if self.sample_method!='categorical':\n",
        "            return idx\n",
        "        return self._frozen_dist[idx]\n",
        "\n",
        "    def convert_val_to_idx(self, val):\n",
        "        if not self.contain_val(val=val, current=False):\n",
        "            raise ValueError(f\"Input value 'val': {val} is NOT a proper value for conversion via Var:{self.var_type}'s distribution: {self._frozen_dist}\")\n",
        "        if self.sample_method!='categorical':\n",
        "            return val\n",
        "        return self._frozen_dist.index(val)\n",
        "\n",
        "    def distribution(self, indices: bool = False):\n",
        "        if self.sample_method!='categorical':\n",
        "            return self._dist\n",
        "        if indices:\n",
        "            return self._dist\n",
        "        return [self._frozen_dist[idx] for idx in self._dist]\n",
        "\n",
        "    def sample(self, trial):\n",
        "        if not isinstance(trial, (Trial, FrozenTrial)):\n",
        "            raise ValueError(f\"Input 'trial' must be of type in (optuna::Trial, optuna::FrozenTrial) but found: {trial}\")\n",
        "\n",
        "        if isinstance(trial, FrozenTrial):\n",
        "            idx_or_val = trial.params[self.var_type]\n",
        "            #sample_method=='categorical' <-> retrieved value is an index NOT an actual value.\n",
        "            sampled_val = self.convert_idx_to_val(idx_or_val) if self.sample_method=='categorical' else idx_or_val\n",
        "            return sampled_val\n",
        "\n",
        "        sampled_val = None\n",
        "        if self.sample_method == 'categorical':\n",
        "            idx = trial.suggest_categorical(self.var_type, choices=self._dist)\n",
        "            sampled_val = self._frozen_dist[idx]\n",
        "        elif self.sample_method == 'float':\n",
        "            sampled_val = trial.suggest_float(self.var_type, **self._dist)\n",
        "        elif self.sample_method == 'int':\n",
        "            sampled_val = trial.suggest_int(self.var_type, **self._dist)\n",
        "\n",
        "        return sampled_val\n",
        "\n",
        "    def update(self, vals: list):\n",
        "        #Proior processing:\n",
        "        if not len(vals):\n",
        "            return\n",
        "        if not all(isinstance(val, (int,float)) for val in vals):\n",
        "            raise ValueError(f\"Var of type: {self.var_type} with sample_method: {self.sample_method} recieved update request with 'vals': {vals} which contain element(s) NOT of type in (int,float)\")\n",
        "        vals = sorted(vals.copy()) if self.sample_method=='categorical' else vals\n",
        "\n",
        "        set_vals = set(vals)\n",
        "        if len(set_vals)==1:\n",
        "            vals = [vals[0]]\n",
        "            self.fixed = True\n",
        "\n",
        "        #ERROR CHECKS:\n",
        "        if self.sample_method!='categorical' and (min(vals)<self._dist['low'] or max(vals)>self._dist['high']):\n",
        "            raise ValueError(f\"Var of type: {self.var_type} with sample_method: {self.sample_method} recieved update request with 'vals': {vals} NOT in valid range: [{self._dist['low']},{self._dist['high']}]. Note the initial search space: [{self._frozen_dist['low']},{self._frozen_dist['high']}].\")\n",
        "        if self.sample_method=='categorical' and not set_vals.issubset(set(self._dist)):\n",
        "            raise ValueError(f\"Var of type: {self.var_type} with sample_method: {self.sample_method} recieved update request with 'vals': {vals} NOT in valid range: {self._dist}. Note the initial search space: {self._frozen_dist}\")\n",
        "\n",
        "        #UPDATE: configuration space.\n",
        "        if self.sample_method=='categorical':\n",
        "            self._dist = vals\n",
        "        else:\n",
        "            self._dist['low'] = min(vals)\n",
        "            self._dist['high'] = max(vals)"
      ],
      "metadata": {
        "id": "6FfK4Xv9-ZeR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test: Var"
      ],
      "metadata": {
        "id": "Yr4PS-9cU9Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestVar(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        self.categorical_source = {\n",
        "            'params': {'choices': [1, 2, 3, 4, 5]},\n",
        "            'sample': 'categorical'\n",
        "        }\n",
        "        self.float_source = {\n",
        "            'params': {'low': 0.1, 'high': 1.0},\n",
        "            'sample': 'float'\n",
        "        }\n",
        "        self.int_source = {\n",
        "            'params': {'low': 1, 'high': 10},\n",
        "            'sample': 'int'\n",
        "        }\n",
        "\n",
        "    def test_init_categorical(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        self.assertEqual(var.var_type, 'test_var')\n",
        "        self.assertEqual(var.sample_method, 'categorical')\n",
        "        self.assertEqual(var._frozen_dist, [1, 2, 3, 4, 5])\n",
        "        self.assertEqual(var._dist, [0, 1, 2, 3, 4])\n",
        "        self.assertFalse(var.fixed)\n",
        "\n",
        "    def test_init_float(self):\n",
        "        var = Var(var_type='test_var', source=self.float_source)\n",
        "        self.assertEqual(var.var_type, 'test_var')\n",
        "        self.assertEqual(var.sample_method, 'float')\n",
        "        self.assertEqual(var._frozen_dist, {'low': 0.1, 'high': 1.0})\n",
        "        self.assertEqual(var._dist, {'low': 0.1, 'high': 1.0})\n",
        "        self.assertFalse(var.fixed)\n",
        "\n",
        "    def test_init_int(self):\n",
        "        var = Var(var_type='test_var', source=self.int_source)\n",
        "        self.assertEqual(var.var_type, 'test_var')\n",
        "        self.assertEqual(var.sample_method, 'int')\n",
        "        self.assertEqual(var._frozen_dist, {'low': 1, 'high': 10})\n",
        "        self.assertEqual(var._dist, {'low': 1, 'high': 10})\n",
        "        self.assertFalse(var.fixed)\n",
        "\n",
        "    def test_init_error_invalid_sample_method(self):\n",
        "        with self.assertRaises(ValueError):\n",
        "            Var(var_type='test_var', source={'params': {'choices': [1, 2]}, 'sample': 'invalid'})\n",
        "\n",
        "    def test_init_error_invalid_distribution_type(self):\n",
        "        with self.assertRaises(ValueError):\n",
        "            Var(var_type='test_var', source={'params': {'choices': {'key': 'value'}}, 'sample': 'categorical'})\n",
        "\n",
        "    def test_contain_idx(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        self.assertTrue(var.contain_idx(2))\n",
        "        self.assertFalse(var.contain_idx(5))\n",
        "\n",
        "        var_float = Var(var_type='test_var', source=self.float_source)\n",
        "        self.assertTrue(var_float.contain_idx(0.5))\n",
        "        self.assertFalse(var_float.contain_idx(1.1))\n",
        "\n",
        "    def test_contain_val(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        self.assertTrue(var.contain_val(3))\n",
        "        self.assertFalse(var.contain_val(6))\n",
        "\n",
        "        var_float = Var(var_type='test_var', source=self.float_source)\n",
        "        self.assertTrue(var_float.contain_val(0.5))\n",
        "        self.assertFalse(var_float.contain_val(1.1))\n",
        "\n",
        "    def test_convert_idx_to_val(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        self.assertEqual(var.convert_idx_to_val(2), 3)\n",
        "\n",
        "        var_float = Var(var_type='test_var', source=self.float_source)\n",
        "        self.assertEqual(var_float.convert_idx_to_val(0.5), 0.5)\n",
        "\n",
        "    def test_convert_val_to_idx(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        self.assertEqual(var.convert_val_to_idx(3), 2)\n",
        "\n",
        "        with self.assertRaises(ValueError):\n",
        "            var.convert_val_to_idx(6)\n",
        "\n",
        "    def test_distribution(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        self.assertEqual(var.distribution(), [1, 2, 3, 4, 5])\n",
        "\n",
        "        var_float = Var(var_type='test_var', source=self.float_source)\n",
        "        self.assertEqual(var_float.distribution(), {'low': 0.1, 'high': 1.0})\n",
        "\n",
        "    def test_sample_categorical(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        trial = optuna.create_study(direction='minimize').ask()\n",
        "        trial.suggest_categorical = Mock(return_value=2)\n",
        "        sampled_val = var.sample(trial)\n",
        "        self.assertEqual(sampled_val, 3)\n",
        "\n",
        "    def test_sample_float(self):\n",
        "        var = Var(var_type='test_var', source=self.float_source)\n",
        "        trial = optuna.create_study(direction='minimize').ask()\n",
        "        trial.suggest_float = Mock(return_value=0.5)\n",
        "        sampled_val = var.sample(trial)\n",
        "        self.assertEqual(sampled_val, 0.5)\n",
        "\n",
        "    def test_sample_error(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        with self.assertRaises(ValueError):\n",
        "            var.sample('not_a_trial')\n",
        "\n",
        "    def test_update_categorical(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        var.update([1, 2])\n",
        "        self.assertEqual(var.distribution(indices=True), [1,2])\n",
        "        self.assertEqual(var.distribution(), [2,3])\n",
        "        self.assertFalse(var.fixed)\n",
        "\n",
        "    def test_update_float(self):\n",
        "        var = Var(var_type='test_var', source=self.float_source)\n",
        "        var.update([0.2, 0.9])\n",
        "        self.assertEqual(var._dist['low'], 0.2)\n",
        "        self.assertEqual(var._dist['high'], 0.9)\n",
        "\n",
        "    def test_update_error_out_of_range(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        with self.assertRaises(ValueError):\n",
        "            var.update([0, 6])\n",
        "\n",
        "    def test_str(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        expected_str = \"Var of type: test_var\\nConfiguration Space:\\n'choices' = [1, 2, 3, 4, 5]\\n\"\n",
        "        self.assertEqual(str(var), expected_str)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "id": "0s272DsrVA_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a52cb24-4750-48c8-91d9-125d36e6394c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "..........[I 2024-09-27 21:37:26,523] A new study created in memory with name: no-name-54b7dbbc-9bd5-4a9c-bd2a-7242277ad5b2\n",
            "..[I 2024-09-27 21:37:26,529] A new study created in memory with name: no-name-5350e2d4-5ac0-4fb0-a06e-00bacf8ef38c\n",
            ".....\n",
            "----------------------------------------------------------------------\n",
            "Ran 17 tests in 0.063s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: Action"
      ],
      "metadata": {
        "id": "PFzep6tqVNNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Action:\n",
        "    def __init__(self, action_func: Callable, sig_dict: dict):\n",
        "        if not all(isinstance(var,Var) for var in sig_dict.values()):\n",
        "            raise ValueError(f\"Constructor of object 'Action' with action_func: '{action_func.__name__}' received an invalid dictionary sig_dict: {sig_dict}\")\n",
        "        self.action_func = action_func\n",
        "        self.sig_dict = sig_dict\n",
        "        self.sig = frozenset(sig_dict.keys())\n",
        "        self.params = {}\n",
        "        self.action_state = None\n",
        "        self._model_loader = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sig_dict)\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.sig)\n",
        "\n",
        "    def __eq__(self, other: Action):\n",
        "        \"\"\"Two Action objects are considered 'equal'\n",
        "        IFF (1)other is Action object\n",
        "            (2)self.action_func == other.action_func\n",
        "            (3)self.params == other.params\n",
        "            (4)self.action_state == other.action_state\n",
        "        \"\"\"\n",
        "        self_params = self._model_loader.keywords if self._model_loader is not None else self._model_loader\n",
        "        other_params = other._model_loader.keywords if other._model_loader is not None else other._model_loader\n",
        "        if self_params != other_params:\n",
        "            return False\n",
        "\n",
        "        # Compare action states if both are dictionaries\n",
        "        if isinstance(self.action_state, dict) and isinstance(other.action_state, dict):\n",
        "            if self.action_state.keys() != other.action_state.keys():\n",
        "                return False\n",
        "            if not all(torch.equal(self.action_state[key], other.action_state[key]) for key in self.action_state.keys()):\n",
        "                return False\n",
        "        elif self.action_state != other.action_state: #IF one is None and the other is not None.\n",
        "            return False\n",
        "\n",
        "        return all([\n",
        "            self.action_func == other.action_func,\n",
        "            self.sig_dict == other.sig_dict,\n",
        "        ])\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        signature = \" \".join([f\"{var}\" for var in self.sig_dict.values()])\n",
        "        output = f\"Action of func: {self.action_func.__name__}\\nSignature Vars:\\n{signature}\\n\"\n",
        "        if self._model_loader:\n",
        "            parameters = \" \".join([f\"{key}={val}\" for key,val in self._model_loader.keywords.items()])\n",
        "            output += f\"Model loader parameters: {parameters}\\n\"\n",
        "        return output\n",
        "\n",
        "    def get_var(self, var_type):\n",
        "        if var_type not in self.keys():\n",
        "            raise ValueError(f\"'{var_type}' is not a valid signature key for Action: '{self.action_func.__name__}'. Available keys: {set(self.keys())}\")\n",
        "        return self.sig_dict[var_type]\n",
        "\n",
        "    def keys(self):\n",
        "        return self.sig_dict.keys()\n",
        "\n",
        "    def values(self):\n",
        "        return self.sig_dict.values()\n",
        "\n",
        "    def items(self):\n",
        "        return self.sig_dict.items()\n",
        "\n",
        "    def is_loadable(self):\n",
        "        return self._model_loader is not None\n",
        "\n",
        "    def is_fixed(self):\n",
        "        return all(var.fixed for var in self.sig_dict.values())\n",
        "\n",
        "    def parameterize(self, trial: optuna.Trial):\n",
        "        \"\"\"\n",
        "        ACCEPTS:\n",
        "        trial := Active optuna trial objet.\n",
        "                 IF input 'manual_action_params' is not empty, THEN 'trial' will NOT be used.\n",
        "        RETURNS: void.\n",
        "                 The function parameterizes the caller Action object.\n",
        "                 Without any saved action_state, the caller Action object needs to be parameterized every time before .__call__()\n",
        "        \"\"\"\n",
        "        #ERROR CHECKS:\n",
        "        if self.action_state is not None and not self.params:\n",
        "            raise ValueError(f\"Action: {self.action_func.__name__} has a saved action state(self.action_state!=None) but NO saved params(self.params==None).\")\n",
        "        if self.action_state is None and trial is None:\n",
        "            raise ValueError(f\"Action: {self.action_func.__name__} has no saved action state(self.action_state==None) and no input trial passed in(self.trial==None). No sampling can be done.\")\n",
        "\n",
        "        if self.action_state is None:\n",
        "            self.params = {cat:var.sample(trial=trial) for cat,var in self.items()}\n",
        "\n",
        "        #self._model_loader <- Fully parameterized model with self.params\n",
        "        #NOTE: IF it has a saved action state, the consistent self.params will restore the recenmost state(based on the recentmost top sampling results)\n",
        "        self._model_loader = partial(self.action_func, **self.params)\n",
        "\n",
        "    def __call__(self, device: torch.device):\n",
        "        if self.action_state is not None and not self.params:\n",
        "            raise ValueError(f\"Action: {self.action_func.__name__} has a saved action state(self.action_state!=None) but no saved params exists(self.params empty). Likely an internal logic issue\")\n",
        "        if self._model_loader is None:\n",
        "            raise ValueError(f\"Action: {self.action_func.__name__} cannot be called. Call Action.parameterize() first and then try it again.\")\n",
        "\n",
        "        #model <- Load the model onto 'device'.\n",
        "        model = self._model_loader(device=device)\n",
        "\n",
        "        #IF 'self.action_state' exists, THEN load the saved weights from the state dictionary(=self.action_state) to the model\n",
        "        if self.action_state:\n",
        "            try:\n",
        "                name = self.action_func.__name__\n",
        "                model.load_state_dict(self.action_state)\n",
        "            except torch.nn.modules.module.ModuleAttributeError as e:\n",
        "                print(f\"Attribute error: {e}. The state dictionary of Action: '{name}' may not match the model.\")\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Runtime error: {e}. The state dictionary of Action: '{name}' may have unmatching layer sizes or missing keys.\")\n",
        "            except Exception as e:\n",
        "                print(f\"An unexpected error occurred while loading state dictionary to Action '{name}': {e}\")\n",
        "\n",
        "        #Last but not least, return the model.\n",
        "        return model\n",
        "\n",
        "    def update_sig(self, update_params: dict):\n",
        "        #IF Action (1)has a saved 'action_state' OR (2)0 elements in the 'update_params'\n",
        "        #THEN NO update shall be done.\n",
        "        if self.action_state or not len(update_params):\n",
        "            return\n",
        "\n",
        "        #ERROR CHECK: Make sure that ALL the keys in 'self.sig_dict' belong to 'sig_params'\n",
        "        leftovers = set(self.keys()) - set(update_params.keys())\n",
        "        if leftovers:\n",
        "            raise ValueError(f\"Updating Action: {self.action_func.__name__} requires following missing keys in 'sig_params': {leftovers}\")\n",
        "        if not all(isinstance(val,list) for val in update_params.values()):\n",
        "            raise ValueError(f\"Updating Action: {self.action_func.__name__} with input 'update_params' failed. ALL the values in 'update_params' MUST be of type 'list' but found: {update_params}\")\n",
        "\n",
        "        #Update: signature configuration space(=='self.sig_dict')\n",
        "        for cat,var in self.items():\n",
        "            var.update(vals=update_params[cat])\n",
        "\n",
        "    def update_state(self, obj):\n",
        "        \"\"\"\n",
        "        profile := A dictionary that contains the caller's signature(except 'device') as its subset.\n",
        "                   Additionally, every (sig->value) must contain the same value as what initialized the passed in 'obj'.\n",
        "        \"\"\"\n",
        "        #ERROR CHECK1: Type of obj.\n",
        "        if not isinstance(obj, (nn.Module, Learner, dict)):\n",
        "            raise ValueError(f\"Updating action state of Action: {self.action_func.__name__} failed. Input object 'obj' must be of type in (nn.Module, Learner, dict) but found: {type(obj)}\")\n",
        "        #ERROR CHECK2: This catches if one attempts to update the Action object with overriden\n",
        "        if self.action_state is not None and self.params != self._model_loader.keywords:\n",
        "            raise ValueError(f\"Updating action state of Action: {self.action_func.__name__} failed. Make sure that this object was sampled with valid Trialin the previuos HPO run. If .get_loadable_action() was used, then .update_state is NOT allowed.\")\n",
        "\n",
        "        if isinstance(obj, dict):\n",
        "            self.action_state = obj\n",
        "        else:\n",
        "            self.action_state = obj.model.state_dict() if isinstance(obj, Learner) else obj.state_dict()\n",
        "\n",
        "        #Manually set 'self.params'. This way, saved action_state -> self.params available!\n",
        "        self.params = self._model_loader.keywords.copy()"
      ],
      "metadata": {
        "id": "Y2qBB2qFHoUo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test: Action"
      ],
      "metadata": {
        "id": "57JeyleVJWz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Parameters used in the testin of class 'Action' defined in this cell\n",
        "\"\"\"\n",
        "class ModelDefault(nn.Module):\n",
        "    def __init__(self, rand_number: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Linear(16,10)\n",
        "        self.rand_number = torch.tensor(rand_number)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x) + self.rand_number\n",
        "\n",
        "class ModelDropout(nn.Module):\n",
        "    def __init__(self, activation: nn.Module, dropout_p: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=16,out_features=10),\n",
        "            activation(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "            nn.Linear(in_features=10,out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def action_default(rand_number: int, device: torch.device):\n",
        "    return ModelDefault(rand_number=rand_number).to(device)\n",
        "\n",
        "def action_dropout(activation, dropout_p, device: torch.device):\n",
        "    #model_dropout := Class header of 'ModelDropout'\n",
        "    return ModelDropout(activation=activation, dropout_p=dropout_p).to(device)\n",
        "\n",
        "#ASSUMED: Input size of 10x16. (Single batch == 10 (4x4 flattened vector)s )\n",
        "#FIRST_LAYER: Fully connected linear layer of size 16x10\n",
        "#ACTIVATION: One of nn.ReLU, nn.PReLU, nn.SiLU\n",
        "#DROPOUT: nn.Dropout(p=dropout_p)\n",
        "#OUT: .shape == [10,10]\n",
        "#NOTE: Input 'model: Callable' will be the class header 'Model'."
      ],
      "metadata": {
        "id": "WouVr4SYNPPP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestAction(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        default_sig_dict = {\n",
        "            'rand_number': Var(var_type='rand_number', source={'params': {'choices': list(range(1, 11))}, 'sample': 'categorical'})\n",
        "        }\n",
        "        dropout_sig_dict = {\n",
        "            'activation': Var(var_type='activation', source={'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]}, 'sample': 'categorical'}),\n",
        "            'dropout_p': Var(var_type='dropout_p', source={'params': {'low': 0.0, 'high': 1.0}, 'sample': 'float'})\n",
        "        }\n",
        "\n",
        "        self.action_sampler = {\n",
        "            action_default: Action(action_default, default_sig_dict),\n",
        "            action_dropout: Action(action_dropout, dropout_sig_dict)\n",
        "        }\n",
        "\n",
        "        # Create a trial object for parameterization\n",
        "        self.trial = optuna.create_study(direction='minimize').ask()\n",
        "\n",
        "    def test_initialization(self):\n",
        "        default_action = self.action_sampler[action_default]\n",
        "        dropout_action = self.action_sampler[action_dropout]\n",
        "\n",
        "        # Test if Action objects are initialized correctly\n",
        "        self.assertIsInstance(default_action, Action)\n",
        "        self.assertIsInstance(dropout_action, Action)\n",
        "\n",
        "        self.assertTrue(default_action.action_func == action_default)\n",
        "        self.assertIsInstance(default_action.get_var('rand_number'), Var)\n",
        "        self.assertTrue(\n",
        "            default_action.get_var('rand_number').distribution() == list(range(1, 11)),\n",
        "            msg=f\"{default_action.get_var('rand_number').distribution()} != {list(range(1, 11))}\"\n",
        "        )\n",
        "        self.assertFalse(default_action.params)\n",
        "        self.assertIsNone(default_action.action_state)\n",
        "        self.assertIsNone(default_action._model_loader)\n",
        "\n",
        "        self.assertTrue(dropout_action.action_func == action_dropout)\n",
        "        self.assertIsInstance(dropout_action.get_var('activation'), Var)\n",
        "        self.assertIsInstance(dropout_action.get_var('dropout_p'), Var)\n",
        "        self.assertTrue(dropout_action.get_var('activation').distribution() == [nn.ReLU, nn.PReLU, nn.SiLU])\n",
        "        self.assertFalse(dropout_action.params)\n",
        "        self.assertIsNone(dropout_action.action_state)\n",
        "        self.assertIsNone(dropout_action._model_loader)\n",
        "\n",
        "    def test_default_parameterize_with_action_state(self):\n",
        "        default_action = self.action_sampler[action_default]\n",
        "        default_action.action_state = 'dummy'\n",
        "        default_action.params = {'rand_number': 1}\n",
        "\n",
        "        # Test parameterization with the default action\n",
        "        default_action.parameterize(trial=self.trial)\n",
        "\n",
        "        # Posterior testing\n",
        "        self.assertIsInstance(default_action, Action)\n",
        "        self.assertIsNotNone(default_action.params)\n",
        "        self.assertIsNotNone(default_action.action_state)\n",
        "        self.assertIsNotNone(default_action._model_loader)\n",
        "\n",
        "        try:\n",
        "            model = default_action(device=torch.device('cpu'))\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "    def test_default_parameterize(self):\n",
        "        default_action = self.action_sampler[action_default]\n",
        "        # Test parameterization with the default action\n",
        "        default_action.parameterize(trial=self.trial)\n",
        "        self.assertTrue(set(default_action.params.keys()), set(['rand_number']))\n",
        "        self.assertTrue(default_action.params['rand_number'] in list(range(1, 11)))\n",
        "        self.assertIsNone(default_action.action_state)\n",
        "        self.assertIsNotNone(default_action._model_loader)\n",
        "        model = default_action(device=torch.device('cpu'))\n",
        "        X = torch.randn(size=[10, 16])\n",
        "        Y = model(X)\n",
        "        self.assertEqual(Y.shape, torch.Size([10, 10]))\n",
        "\n",
        "        self.assertIsNotNone(default_action.params)\n",
        "        self.assertIsNone(default_action.action_state)\n",
        "        self.assertIsNotNone(default_action._model_loader)\n",
        "\n",
        "    def test_dropout_parameterize_with_action_state(self):\n",
        "        dropout_action = self.action_sampler[action_dropout]\n",
        "        dropout_action.params = {\n",
        "            'activation': nn.ReLU,\n",
        "            'dropout_p': 0.5\n",
        "        }\n",
        "        model = ModelDropout(activation=nn.ReLU, dropout_p=0.5).to(torch.device('cpu'))\n",
        "        dropout_action.action_state = model.state_dict()\n",
        "\n",
        "        # Test parameterization with the default action\n",
        "        dropout_action.parameterize(trial=self.trial)\n",
        "\n",
        "        # Posterior testing\n",
        "        self.assertIsInstance(dropout_action, Action)\n",
        "        self.assertIsNotNone(dropout_action.params)\n",
        "        self.assertIsNotNone(dropout_action.action_state)\n",
        "        self.assertIsNotNone(dropout_action._model_loader)\n",
        "\n",
        "        try:\n",
        "            model = dropout_action(device=torch.device('cpu'))\n",
        "            self.assertTrue(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "        # Final testing\n",
        "        self.assertIsNotNone(dropout_action.params)\n",
        "        self.assertIsNotNone(dropout_action.action_state)\n",
        "        self.assertIsNotNone(dropout_action._model_loader)\n",
        "\n",
        "    def test_dropout_parameterize(self):\n",
        "        dropout_action = self.action_sampler[action_dropout]\n",
        "\n",
        "        # Prior Testing\n",
        "        self.assertIsInstance(dropout_action, Action)\n",
        "        self.assertTrue(dropout_action.params == {})\n",
        "        self.assertIsNone(dropout_action.action_state)\n",
        "        self.assertIsNone(dropout_action._model_loader)\n",
        "\n",
        "        # Test parameterization with the default action\n",
        "        dropout_action.parameterize(trial=self.trial)\n",
        "\n",
        "        # Posterior Testing\n",
        "        self.assertTrue(set(dropout_action.params.keys()), set(['activation', 'dropout_p']))\n",
        "        self.assertTrue(dropout_action.params['activation'] in [nn.ReLU, nn.PReLU, nn.SiLU])\n",
        "        self.assertTrue(0.0 <= dropout_action.params['dropout_p'] <= 1.0)\n",
        "        self.assertIsNone(dropout_action.action_state)\n",
        "        self.assertIsNotNone(dropout_action._model_loader)\n",
        "\n",
        "        # Model loading & testing\n",
        "        model = dropout_action(device=torch.device('cpu'))\n",
        "        self.assertEqual(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "        # Final testing\n",
        "        self.assertIsNotNone(dropout_action.params)\n",
        "        self.assertIsNone(dropout_action.action_state)\n",
        "        self.assertIsNotNone(dropout_action._model_loader)\n",
        "\n",
        "    def test_update_sig(self):\n",
        "        # Preparation\n",
        "        default_action = self.action_sampler[action_default]\n",
        "        dropout_action = self.action_sampler[action_dropout]\n",
        "\n",
        "        default_new_sig_params = {\n",
        "            'rand_number': [2]\n",
        "        }\n",
        "        dropout_new_sig_params = {\n",
        "            'activation': [1, 2],\n",
        "            'dropout_p': [0.45, 0.5, 0.72]\n",
        "        }\n",
        "\n",
        "        # TEST: default_action FOR: sig_dict\n",
        "        default_action.update_sig(update_params=default_new_sig_params)\n",
        "        self.assertIsInstance(default_action.get_var('rand_number'), Var)\n",
        "        self.assertTrue(default_action.get_var('rand_number').distribution() == [3])\n",
        "        self.assertTrue(default_action.get_var('rand_number').distribution(indices=True) == [2])\n",
        "\n",
        "        # TEST: dropout_action FOR: sig_dict\n",
        "        dropout_action.update_sig(update_params=dropout_new_sig_params)\n",
        "        self.assertIsInstance(dropout_action.get_var('activation'), Var)\n",
        "        self.assertTrue(dropout_action.get_var('activation').distribution() == [nn.PReLU, nn.SiLU],\n",
        "                        msg=f\"{dropout_action.get_var('activation').distribution()} != {[nn.PReLU, nn.SiLU]}\")\n",
        "        self.assertTrue(dropout_action.get_var('activation').distribution(True) == [1, 2],\n",
        "                        msg=f\"{dropout_action.get_var('activation').distribution(True)} != {[1, 2]}\")\n",
        "        self.assertIsInstance(dropout_action.get_var('dropout_p'), Var)\n",
        "        dropout_p_var = dropout_action.get_var('dropout_p')\n",
        "        self.assertTrue(dropout_p_var.distribution()['low'] == 0.45 and dropout_p_var.distribution()['high'] == 0.72)\n",
        "\n",
        "    # Additional method to test update_state if needed\n",
        "    def test_update_state(self):\n",
        "        for i in range(5):\n",
        "            default_action = self.action_sampler[action_default]\n",
        "            dropout_action = self.action_sampler[action_dropout]\n",
        "\n",
        "            if not i:\n",
        "                self.assertTrue(default_action.params == {})\n",
        "                self.assertIsNone(default_action.action_state)\n",
        "                self.assertIsNone(default_action._model_loader)\n",
        "\n",
        "                self.assertTrue(dropout_action.params == {})\n",
        "                self.assertIsNone(dropout_action.action_state)\n",
        "                self.assertIsNone(dropout_action._model_loader)\n",
        "            else:\n",
        "                self.assertFalse(default_action.params == {})\n",
        "                self.assertIsNotNone(default_action.action_state)\n",
        "                self.assertIsNotNone(default_action._model_loader)\n",
        "\n",
        "                self.assertFalse(dropout_action.params == {})\n",
        "                self.assertIsNotNone(dropout_action.action_state)\n",
        "                self.assertIsNotNone(dropout_action._model_loader)\n",
        "\n",
        "            default_action.parameterize(trial=self.trial)\n",
        "            dropout_action.parameterize(trial=self.trial)\n",
        "\n",
        "            default_model = default_action(device=torch.device('cpu'))\n",
        "            dropout_model = dropout_action(device=torch.device('cpu'))\n",
        "\n",
        "            self.assertEqual(default_model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "            self.assertEqual(dropout_model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "            default_action.update_state(obj=default_model)\n",
        "            dropout_action.update_state(obj=dropout_model)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9nYGFwtTzAh",
        "outputId": "5341c81e-0114-45b7-e51d-b51fa9aee016"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:37:26,696] A new study created in memory with name: no-name-d3ffcc07-671d-4141-af90-0d7a1005a56f\n",
            ".[I 2024-09-27 21:37:26,818] A new study created in memory with name: no-name-617f16d5-8123-4c44-b061-18f72dacb208\n",
            ".[I 2024-09-27 21:37:26,830] A new study created in memory with name: no-name-14a98dd4-b6ed-4075-9a64-a476c0ede889\n",
            ".[I 2024-09-27 21:37:26,885] A new study created in memory with name: no-name-98460ab6-a6f0-4411-85f6-c46979e51242\n",
            ".[I 2024-09-27 21:37:26,916] A new study created in memory with name: no-name-32f78d07-55fa-46de-90db-286de227b1d9\n",
            ".[I 2024-09-27 21:37:26,923] A new study created in memory with name: no-name-5ada5028-e7e0-41f8-8e7e-9c69cfafb7b7\n",
            ".[I 2024-09-27 21:37:26,933] A new study created in memory with name: no-name-595af548-4d81-4b5f-a9c4-3ad02184030e\n",
            "...........[I 2024-09-27 21:37:26,996] A new study created in memory with name: no-name-200a71fe-1cf9-4283-96e3-c50662573d03\n",
            "..[I 2024-09-27 21:37:27,018] A new study created in memory with name: no-name-b181fca4-f8bc-4d97-ba1b-82bb0dbd3e16\n",
            ".....\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 0.331s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: ActionSampler"
      ],
      "metadata": {
        "id": "NpxMBQTBeH4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ActionSampler:\n",
        "    def __init__(self, INIT_ACTION_DICT: dict):\n",
        "        self.actions = dict()\n",
        "\n",
        "        for action_func,sig_dict in INIT_ACTION_DICT.items():\n",
        "            if not all(isinstance(var,Var) for var in sig_dict.values()):\n",
        "                raise ValueError(f\"Input dictionary for initializing object 'ActionSampler' with action_func: {action_func.__name__} has a non-Var value in it. Input Dictionary: {sig_dict}\")\n",
        "            self.actions[action_func] = Action(action_func=action_func, sig_dict=sig_dict)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.actions)\n",
        "\n",
        "    def __eq__(self, other: ActionSampler):\n",
        "        return isinstance(other, ActionSampler) and self.actions == other.actions\n",
        "\n",
        "    def __str__(self):\n",
        "        output = \"**********ActionSampler**********\\n\"\n",
        "        output += \"\".join([f\"{action}\\n\" for action in self.actions.values()])\n",
        "        return output\n",
        "\n",
        "    def get_action(self, action_func):\n",
        "        if action_func not in self.keys():\n",
        "            raise KeyError(f\"ActionSampler cannot retrieve Requested Action: {action_func.__name__ if callable(action_func) else action_func}, since it does NOT belong to: {self.keys()}\")\n",
        "        return self.actions[action_func]\n",
        "\n",
        "    def keys(self):\n",
        "        return self.actions.keys()\n",
        "\n",
        "    def values(self):\n",
        "        return self.actions.values()\n",
        "\n",
        "    def items(self):\n",
        "        return self.actions.items()\n",
        "\n",
        "    def sample(self, action_func: Callable, trial: Trial):\n",
        "        \"\"\"\n",
        "        SAMPLING THROUGH ActionSampler WILL ENFORCE THAT input 'trial'!=None.\n",
        "        (Much like the TrainSampler)\n",
        "        \"\"\"\n",
        "        if trial is not None and not isinstance(trial, (Trial, FrozenTrial)):\n",
        "            raise ValueError(f\"Input 'trial' should be an object optuna::Trial or optuna::FrozenTrial but found: {trial}\")\n",
        "        if trial is None:\n",
        "            raise ValueError(f\"Input 'trial' cannot be None when sampling is requested through ActionSampler. Either pass in as trial an active TrialOR manually build an Action function\")\n",
        "\n",
        "        #action <- Action object that encapsulates 'action_func'\n",
        "        action = self.get_action(action_func)\n",
        "\n",
        "        #Parameterize 'action'.\n",
        "        action.parameterize(trial=trial)\n",
        "\n",
        "        #RETURN: Fully parameterized 'action'.\n",
        "        #NOTE: 'action' could be either be sampled from 'trial' or loaded from saved signatures(if 'action' has a saved action_state or trial==None)\n",
        "        return action\n",
        "\n",
        "    def get_loadable_action(self, action_func: Callable, source):\n",
        "        \"\"\"\n",
        "        ASSUMPTION: source is a dictionary of parameters whose categorical values are all indices.\n",
        "        \"\"\"\n",
        "        if not isinstance(source, (Trial, FrozenTrial, dict)):\n",
        "            raise ValueError(f\"Input 'source' must be of type in (optuna::Trial, optuna::FrozenTrial, dict) but found: {source}\")\n",
        "\n",
        "        action = self.get_action(action_func)\n",
        "        #IF action has a saved 'action_state', THEN return action object.\n",
        "        if action.action_state:\n",
        "            return action\n",
        "\n",
        "        #source <- source.params if isinstance(Trial, FrozenTrial)\n",
        "        source = source if isinstance(source, dict) else source.params\n",
        "        #leftovers <- action.keys() that are not covered by source.keys()\n",
        "        leftovers = set(action.keys()) - set(source.keys())\n",
        "        if leftovers:\n",
        "            raise ValueError(f\"Action: {action_func.__name__} requires following missing keys in 'source': {leftovers}\")\n",
        "\n",
        "        #Recast the values of 'source' using action.items()\n",
        "        source = {key:var.convert_idx_to_val(idx=source[key]) for key,var in action.items()}\n",
        "\n",
        "        #OVERRIDE: action._model_loader\n",
        "        action._model_loader = partial(action_func, **source)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def get_action_to_profile(self, list_params: list):\n",
        "        \"\"\"\n",
        "        TO BE CALLED IN Sampler.get_default_dict() AFTER .get_evaluated_params()\n",
        "        list_of_params := list of params produced by .get_evaluated_params() on each trial of top_k_trials.\n",
        "        \"\"\"\n",
        "        action_to_profile = defaultdict(lambda: defaultdict(list))\n",
        "        profiled_actions = set()\n",
        "        action_funcs = self.keys()\n",
        "\n",
        "        for params in list_params:\n",
        "            if 'action_func' not in params.keys(): continue\n",
        "            #action_func <- Callable 'action_func'\n",
        "            action_func = params['action_func']\n",
        "            #Sanity Check1:\n",
        "            assert action_func in action_funcs\n",
        "            #action <- Action object that reprs 'action_func'\n",
        "            action = self.get_action(action_func)\n",
        "            #Sanity Check2:\n",
        "            assert isinstance(action, Action)\n",
        "            #action_state <- state dictionary of the 'action' object.\n",
        "            action_state = action.action_state\n",
        "            params_sig_keys = set(params.keys() & action.keys())\n",
        "            params_train_keys = set(params.keys()) - params_sig_keys\n",
        "\n",
        "            #ERROR CHECKS:\n",
        "            if action_state and params_sig_keys:\n",
        "                raise ValueError(f\"Action: {action.action_func.__name__} has a saved action_state but 'params' has the following keys: {params_sig_keys}\")\n",
        "            if not action_state and params_sig_keys!=set(action.keys()):\n",
        "                raise ValueError(f\"Action: {action.action_func.__name__} does NOT have a saved action_state but params_sig_keys: {params_sig_keys} != action.keys(): {action.keys()}\")\n",
        "\n",
        "            #profile <- Dict of lists according to the 'action_func'\n",
        "            profile = action_to_profile[action_func]\n",
        "            profile.update({key:profile[key] + [val] for key,val in params.items() if key in params_sig_keys})\n",
        "            if action_func not in profiled_actions:\n",
        "                profiled_actions.add(action_func)\n",
        "                profile.update({key:profile[key] + [val] for key,val in params.items() if key in params_train_keys})\n",
        "\n",
        "        return action_to_profile\n",
        "\n",
        "    def update_vars(self, action_to_profile: dict):\n",
        "        for action_func,profile in action_to_profile.items():\n",
        "            self.get_action(action_func).update_sig(update_params=profile)\n",
        "\n",
        "    def update_states(self, action_to_profile: dict, model_train_window: int, device: torch.device):\n",
        "        m = model_train_window\n",
        "\n",
        "        for action_func, profile in list(action_to_profile.items())[:m]:\n",
        "            #default_dict <- only the best value(s) for each (signature)parameter extracted.\n",
        "            default_dict = {var_type:vals[0] for var_type,vals in profile.items()}\n",
        "            #action <- loadable action created with best signature parameters\n",
        "            action = self.get_loadable_action(\n",
        "                action_func=action_func,\n",
        "                source=default_dict\n",
        "            )\n",
        "\n",
        "            assert action.is_loadable(), f\"action: {action}\"\n",
        "\n",
        "            #UPDATE: 'default_dict' with ('action_func'->manual_action)\n",
        "            default_dict.update({'action_func':action})\n",
        "\n",
        "            trainer, learner = Wrapper(\n",
        "                trial=None,\n",
        "                sampler=None,\n",
        "                device=device,\n",
        "                default_dict=default_dict\n",
        "            ).yield_execution_set()\n",
        "            trainer()\n",
        "            action.update_state(obj=learner)"
      ],
      "metadata": {
        "id": "7F91cihMfry0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test: ActionSampler"
      ],
      "metadata": {
        "id": "Ihwh3f14Wl_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelDefault(nn.Module):\n",
        "    def __init__(self, rand_number: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Linear(16,10)\n",
        "        self.rand_number = torch.tensor(rand_number)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x) + self.rand_number\n",
        "\n",
        "class ModelDropout(nn.Module):\n",
        "    def __init__(self, activation: nn.Module, dropout_p: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=16,out_features=10),\n",
        "            activation(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "            nn.Linear(in_features=10,out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def action_default(rand_number: int, device: torch.device):\n",
        "    return ModelDefault(rand_number=rand_number).to(device)\n",
        "\n",
        "def action_dropout(activation, dropout_p, device: torch.device):\n",
        "    #model_dropout := Class header of 'ModelDropout'\n",
        "    return ModelDropout(activation=activation, dropout_p=dropout_p).to(device)\n",
        "\n",
        "#Wrapper <- Mock object\n",
        "#NOTE: Details of this object will be filled in the next cell(inside test(s) of 'TestActionSampler')\n",
        "Wrapper = Mock()"
      ],
      "metadata": {
        "id": "tNhUlYpwrQBP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestActionSampler(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.INIT_DICT = {\n",
        "            'rand_number': Var(var_type='rand_number', source={'params': {'choices': list(range(1, 11))}, 'sample': 'categorical'}),\n",
        "            'activation': Var(var_type='activation', source={'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]}, 'sample': 'categorical'}),\n",
        "            'dropout_p': Var(var_type='dropout_p', source={'params': {'low': 0.0, 'high': 1.0}, 'sample': 'float'})\n",
        "        }\n",
        "\n",
        "        action_to_sig = {func: set(signature(func).parameters.keys()) - {'device'} for func in [action_default, action_dropout]}\n",
        "        self.INIT_ACTION_DICT = {func: {key: self.INIT_DICT[key] for key in sig} for func, sig in action_to_sig.items()}\n",
        "        self.trial = optuna.create_study(direction='minimize').ask()\n",
        "\n",
        "    def test_initialization(self):\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        self.assertEqual(len(action_sampler.actions), 2)\n",
        "        self.assertIn(action_default, action_sampler.actions)\n",
        "        self.assertIn(action_dropout, action_sampler.actions)\n",
        "        self.assertTrue(all(isinstance(action, Action) for action in action_sampler.actions.values()))\n",
        "\n",
        "        default_sig_dict = {'rand_number': Var(var_type='rand_number', source={'params': {'choices': list(range(1, 11))}, 'sample': 'categorical'})}\n",
        "        dropout_sig_dict = {\n",
        "            'activation': Var(var_type='activation', source={'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]}, 'sample': 'categorical'}),\n",
        "            'dropout_p': Var(var_type='dropout_p', source={'params': {'low': 0.0, 'high': 1.0}, 'sample': 'float'})\n",
        "        }\n",
        "\n",
        "        self.assertTrue(action_sampler.get_action(action_default) == Action(action_default, default_sig_dict))\n",
        "        self.assertTrue(action_sampler.get_action(action_dropout) == Action(action_dropout, dropout_sig_dict))\n",
        "\n",
        "    def test_sample_action(self):\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        for func in [action_default, action_dropout]:\n",
        "            sampled_action = action_sampler.sample(\n",
        "                action_func=func,\n",
        "                trial=optuna.create_study(direction='minimize').ask()\n",
        "            )\n",
        "            self.assertIsInstance(sampled_action, Action)\n",
        "            expected_keys = ['rand_number'] if func == action_default else ['activation', 'dropout_p']\n",
        "            self.assertTrue(set(sampled_action.params.keys()) == set(expected_keys))\n",
        "            self.assertTrue(set(sampled_action._model_loader.keywords.keys()) == set(expected_keys))\n",
        "            self.assertIsNone(sampled_action.action_state)\n",
        "            model = sampled_action(device=torch.device('cpu'))\n",
        "            self.assertIsInstance(model, nn.Module)\n",
        "            self.assertEqual(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "    def test_get_loadable_action_with_dict(self):\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        for func in [action_default, action_dropout]:\n",
        "            loadable_action = action_sampler.get_loadable_action(\n",
        "                action_func=func,\n",
        "                source={'rand_number': 1} if func == action_default else {'activation': 0, 'dropout_p': 0.5}\n",
        "            )\n",
        "            self.assertIsInstance(loadable_action, Action)\n",
        "            self.assertTrue(\n",
        "                set(loadable_action._model_loader.keywords.keys()) == set(['rand_number']) if func == action_default else set(['activation', 'dropout_p']),\n",
        "                msg=f\"loadable_action._model_loader.keywords: {loadable_action._model_loader.keywords}\"\n",
        "            )\n",
        "            self.assertIsNone(loadable_action.action_state)\n",
        "            model = loadable_action(device=torch.device('cpu'))\n",
        "            self.assertIsInstance(model, nn.Module)\n",
        "            self.assertEqual(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "    def test_get_loadable_action_with_trial(self):\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        for func in [action_default, action_dropout]:\n",
        "            trial = optuna.create_study(direction='minimize').ask()\n",
        "            dummy = action_sampler.sample(action_func=func, trial=trial)  # Sample to simulate state changes.\n",
        "            loadable_action = action_sampler.get_loadable_action(\n",
        "                action_func=func,\n",
        "                source=trial\n",
        "            )\n",
        "            self.assertIsInstance(loadable_action, Action)\n",
        "            expected_keys = ['rand_number'] if func == action_default else ['activation', 'dropout_p']\n",
        "            self.assertTrue(set(loadable_action.params.keys()) == set(expected_keys),\n",
        "                            msg=f\"loadable_action.params: {loadable_action.params}\")\n",
        "            self.assertTrue(set(loadable_action._model_loader.keywords.keys()) == set(expected_keys),\n",
        "                            msg=f\"loadable_action._model_loader.keywords: {loadable_action._model_loader.keywords}\")\n",
        "            self.assertIsNone(loadable_action.action_state)\n",
        "            model = loadable_action(device=torch.device('cpu'))\n",
        "            self.assertIsInstance(model, nn.Module)\n",
        "            self.assertEqual(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "    def test_sample_with_invalid_trial(self):\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        with self.assertRaises(ValueError):\n",
        "            action_sampler.sample(action_default, None)\n",
        "        with self.assertRaises(ValueError):\n",
        "            action_sampler.sample(action_dropout, None)\n",
        "\n",
        "        # Test sampling with invalid trial type\n",
        "        with self.assertRaises(ValueError):\n",
        "            action_sampler.sample(action_default, \"invalid_trial\")\n",
        "        with self.assertRaises(ValueError):\n",
        "            action_sampler.sample(action_dropout, \"invalid_trial\")\n",
        "\n",
        "    def test_get_action_to_profile(self):\n",
        "        list_params = [\n",
        "            {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "            {'action_func': action_default, 'rand_number': 1, 'lr': 1e-2, 'n_epoch': 12},\n",
        "            {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "            {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20},\n",
        "            {'action_func': action_default, 'rand_number': 3, 'lr': 2e-3, 'n_epoch': 1}\n",
        "        ]\n",
        "\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        action_to_profile = action_sampler.get_action_to_profile(list_params=list_params)\n",
        "\n",
        "        for action_func, profile in action_to_profile.items():\n",
        "            self.assertIn(action_func, action_sampler.keys())\n",
        "\n",
        "            if action_func == action_default:\n",
        "                self.assertEqual(profile['rand_number'], [1, 1, 3], msg=f\"profile['rand_number']: {profile['rand_number']}\")\n",
        "                self.assertEqual(profile['lr'], [1e-2], msg=f\"profile['lr']: {profile['lr']}\")\n",
        "                self.assertEqual(profile['n_epoch'], [12], msg=f\"profile['n_epoch']: {profile['n_epoch']}\")\n",
        "            else:\n",
        "                self.assertEqual(profile['dropout_p'], [0.78, 0.123], msg=f\"profile['dropout_p']: {profile['dropout_p']}\")\n",
        "                self.assertEqual(profile['activation'], [1, 2], msg=f\"profile['activation']: {profile['activation']}\")\n",
        "                self.assertEqual(profile['lr'], [1e-1], msg=f\"profile['lr']: {profile['lr']}\")\n",
        "                self.assertEqual(profile['n_epoch'], [10], msg=f\"profile['n_epoch']: {profile['n_epoch']}\")\n",
        "\n",
        "    def test_update_vars(self):\n",
        "        list_params = [\n",
        "            {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "            {'action_func': action_default, 'rand_number': 1, 'lr': 1e-2, 'n_epoch': 12},\n",
        "            {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "            {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20},\n",
        "            {'action_func': action_default, 'rand_number': 3, 'lr': 2e-3, 'n_epoch': 1}\n",
        "        ]\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        action_to_profile = action_sampler.get_action_to_profile(list_params=list_params)\n",
        "        action_sampler.update_vars(action_to_profile)\n",
        "\n",
        "        # Check the updated variables for action_default\n",
        "        default_action = action_sampler.get_action(action_default)\n",
        "        rand_var = Var(var_type='rand_number', source={'params': {'choices': list(range(1, 11))}, 'sample': 'categorical'})\n",
        "        rand_var._dist = [1, 1, 3]\n",
        "        self.assertEqual(default_action.sig_dict, {'rand_number': rand_var}, msg=f\"default_action.sig_dict: {default_action.sig_dict}\")\n",
        "\n",
        "        # Check the updated variables for action_dropout\n",
        "        dropout_action = action_sampler.get_action(action_dropout)\n",
        "        activation_var = Var(var_type='activation', source={'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]}, 'sample': 'categorical'})\n",
        "        activation_var._dist = [1, 2]\n",
        "        dropout_p_var = Var(var_type='dropout_p', source={'params': {'low': 0.0, 'high': 1.0}, 'sample': 'float'})\n",
        "        dropout_p_var._dist = {'low': 0.123, 'high': 0.78}\n",
        "        self.assertTrue(dropout_action.get_var('activation') == activation_var,\n",
        "                        msg=f\"dropout_action['activation']: {dropout_action.get_var('activation')} != \\nactivation_var: {activation_var}\")\n",
        "        self.assertTrue(dropout_action.get_var('dropout_p') == dropout_p_var,\n",
        "                        msg=f\"dropout_action['dropout_p']: {dropout_action.get_var('dropout_p')} != \\ndropout_p_var: {dropout_p_var}\")\n",
        "\n",
        "    def mock_wrapper_init(self, trial, default_dict, sampler, device):\n",
        "        action = default_dict['action_func']\n",
        "        self.assertIsInstance(action, Action)\n",
        "        self.assertIsNotNone(action.params)\n",
        "        self.assertIsNone(action.action_state)\n",
        "        self.assertIsNotNone(action._model_loader)\n",
        "\n",
        "        # Create the model after checking action is valid\n",
        "        model = action(device=device)\n",
        "        self.assertIsInstance(model, nn.Module)\n",
        "        self.assertEqual(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "        trainer = Mock()\n",
        "        trainer.side_effect = lambda: [param.data.fill_(0) for param in model.parameters()]\n",
        "\n",
        "        execution_set = Mock()\n",
        "        execution_set.yield_execution_set.return_value = (trainer, model)\n",
        "\n",
        "        return execution_set\n",
        "\n",
        "    def produce_saved_bools(self, action_sampler: ActionSampler):\n",
        "        dropout_action = action_sampler.get_action(action_dropout)\n",
        "        default_action = action_sampler.get_action(action_default)\n",
        "        default_saved = default_action.action_state is not None\n",
        "        dropout_saved = dropout_action.action_state is not None\n",
        "\n",
        "        if default_saved:\n",
        "            for param_tensor in default_action.action_state.values():\n",
        "                if param_tensor.numel() > 0:  # Check tensor is not empty\n",
        "                    default_saved &= torch.all(param_tensor == 0).item()\n",
        "        if dropout_saved:\n",
        "            for param_tensor in dropout_action.action_state.values():\n",
        "                if param_tensor.numel() > 0:  # Check tensor is not empty\n",
        "                    dropout_saved &= torch.all(param_tensor == 0).item()\n",
        "        return default_saved, dropout_saved\n",
        "\n",
        "    def test_update_states(self):\n",
        "        param_sets = [\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-2, 'n_epoch': 12},\n",
        "                    {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20},\n",
        "                    {'action_func': action_default, 'rand_number': 3, 'lr': 2e-3, 'n_epoch': 1},\n",
        "                ],\n",
        "                'model_train_window': 1,\n",
        "                'xy': (False, True)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-2, 'n_epoch': 12},\n",
        "                    {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "                    {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20},\n",
        "                    {'action_func': action_default, 'rand_number': 3, 'lr': 2e-3, 'n_epoch': 1},\n",
        "                ],\n",
        "                'model_train_window': 1,\n",
        "                'xy': (True, False)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-2, 'n_epoch': 12},\n",
        "                    {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20},\n",
        "                    {'action_func': action_default, 'rand_number': 3, 'lr': 2e-3, 'n_epoch': 1},\n",
        "                ],\n",
        "                'model_train_window': 2,\n",
        "                'xy': (True, True)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "                    {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20}\n",
        "                ],\n",
        "                'model_train_window': 2,\n",
        "                'xy': (True, True)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "                    {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20}\n",
        "                ],\n",
        "                'model_train_window': 0,\n",
        "                'xy': (False, False)\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        for params in param_sets:\n",
        "            action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "            Wrapper.side_effect = self.mock_wrapper_init\n",
        "            list_params, model_train_window, xy_label = params['params'], params['model_train_window'], params['xy']\n",
        "\n",
        "            action_to_profile = action_sampler.get_action_to_profile(list_params=list_params)\n",
        "            action_sampler.update_vars(action_to_profile)\n",
        "            action_sampler.update_states(action_to_profile, model_train_window, torch.device('cpu'))\n",
        "\n",
        "            xy = self.produce_saved_bools(action_sampler)\n",
        "            self.assertEqual(xy, xy_label)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp90cX_XVmsQ",
        "outputId": "ce18a5db-2097-4f4a-f4cd-a3d0bd269ea8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:37:27,720] A new study created in memory with name: no-name-9057a1a6-28a0-49ab-bf6e-8f49762f06e2\n",
            ".[I 2024-09-27 21:37:27,735] A new study created in memory with name: no-name-af36177c-776c-4d2e-bf17-a0e5e30f0cb9\n",
            ".[I 2024-09-27 21:37:27,745] A new study created in memory with name: no-name-14237fc2-b422-4771-87ea-50238f9fd62f\n",
            ".[I 2024-09-27 21:37:27,774] A new study created in memory with name: no-name-1b8d6390-2e40-49a2-90a8-7797d38980bf\n",
            ".[I 2024-09-27 21:37:27,790] A new study created in memory with name: no-name-6ed84615-5784-49da-8f76-de3a94bad625\n",
            ".[I 2024-09-27 21:37:27,810] A new study created in memory with name: no-name-0a63d515-9810-4304-a002-b6ce1140bf9e\n",
            ".[I 2024-09-27 21:37:27,819] A new study created in memory with name: no-name-e725afb9-03e6-465a-9e8b-bb70fb9aaa30\n",
            ".[I 2024-09-27 21:37:27,872] A new study created in memory with name: no-name-a372b31a-0d9d-4e45-9703-4fbf1e440a45\n",
            ".[I 2024-09-27 21:37:27,887] A new study created in memory with name: no-name-165f3e36-5539-49d1-886c-8bca13624434\n",
            ".[I 2024-09-27 21:37:27,894] A new study created in memory with name: no-name-ace6fa79-46c2-48aa-943a-9df2892e2670\n",
            "[I 2024-09-27 21:37:27,899] A new study created in memory with name: no-name-652db775-6672-4a7b-8a04-a620a994fe9a\n",
            "[I 2024-09-27 21:37:27,906] A new study created in memory with name: no-name-c35d17e5-5444-4699-b761-cdfd6d9edfc1\n",
            ".[I 2024-09-27 21:37:27,914] A new study created in memory with name: no-name-6f0d8dec-85d0-4cdc-8349-5bbe151247e5\n",
            ".[I 2024-09-27 21:37:27,941] A new study created in memory with name: no-name-dc05c9f1-4ef8-49e7-8241-04f0ffb3cb97\n",
            "[I 2024-09-27 21:37:27,950] A new study created in memory with name: no-name-2df7ae82-98f0-4e2b-ab5a-769cc5c719c2\n",
            "[I 2024-09-27 21:37:27,961] A new study created in memory with name: no-name-b25e1cb5-fc8e-4d89-8316-be235d510c3a\n",
            ".[I 2024-09-27 21:37:27,975] A new study created in memory with name: no-name-771713b7-8d83-4327-8109-4b7831987785\n",
            ".[I 2024-09-27 21:37:27,982] A new study created in memory with name: no-name-0c0a2713-0fc7-4519-9d61-4a06d8442c5f\n",
            ".[I 2024-09-27 21:37:28,049] A new study created in memory with name: no-name-700a1dad-769d-42e4-9429-fe73bf5a5f43\n",
            "...........[I 2024-09-27 21:37:28,098] A new study created in memory with name: no-name-60dac276-9d20-45c0-b122-e7137645ef38\n",
            "..[I 2024-09-27 21:37:28,108] A new study created in memory with name: no-name-f80857c4-bb0f-4a88-84d0-9757ee4eb22f\n",
            ".....\n",
            "----------------------------------------------------------------------\n",
            "Ran 32 tests in 0.430s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: TrainSampler"
      ],
      "metadata": {
        "id": "EqVpt_tceM-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainSampler:\n",
        "    def __init__(self, INIT_TRAIN_DICT: dict):\n",
        "        if not all(isinstance(var,Var) for var in INIT_TRAIN_DICT.values()):\n",
        "            raise ValueError(f\"Input dictionary for initializing object 'TrainSampler' has a non-Var value in it. Input dictionary: {INIT_TRAIN_DICT}\")\n",
        "        self.sample_dict = {cat:val for cat,val in INIT_TRAIN_DICT.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_dict)\n",
        "\n",
        "    def __eq__(self, other: TrainSampler):\n",
        "        return isinstance(other, TrainSampler) and self.sample_dict == other.sample_dict\n",
        "\n",
        "    def __str__(self):\n",
        "        output = \"**********TrainSampler**********\\n\"\n",
        "        output += \"\".join([f\"{var}\\n\" for var in self.sample_dict.values()])\n",
        "        return output\n",
        "\n",
        "    def get_var(self, var_type):\n",
        "        if var_type not in self.keys():\n",
        "            raise KeyError(f\"Requested 'var_type': {var_type} is not in train keys: {self.keys()}.\")\n",
        "        return self.sample_dict[var_type]\n",
        "\n",
        "    def keys(self):\n",
        "        return self.sample_dict.keys()\n",
        "\n",
        "    def values(self):\n",
        "        return self.sample_dict.values()\n",
        "\n",
        "    def items(self):\n",
        "        return self.sample_dict.items()\n",
        "\n",
        "    def is_fixed(self):\n",
        "        return all(var.fixed for var in self.values())\n",
        "\n",
        "    def get_evaluated_params(self, source):\n",
        "        if not isinstance(source, (Trial, FrozenTrial, dict)):\n",
        "            raise ValueError(f\"Input 'source' must be of type in (optuna::Trial, optuna::FrozenTrial, dict) but found: {source}\")\n",
        "\n",
        "        source = source if isinstance(source, dict) else source.params\n",
        "\n",
        "        #return source | {var_type:self.get_var(var_type).convert_idx_to_val(source[var_type]) for var_type in self.keys()&source.keys()}\n",
        "        return source | {var_type:self.get_var(var_type).convert_idx_to_val(idx) for var_type,idx in source.items() if var_type in self.keys()}\n",
        "\n",
        "    def sample(self, var_type: str, trial):\n",
        "        if trial is not None and not isinstance(trial, (Trial, FrozenTrial)):\n",
        "            raise ValueError(f\"Input 'trial' should be an instance of optuna::Trial OR optuna::FrozenTrial but found: {trial}\")\n",
        "        if trial is None:\n",
        "            raise ValueError(\"Input 'trial' CANNOT be 'None'. Make sure to throw in optuna::Trial OR optuna::FrozenTrial\")\n",
        "        if var_type not in self.keys():\n",
        "            raise ValueError(f\"Requested var_type: {var_type} does NOT exist in the called TrainSampler!\")\n",
        "\n",
        "        #sampled_val <- value (of category 'var_type') sampled from 'sample_dict' with trial 'trial'.\n",
        "        sampled_val = self.get_var(var_type).sample(trial=trial)\n",
        "\n",
        "        return sampled_val\n",
        "\n",
        "    def update_vars(self, top_k_trials: list):\n",
        "        #Acc over the list of trials for each parameter key.\n",
        "        for key,var in self.items():\n",
        "            var.update(vals=[trial.params[key] for trial in top_k_trials if key in trial.params.keys()])"
      ],
      "metadata": {
        "id": "rIdylV13-qhH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: Sampler"
      ],
      "metadata": {
        "id": "aT-F4CO5z0CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampler:\n",
        "    def __init__(self, INIT_DICT: dict):\n",
        "        #Preprocessing:\n",
        "        init_keys = set(INIT_DICT.keys())\n",
        "        self._sig_keys = set()\n",
        "        INIT_ACTION_DICT = dict()\n",
        "\n",
        "        for action_func in set(INIT_DICT['action_func']['params']['choices']):\n",
        "            sig = set(signature(action_func).parameters.keys()) - {'device'}\n",
        "            leftovers = sig - init_keys\n",
        "            if leftovers:\n",
        "                raise ValueError(f\"Missing keys for parameterizing '{action_func.__name__}': [{leftovers}]. Required keys: {sig}, provided keys: {init_keys}.\")\n",
        "            #INIT_ACTION_DICT[action_func] <- Dictionary of mappings (var_type->Var ) for every var_type in 'sig'.\n",
        "            INIT_ACTION_DICT[action_func] = {var_type:Var(var_type=var_type,source=INIT_DICT[var_type]) for var_type in sig}\n",
        "            #self.sig_keys <- Union(self.action_keys, sig)\n",
        "            self._sig_keys |= sig\n",
        "\n",
        "        #INIT_TRAIN_DICT <- {(var_type->Var )|var_type NOT IN action_keys}\n",
        "        INIT_TRAIN_DICT = {var_type:Var(var_type=var_type,source=INIT_DICT[var_type]) for var_type in init_keys-self._sig_keys}\n",
        "\n",
        "        #train_keys <- all the keys that belong to the TrainSampler's space.\n",
        "        train_keys = set(INIT_TRAIN_DICT.keys())\n",
        "\n",
        "        #Make sure that 'action_func' is in 'INIT_DICT_TRAIN'.\n",
        "        if 'action_func' not in train_keys:\n",
        "            raise ValueError(\"Reconstructed 'INIT_TRAIN_DICT' must have 'action_func' as a valid key but not found.\")\n",
        "\n",
        "        #Declare two Samplers, after pre-processing is done.\n",
        "        self.action_sampler = ActionSampler(INIT_ACTION_DICT=INIT_ACTION_DICT)\n",
        "        self.train_sampler = TrainSampler(INIT_TRAIN_DICT=INIT_TRAIN_DICT)\n",
        "        #Fix the hidden_keys\n",
        "        self._sig_keys = frozenset(self._sig_keys)\n",
        "\n",
        "    def __str__(self):\n",
        "        output = \"Sampler:\\n\"\n",
        "        output += f\"{self.action_sampler}\\n\"\n",
        "        return output + f\"{self.train_sampler}\\n\"\n",
        "\n",
        "    def get_action(self, action_func) -> Action:\n",
        "        action_func_var = self.get_var('action_func')\n",
        "        action_func = action_func_var.convert_idx_to_val(action_func) if isinstance(action_func, int) else action_func\n",
        "        return self.action_sampler.get_action(action_func)\n",
        "\n",
        "    def get_var(self, var_type, sig_var_type=None) -> Var:\n",
        "        #sig_var_type is None <-> var_type in self.train_sampler.keys()\n",
        "        if sig_var_type is None:\n",
        "            return self.train_sampler.get_var(var_type)\n",
        "\n",
        "        action = self.get_action(action_func=var_type)  # Get the associated action\n",
        "        return action.get_var(var_type=sig_var_type)\n",
        "\n",
        "    ###Inherited Methods:\n",
        "    def convert_idx_to_val(self, var_type, sig_var_type_or_idx, idx=None):\n",
        "        if idx is None:\n",
        "            return self.get_var(var_type).convert_idx_to_val(idx=sig_var_type_or_idx)\n",
        "        return self.get_var(var_type, sig_var_type_or_idx).convert_idx_to_val(idx=idx)\n",
        "\n",
        "    def convert_val_to_idx(self, var_type, sig_var_type_or_val, val=None):\n",
        "        if val is None:\n",
        "            return self.get_var(var_type).convert_val_to_idx(val=sig_var_type_or_val)\n",
        "        return self.get_var(var_type, sig_var_type_or_val).convert_val_to_idx(val=val)\n",
        "\n",
        "    def contain_idx(self, var_type, sig_var_type_or_idx, idx=None):\n",
        "        if idx is None:\n",
        "            return self.get_var(var_type).contain_idx(sig_var_type_or_idx)\n",
        "        return self.get_var(var_type, sig_var_type_or_idx).contain_idx(idx)\n",
        "\n",
        "    def contain_val(self, var_type, sig_var_type_or_val, val=None):\n",
        "        if val is None:\n",
        "            return self.get_var(var_type).contain_val(sig_var_type_or_val)\n",
        "        return self.get_var(var_type,sig_var_type_or_val).contain_val(val)\n",
        "    ###Inherited Methods:\n",
        "\n",
        "    def sig_keys(self):\n",
        "        return self._sig_keys\n",
        "\n",
        "    def train_keys(self):\n",
        "        return self.train_sampler.keys()\n",
        "\n",
        "    def action_funcs(self):\n",
        "        return self.action_sampler.keys()\n",
        "\n",
        "    def is_fixed(self):\n",
        "        action_func = self.get_var('action_func').distribution()[0]\n",
        "        action = self.get_action(action_func)\n",
        "        return self.train_sampler.is_fixed() and action.is_fixed()\n",
        "\n",
        "    def sample(self, var_type: str, trial: Trial, default_val = None):\n",
        "        \"\"\"\n",
        "        For the sampling to be done properly, the trial == optuna::Trial\n",
        "        (IF trial==None, THEN default_val will be returned)\n",
        "        \"\"\"\n",
        "        train_keys = self.train_keys()\n",
        "        action_funcs = self.action_funcs()\n",
        "        var = self.get_var(var_type)\n",
        "        valid_trial = trial is not None and isinstance(trial, (Trial, FrozenTrial))\n",
        "        #NOTE: Any 'default_val' that gets passed into Sampler.sample MUST be in its current distribution.\n",
        "        if not valid_trial and not var.contain_val(default_val):\n",
        "            raise ValueError(f\"Var of type: {var_type} CANNOT produce the given 'default_val': {default_val} since its current distribution is: {var.distribution()}\")\n",
        "        if not valid_trial:\n",
        "            #IF NOT valid_trial YET 'default_val' IS in the Var:var_type's distribution,\n",
        "            #THEN return 'default_val'\n",
        "            return default_val\n",
        "\n",
        "        #sampled_val <- sampled value of type: var_type from: self.train_sampler\n",
        "        sampled_val = self.train_sampler.sample(var_type=var_type, trial=trial)\n",
        "        #IF 'sampled_val' is NOT one of the action_func(s), THEN return the sampled result.\n",
        "        if sampled_val not in action_funcs:\n",
        "            return sampled_val\n",
        "        #ELSE, sample from internal action sampler. This will return a fully parameterized Action object.\n",
        "        return self.action_sampler.sample(action_func=sampled_val, trial=trial)\n",
        "\n",
        "    def get_action_to_profile(self, top_k_trials: list):\n",
        "        list_params = [self.train_sampler.get_evaluated_params(source=trial) for trial in top_k_trials]\n",
        "        action_to_profile = self.action_sampler.get_action_to_profile(list_params=list_params)\n",
        "        return action_to_profile\n",
        "\n",
        "    def update(self, top_k_trials: list, model_train_window: int, device: torch.device):\n",
        "        #UPDATE: train_sampler\n",
        "        self.train_sampler.update_vars(top_k_trials=top_k_trials)\n",
        "\n",
        "        #PRODUCE: action_to_profile\n",
        "        #UPDATE: action_sampler Var(s) WITH: action_to_profile\n",
        "        action_to_profile = self.get_action_to_profile(top_k_trials=top_k_trials)\n",
        "        self.action_sampler.update_vars(action_to_profile=action_to_profile)\n",
        "\n",
        "        #UPDATE: action_sampler WITH: action_to_profile\n",
        "        self.action_sampler.update_states(\n",
        "            action_to_profile=action_to_profile,\n",
        "            model_train_window=min(model_train_window, len(action_to_profile)),\n",
        "            device=device\n",
        "        )"
      ],
      "metadata": {
        "id": "3Q2iknmxznF_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test: Sampler\n",
        "\n"
      ],
      "metadata": {
        "id": "YbHQetChF_yV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelDefault(nn.Module):\n",
        "    def __init__(self, rand_number: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Linear(16,10)\n",
        "        self.rand_number = torch.tensor(rand_number)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x) + self.rand_number\n",
        "\n",
        "class ModelDropout(nn.Module):\n",
        "    def __init__(self, activation: nn.Module, dropout_p: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=16,out_features=10),\n",
        "            activation(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "            nn.Linear(in_features=10,out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class ModelDropoutVariant(nn.Module):\n",
        "    \"\"\"\n",
        "    Same parameters as ModelDropout. This model will be used in the test\n",
        "    to check the independence of signature Var(s).\n",
        "    i.e. IF different values were thrown into .update() of ModelDropout VS ModelDropoutVariant,\n",
        "         THEN their signature Var(s), though they have the same var_type, ._frozen_dist, they WILL BE TREATED AS DIFFERENT/INDEPENDENT objects.\n",
        "    \"\"\"\n",
        "    def __init__(self, activation: nn.Module, dropout_p: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=16,out_features=10),\n",
        "            activation(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "            nn.Linear(in_features=10,out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def action_default(rand_number: int, device: torch.device):\n",
        "    return ModelDefault(rand_number=rand_number).to(device)\n",
        "\n",
        "def action_dropout(activation, dropout_p, device: torch.device):\n",
        "    #model_dropout := Class header of 'ModelDropout'\n",
        "    return ModelDropout(activation=activation, dropout_p=dropout_p).to(device)\n",
        "\n",
        "def action_dropout_variant(activation, dropout_p, device: torch.device):\n",
        "    #model_dropout := Class header of 'ModelDropout'\n",
        "    return ModelDropout(activation=activation, dropout_p=dropout_p).to(device)\n",
        "\n",
        "#To be used in the next cell, to imitate the list of frozen optuna.Trial(s).\n",
        "#optimized_study = Mock()"
      ],
      "metadata": {
        "id": "A26isaxcoXe1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestSampler(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.INIT_DICT = {\n",
        "            'action_func': {\n",
        "                'params': {\n",
        "                    'choices': [action_default, action_dropout, action_dropout_variant]\n",
        "                },\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'rand_number': {\n",
        "                'params': {\n",
        "                    'choices': list(range(1, 11))\n",
        "                },\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'activation': {\n",
        "                'params': {\n",
        "                    'choices': [nn.ReLU, nn.PReLU, nn.SiLU]\n",
        "                },\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'dropout_p': {\n",
        "                'params': {\n",
        "                    'low': 0.0,\n",
        "                    'high': 1.0\n",
        "                },\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'lr': {\n",
        "                'params': {\n",
        "                    'low': 1e-4,\n",
        "                    'high': 1e-2,\n",
        "                    'log': True\n",
        "                },\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'wd': {\n",
        "                'params': {\n",
        "                    'low': 1e-4,\n",
        "                    'high': 1e-1,\n",
        "                    'log': True\n",
        "                },\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'batch_size': {\n",
        "                'params': {\n",
        "                    'choices': [32, 64, 128, 256]\n",
        "                },\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'n_epoch': {\n",
        "                'params': {\n",
        "                    'choices': [5, 10, 15]\n",
        "                },\n",
        "                'sample': 'categorical'\n",
        "            }\n",
        "        }\n",
        "        self.trial = optuna.create_study(direction='minimize').ask()\n",
        "\n",
        "    def test_initialization(self):\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "\n",
        "        # Check keys and contents after initialization\n",
        "        self.assertEqual(sampler.sig_keys(), frozenset(['rand_number', 'activation', 'dropout_p']))\n",
        "        self.assertEqual(sampler.action_funcs(), set([action_default, action_dropout, action_dropout_variant]))\n",
        "        self.assertEqual(sampler.train_keys(), set(['action_func', 'lr', 'wd', 'batch_size', 'n_epoch']))\n",
        "\n",
        "        #Check action sampler\n",
        "        expected_action_sampler = self.make_action_sampler(\n",
        "            rand_choices=list(range(1, 11)),\n",
        "            activation_choices=[nn.ReLU, nn.PReLU, nn.SiLU],\n",
        "            dropout_tuple=(0.0, 1.0)\n",
        "        )\n",
        "        self.assertEqual(sampler.action_sampler, expected_action_sampler)\n",
        "\n",
        "        #Check train sampler\n",
        "        expected_train_sampler = self.make_train_sampler(\n",
        "            action_func_choices=[action_default, action_dropout, action_dropout_variant],\n",
        "            lr_tuple=(1e-4, 1e-2),\n",
        "            wd_tuple=(1e-4, 1e-1),\n",
        "            batch_size_choices=[32, 64, 128, 256],\n",
        "            n_epoch_choices=[5, 10, 15]\n",
        "        )\n",
        "        self.assertEqual(sampler.train_sampler, expected_train_sampler)\n",
        "\n",
        "    def test_sample(self):\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        self.assertTrue(sampler.sig_keys() == frozenset(['rand_number', 'activation', 'dropout_p']))\n",
        "        self.assertTrue(sampler.action_funcs() == set([action_default, action_dropout, action_dropout_variant]))\n",
        "        self.assertTrue(sampler.train_keys() == set(['action_func', 'lr', 'wd', 'batch_size', 'n_epoch']))\n",
        "\n",
        "        for key in sampler.sig_keys():\n",
        "            with self.assertRaises(KeyError):\n",
        "                sampler.sample(var_type=key, trial=self.trial, default_val=None)\n",
        "\n",
        "        for key in sampler.train_keys():\n",
        "            with self.assertRaises(ValueError):\n",
        "                #ValueError due to 'default_val' NOT belonging to the distribution of each var_type\n",
        "                sampler.sample(var_type=key, trial=None, default_val=None)\n",
        "            var = sampler.get_var(key)\n",
        "            self.assertIsInstance(var, Var)\n",
        "            self.assertTrue(var.var_type==key)\n",
        "            dist = var.distribution()\n",
        "            default_val = dist['low'] if var.sample_method!='categorical' else random.choices(dist)[0]\n",
        "            self.assertTrue(var.contain_val(default_val),\n",
        "                            msg=f\"default_val: {default_val} NOT in distribution: {dist} of Var: {var.var_type}\")\n",
        "            sampled_val = sampler.sample(var_type=key, trial=None, default_val=default_val)\n",
        "            self.assertEqual(sampled_val, default_val)\n",
        "\n",
        "        for key in sampler.train_keys():\n",
        "            sampled_val = sampler.sample(var_type=key, trial=self.trial, default_val=None)\n",
        "            var = sampler.get_var(key)\n",
        "            self.assertTrue(var.contain_val(sampled_val),\n",
        "                            msg=f\"sampled_val: {sampled_val} NOT in distribution: {var.distribution()}\")\n",
        "\n",
        "    def make_action_sampler(self, rand_choices, activation_choices, dropout_tuple):\n",
        "        INIT_ACTION_DICT = {\n",
        "            'rand_number': Var(var_type='rand_number', source={'params': {'choices': rand_choices}, 'sample': 'categorical'}),\n",
        "            'activation': Var(var_type='activation', source={'params': {'choices': activation_choices}, 'sample': 'categorical'}),\n",
        "            'dropout_p': Var(var_type='dropout_p', source={'params': {'low': dropout_tuple[0], 'high': dropout_tuple[1]}, 'sample': 'float'})\n",
        "        }\n",
        "        action_to_sig = {func: set(signature(func).parameters.keys()) - {'device'} for func in [action_default, action_dropout, action_dropout_variant]}\n",
        "        INIT_ACTION_DICT = {func: {key: INIT_ACTION_DICT[key] for key in sig} for func, sig in action_to_sig.items()}\n",
        "        return ActionSampler(INIT_ACTION_DICT=INIT_ACTION_DICT)\n",
        "\n",
        "    def make_train_sampler(self, action_func_choices, lr_tuple, wd_tuple, batch_size_choices, n_epoch_choices):\n",
        "        INIT_TRAIN_DICT = {\n",
        "            'action_func': Var(var_type='action_func', source={'params': {'choices': action_func_choices}, 'sample': 'categorical'}),\n",
        "            'lr': Var(var_type='lr', source={'params': {'low': lr_tuple[0], 'high': lr_tuple[1], 'log': True}, 'sample': 'float'}),\n",
        "            'wd': Var(var_type='wd', source={'params': {'low': wd_tuple[0], 'high': wd_tuple[1], 'log': True}, 'sample': 'float'}),\n",
        "            'batch_size': Var(var_type='batch_size', source={'params': {'choices': batch_size_choices}, 'sample': 'categorical'}),\n",
        "            'n_epoch': Var(var_type='n_epoch', source={'params': {'choices': n_epoch_choices}, 'sample': 'categorical'})\n",
        "        }\n",
        "        return TrainSampler(INIT_TRAIN_DICT=INIT_TRAIN_DICT)\n",
        "\n",
        "    def mock_wrapper_init(self, trial, default_dict, sampler, device):\n",
        "        action = default_dict['action_func']\n",
        "        model = action(device=device)\n",
        "\n",
        "        self.assertIsInstance(model, nn.Module)\n",
        "        self.assertEqual(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "        #Mock trainer that will update all the parameters to zero\n",
        "        trainer = Mock()\n",
        "        trainer.side_effect = lambda: [param.data.fill_(0) for param in model.parameters()]\n",
        "\n",
        "        #Ensure the model's state dict gets updated with zeros\n",
        "        for param in model.parameters():\n",
        "            param.data.fill_(0)\n",
        "\n",
        "        execution_set = Mock()\n",
        "        execution_set.yield_execution_set.return_value = (trainer, model)\n",
        "\n",
        "        #Return the execution set\n",
        "        return execution_set\n",
        "\n",
        "    def test_update(self):\n",
        "        param_sets = self.construct_mock_trials()\n",
        "        for i,param_set in enumerate(param_sets):\n",
        "            sampler = Sampler(INIT_DICT=self.get_init_dict())\n",
        "            top_k_trials = []\n",
        "            model_train_window = param_set['model_train_window']\n",
        "            distributions = param_set['distributions']\n",
        "            xyz = param_set['xyz']\n",
        "            for params in param_set['params']:\n",
        "                trial = Mock(spec=FrozenTrial)\n",
        "                trial.params = params\n",
        "                top_k_trials.append(trial)\n",
        "            #Mock the wrapper\n",
        "            Wrapper = Mock()\n",
        "            Wrapper.side_effect = self.mock_wrapper_init\n",
        "            sampler.update(top_k_trials=top_k_trials,\n",
        "                           model_train_window=model_train_window,\n",
        "                           device=None)\n",
        "            for var_type in sampler.train_keys():\n",
        "                var = sampler.get_var(var_type)\n",
        "                self.assertEqual(\n",
        "                    var.distribution(), distributions[var_type],\n",
        "                    msg = f\"{i}th param_set: {var.var_type}.distribution(): {var.distribution()} != \\nExpected distribution for {var_type}: {distributions[var_type]}\"\n",
        "                )\n",
        "            for action_func in sampler.action_funcs():\n",
        "                action = sampler.get_action(action_func)\n",
        "                assert isinstance(action, Action), f\"{i}th param_set: action: {action} != An instance of 'Action'\"\n",
        "                for var_type in action.keys():\n",
        "                    var_retrieved_from_sampler = sampler.get_var(action_func, var_type)\n",
        "                    var = action.get_var(var_type)\n",
        "                    self.assertEqual(\n",
        "                        var_retrieved_from_sampler, var,\n",
        "                        msg = f\"{i}th param_set: sampler.get_var(action_func, var_type): {var_retrieved_from_sampler} != \\n action[var_type]: {var}\"\n",
        "                    )\n",
        "                    #Since 'var_type' is from 'action.keys(), it may NOT be in distributions.\n",
        "                    #IF SO, then continue.\n",
        "                    if var_type not in distributions.keys():\n",
        "                        continue\n",
        "                    try:\n",
        "                        distribution = distributions[var_type].get(action_func, None)\n",
        "                    except Exception as e:\n",
        "                        print(f\"distributions: {distributions}, distributions[var_type]: {distributions[var_type]} Exception: {e}\")\n",
        "                    if distribution is None:\n",
        "                        continue\n",
        "                    self.assertEqual(\n",
        "                        var.distribution(), distribution,\n",
        "                        msg = f\"{i}th param_set::{action_func}:: {var.var_type}.distribution(): {var.distribution()} != \\nExpected distribution: {distribution}\"\n",
        "                    )\n",
        "            self.assertEqual(self.produce_saved_bools(sampler), param_set['xyz'])\n",
        "            self.assertEqual(sampler.is_fixed(), param_set.get('fixed', False))\n",
        "\n",
        "    def produce_saved_bools(self, sampler: Sampler):\n",
        "        action_sampler = sampler.action_sampler\n",
        "        default_action = action_sampler.get_action(action_default)\n",
        "        dropout_action = action_sampler.get_action(action_dropout)\n",
        "        dropout_variant_action = action_sampler.get_action(action_dropout_variant)\n",
        "        default_saved = default_action.action_state is not None\n",
        "        dropout_saved = dropout_action.action_state is not None\n",
        "        dropout_variant_saved = dropout_variant_action.action_state is not None\n",
        "\n",
        "        if default_saved:\n",
        "            for param_tensor in default_action.action_state.values():\n",
        "                if param_tensor.numel() > 0:  # Check tensor is not empty\n",
        "                    default_saved &= torch.all(param_tensor == 0).item()\n",
        "        if dropout_saved:\n",
        "            for param_tensor in dropout_action.action_state.values():\n",
        "                if param_tensor.numel() > 0:  # Check tensor is not empty\n",
        "                    dropout_saved &= torch.all(param_tensor == 0).item()\n",
        "\n",
        "        if dropout_variant_saved:\n",
        "            for param_tensor in dropout_variant_action.action_state.values():\n",
        "                if param_tensor.numel() > 0:  # Check tensor is not empty\n",
        "                    dropout_variant_saved &= torch.all(param_tensor == 0).item()\n",
        "\n",
        "        return (default_saved, dropout_saved, dropout_variant_saved)\n",
        "\n",
        "    def construct_mock_trials(self):\n",
        "        #Constructs a list of mock trials based on the provided param_sets structure\n",
        "        param_sets = [\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': 1, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 9, 'wd': 1e-2, 'batch_size': 6},\n",
        "                    {'action_func': 0, 'rand_number': 1, 'lr': 1e-2, 'n_epoch': 11, 'wd': 5e-2, 'batch_size': 7},\n",
        "                    {'action_func': 1, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 13, 'wd': 1e-3, 'batch_size': 5},\n",
        "                    {'action_func': 0, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 19, 'wd': 2e-2, 'batch_size': 8},\n",
        "                    {'action_func': 0, 'rand_number': 3, 'lr': 2e-3, 'n_epoch': 0, 'wd': 4e-2, 'batch_size': 6},\n",
        "                    #Addendum.\n",
        "                    {'action_func': 2, 'activation': 0, 'dropout_p': 0.0, 'lr': 1e-3, 'n_epoch': 13, 'wd': 1e-3, 'batch_size': 5}\n",
        "                ],\n",
        "                'distributions': {\n",
        "                    'action_func': [action_default, action_default, action_default, action_dropout, action_dropout, action_dropout_variant],\n",
        "                    'rand_number': {action_default: [2, 2, 4]},\n",
        "                    'activation': {action_dropout: [nn.PReLU, nn.SiLU], action_dropout_variant: [nn.ReLU]},\n",
        "                    'batch_size': [2 ** exp for exp in [5, 5, 6, 6, 7, 8]],\n",
        "                    'n_epoch': [1, 10, 12, 14, 14, 20],\n",
        "                    'dropout_p': {action_dropout: {'low': 0.123, 'high': 0.78}, action_dropout_variant: {'low': 0.0, 'high': 0.0}},\n",
        "                    'lr': {'low': 1e-9, 'high': 1e-1, 'log': True},\n",
        "                    'wd': {'low': 1e-3, 'high': 5e-2, 'log': True}\n",
        "                },\n",
        "                'model_train_window': 1,\n",
        "                'xyz': (False, True, False)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': 0, 'rand_number': 3, 'lr': 1e-2, 'n_epoch': 11, 'wd': 1e-2, 'batch_size': 0},\n",
        "\n",
        "                    #Addendum\n",
        "                    {'action_func': 2, 'activation': 1, 'dropout_p': 0.13, 'lr': 1e-3, 'n_epoch': 13, 'wd': 3e-2, 'batch_size': 8},\n",
        "\n",
        "                    {'action_func': 1, 'activation': 0, 'dropout_p': 0.012, 'lr': 5e-1, 'n_epoch': 9, 'wd': 1e-1, 'batch_size': 1},\n",
        "                    {'action_func': 1, 'activation': 2, 'dropout_p': 0.13, 'lr': 1e-3, 'n_epoch': 13, 'wd': 3e-2, 'batch_size': 8},\n",
        "                    {'action_func': 0, 'rand_number': 7, 'lr': 1e-3, 'n_epoch': 19, 'wd': 4e-4, 'batch_size': 3},\n",
        "                    {'action_func': 0, 'rand_number': 9, 'lr': 2e-3, 'n_epoch': 4, 'wd': 5e-3, 'batch_size': 4},\n",
        "                ],\n",
        "                'distributions': {\n",
        "                    'action_func': [action_default, action_default, action_default, action_dropout, action_dropout, action_dropout_variant],\n",
        "                    'rand_number': {action_default: [4, 8, 10]},\n",
        "                    'activation': {action_dropout: [nn.ReLU, nn.SiLU], action_dropout_variant: [nn.PReLU]},\n",
        "                    'batch_size': [2 ** exp for exp in [0, 1, 3, 4, 8, 8]],\n",
        "                    'n_epoch': [5, 10, 12, 14, 14, 20],\n",
        "                    'dropout_p': {action_dropout: {'low': 0.012, 'high': 0.13}, action_dropout_variant: {'low': 0.13, 'high': 0.13}},\n",
        "                    'lr': {'low': 1e-3, 'high': 5e-1, 'log': True},\n",
        "                    'wd': {'low': 4e-4, 'high': 1e-1, 'log': True}\n",
        "                },\n",
        "                'model_train_window': 1,\n",
        "                'xyz': (True, False, False)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': 1, 'activation': 0, 'dropout_p': 0.532, 'lr': 3e-1, 'n_epoch': 17, 'wd': 6e-5, 'batch_size': 8},\n",
        "                    {'action_func': 0, 'rand_number': 5, 'lr': 3e-1, 'n_epoch': 17, 'wd': 6e-5, 'batch_size': 8},\n",
        "\n",
        "                    #Addendum\n",
        "                    {'action_func': 2, 'activation': 2, 'dropout_p': 0.532, 'lr': 3e-1, 'n_epoch': 17, 'wd': 6e-5, 'batch_size': 8},\n",
        "\n",
        "                    {'action_func': 1, 'activation': 0, 'dropout_p': 0.532, 'lr': 3e-1, 'n_epoch': 17, 'wd': 6e-5, 'batch_size': 8},\n",
        "                    {'action_func': 0, 'rand_number': 5, 'lr': 3e-1, 'n_epoch': 17, 'wd': 6e-5, 'batch_size': 8},\n",
        "                    {'action_func': 0, 'rand_number': 5, 'lr': 3e-1, 'n_epoch': 17, 'wd': 6e-5, 'batch_size': 8},\n",
        "                ],\n",
        "                'distributions': {\n",
        "                    'action_func': [action_default, action_default, action_default, action_dropout, action_dropout, action_dropout_variant],\n",
        "                    'rand_number': {action_default: [6]},\n",
        "                    'activation': {action_dropout: [nn.ReLU], action_dropout_variant: [nn.SiLU]},\n",
        "                    'batch_size': [2 ** 8],\n",
        "                    'n_epoch': [18],\n",
        "                    'dropout_p': {action_dropout: {'low': 0.532, 'high': 0.532}, action_dropout_variant: {'low': 0.532, 'high': 0.532}},\n",
        "                    'lr': {'low': 3e-1, 'high': 3e-1, 'log': True},\n",
        "                    'wd': {'low': 6e-5, 'high': 6e-5, 'log': True}\n",
        "                },\n",
        "                'model_train_window': 3,\n",
        "                'xyz': (True, True, True)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': 1, 'activation': 1, 'dropout_p': 0.176, 'lr': 1e-1, 'n_epoch': 10, 'wd': 5e-2, 'batch_size': 1},\n",
        "\n",
        "                    #Addendum\n",
        "                    {'action_func': 2, 'activation': 1, 'dropout_p': 0.111, 'lr': 1e-1, 'n_epoch': 10, 'wd': 5e-2, 'batch_size': 1},\n",
        "\n",
        "                    {'action_func': 1, 'activation': 0, 'dropout_p': 0.176, 'lr': 1e-3, 'n_epoch': 14, 'wd': 2e-1, 'batch_size': 2},\n",
        "                    {'action_func': 0, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 19, 'wd': 7e-3, 'batch_size': 3}\n",
        "                ],\n",
        "                'distributions': {\n",
        "                    'action_func': [action_default, action_dropout, action_dropout, action_dropout_variant],\n",
        "                    'rand_number': {action_default: [2]},\n",
        "                    'activation':  {action_dropout: [nn.ReLU, nn.PReLU], action_dropout_variant: [nn.PReLU]},\n",
        "                    'batch_size': [2, 2, 4, 8],\n",
        "                    'n_epoch': [11, 11, 15, 20],\n",
        "                    'dropout_p': {action_dropout: {'low': 0.176, 'high': 0.176}, action_dropout_variant: {'low': 0.111, 'high': 0.111}},\n",
        "                    'lr': {'low': 1e-9, 'high': 1e-1, 'log': True},\n",
        "                    'wd': {'low': 7e-3, 'high': 2e-1, 'log': True}\n",
        "                },\n",
        "                'model_train_window': 2,\n",
        "                'xyz': (False, True, True)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': 1, 'activation': 2, 'dropout_p': 0.85, 'lr': 1e-3, 'n_epoch': 10, 'wd': 1e-4, 'batch_size': 7},\n",
        "                    {'action_func': 1, 'activation': 2, 'dropout_p': 0.85, 'lr': 1e-3, 'n_epoch': 10, 'wd': 1e-4, 'batch_size': 7},\n",
        "                    {'action_func': 1, 'activation': 2, 'dropout_p': 0.85, 'lr': 1e-3, 'n_epoch': 10, 'wd': 1e-4, 'batch_size': 7}\n",
        "                ],\n",
        "                'distributions': {\n",
        "                    'action_func': [action_dropout],\n",
        "                    'activation': {action_dropout: [nn.SiLU]},\n",
        "                    'batch_size': [128],\n",
        "                    'n_epoch': [11],\n",
        "                    'dropout_p': {action_dropout: {'low': 0.85, 'high': 0.85}},\n",
        "                    'lr': {'low': 1e-3, 'high': 1e-3, 'log': True},\n",
        "                    'wd': {'low': 1e-4, 'high': 1e-4, 'log': True}\n",
        "                },\n",
        "                'model_train_window': 100,\n",
        "                'xyz': (False, True, False),\n",
        "                'fixed': True\n",
        "            }\n",
        "        ]\n",
        "        return param_sets\n",
        "\n",
        "    def get_init_dict(self):\n",
        "        action_func_choices = [action_default, action_dropout, action_dropout_variant]\n",
        "        rand_number_choices = list(range(1,11))\n",
        "        activation_choices = [nn.ReLU, nn.PReLU, nn.SiLU]\n",
        "        dropout_p_min = 0.0\n",
        "        dropout_p_max = 1.0\n",
        "        lr_min = 1e-9\n",
        "        lr_max = 5.0\n",
        "        wd_min = 1e-9\n",
        "        wd_max = 1.0\n",
        "        n_epoch_choices = list(range(1,21))\n",
        "        batch_size_choices = [2**exp for exp in range(9)]\n",
        "\n",
        "        # Construct INIT_DICT for each param_set\n",
        "        init_dict = {\n",
        "            'action_func': {\n",
        "                'params': {'choices': action_func_choices},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'rand_number': {\n",
        "                'params': {'choices': rand_number_choices},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'activation': {\n",
        "                'params': {'choices': activation_choices},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'dropout_p': {\n",
        "                'params': {'low': dropout_p_min, 'high': dropout_p_max},\n",
        "                'sample': 'float'\n",
        "             },\n",
        "            'lr': {\n",
        "                'params': {'low': lr_min, 'high': lr_max, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'n_epoch': {\n",
        "                'params': {'choices': n_epoch_choices},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'wd': {\n",
        "                'params': {'low': wd_min, 'high': wd_max, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'batch_size': {\n",
        "                'params': {'choices': batch_size_choices},\n",
        "                'sample': 'categorical'\n",
        "            }\n",
        "        }\n",
        "        return init_dict\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEpP09BT-dRl",
        "outputId": "93730ea5-9f56-4291-a3f1-8cac73c4f30a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:37:28,848] A new study created in memory with name: no-name-3c70d645-bbd1-410f-8dca-135f2768efd5\n",
            ".[I 2024-09-27 21:37:28,878] A new study created in memory with name: no-name-cdeb2f45-e5d1-49bb-a425-69e12310a82b\n",
            ".[I 2024-09-27 21:37:28,899] A new study created in memory with name: no-name-5f552c3c-5f35-48ca-b52d-a6e3e8b38782\n",
            ".[I 2024-09-27 21:37:28,918] A new study created in memory with name: no-name-0c7b7a56-5ceb-40d8-ac24-7039893e4378\n",
            ".[I 2024-09-27 21:37:28,942] A new study created in memory with name: no-name-459b5a67-ac65-402f-86f6-93497b8357ab\n",
            ".[I 2024-09-27 21:37:28,949] A new study created in memory with name: no-name-d03f4ef1-f258-4106-93f2-0ae1bf89edea\n",
            ".[I 2024-09-27 21:37:28,960] A new study created in memory with name: no-name-1e94e4d8-c021-46fc-8449-419e0a7fcdbe\n",
            ".[I 2024-09-27 21:37:29,011] A new study created in memory with name: no-name-e5a8d25d-c2c3-4d77-8063-0cc4de16d6e3\n",
            ".[I 2024-09-27 21:37:29,020] A new study created in memory with name: no-name-6d664f3c-4aff-4cd9-abeb-6a9e1fda4aa6\n",
            ".[I 2024-09-27 21:37:29,031] A new study created in memory with name: no-name-988bb902-8d81-4b38-9b65-9386e89c8732\n",
            "[I 2024-09-27 21:37:29,036] A new study created in memory with name: no-name-eb974276-484d-48f3-bff8-b75838fb0607\n",
            "[I 2024-09-27 21:37:29,041] A new study created in memory with name: no-name-1a94fe00-d055-439e-adbf-4db9287f9764\n",
            ".[I 2024-09-27 21:37:29,058] A new study created in memory with name: no-name-24e29995-a231-4311-825c-50f20e0f8aa4\n",
            ".[I 2024-09-27 21:37:29,066] A new study created in memory with name: no-name-21af4f68-65ec-4105-a7f2-c633e8d30c67\n",
            "[I 2024-09-27 21:37:29,069] A new study created in memory with name: no-name-68707df2-3141-4d0e-8ef4-7b5c400c237c\n",
            "[I 2024-09-27 21:37:29,076] A new study created in memory with name: no-name-d0c9d739-89a1-475e-9e93-5d1d195f9b5b\n",
            ".[I 2024-09-27 21:37:29,108] A new study created in memory with name: no-name-84aa3f9c-c406-4e83-8a10-d074f6c79fbc\n",
            ".[I 2024-09-27 21:37:29,113] A new study created in memory with name: no-name-122866c0-febb-4982-9789-102a4df653d9\n",
            ".[I 2024-09-27 21:37:29,173] A new study created in memory with name: no-name-47c473af-71bb-45a6-a2e9-2ab05be19c73\n",
            ".[I 2024-09-27 21:37:29,188] A new study created in memory with name: no-name-1d3014aa-c888-44da-b59b-6ed6d281f676\n",
            ".[I 2024-09-27 21:37:29,203] A new study created in memory with name: no-name-87e7a49a-2fba-4cd9-b14c-aa7654a4ffaf\n",
            ".[I 2024-09-27 21:37:29,219] A new study created in memory with name: no-name-df1f7cb7-234a-45b8-9d95-532aae7c422d\n",
            "...........[I 2024-09-27 21:37:29,387] A new study created in memory with name: no-name-6b477268-99c0-46be-9139-26642cc67c64\n",
            "..[I 2024-09-27 21:37:29,395] A new study created in memory with name: no-name-04a9b27d-0621-44fc-9b32-9368ec4e05f3\n",
            ".....\n",
            "----------------------------------------------------------------------\n",
            "Ran 35 tests in 0.574s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: Wrapper"
      ],
      "metadata": {
        "id": "lq4j5jcUad_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Wrapper:\n",
        "    def __init__(self, trial, sampler: Sampler, device: torch.device, default_dict: dict = {}):\n",
        "        #Perform general-error checking\n",
        "        self._error_check(trial=trial, sampler=sampler, default_dict=default_dict)\n",
        "\n",
        "        #Initialize all the member variables.\n",
        "        self.trial = trial\n",
        "        self.default_dict = default_dict\n",
        "        self.default_keys = set(default_dict.keys())\n",
        "        self.sampler = sampler\n",
        "        self.train_keys = set(self.sampler.train_keys()) if self.sampler else self.default_keys\n",
        "        self.action_funcs = set(self.sampler.action_funcs()) if self.sampler else set([self.default_dict['action_func'].action_func])\n",
        "        self.sampled_vars = set()\n",
        "        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        #print(\"*************************************************************************************\")\n",
        "        #print(f\"default_dict: {default_dict}\")\n",
        "        #print(\"*************************************************************************************\")\n",
        "\n",
        "    def _error_check(self, trial: Trial, sampler: Sampler, default_dict: dict):\n",
        "        #trial type check:\n",
        "        if trial is not None and not isinstance(trial, (Trial, FrozenTrial)):\n",
        "            raise ValueError(f\"Input 'trial' must either be 'None' or an instance in (optuna::Trial, optuna::FrozenTrial) but found: {trial}\")\n",
        "\n",
        "        #sampler type check:\n",
        "        if sampler is not None and not isinstance(sampler, Sampler):\n",
        "            raise ValueError(f\"Input 'sampler' must either be None of type Sampler but found: {sampler}\")\n",
        "\n",
        "        #Make sure there's something to be sampled:\n",
        "        if not default_dict and not sampler:\n",
        "            raise ValueError(f\"Both default_dict and sampler are empty. Nothing to be sampled.\")\n",
        "\n",
        "        #Make sure that IF 'action_func' exists in 'default_dict',\n",
        "        #               THEN it maps to a properly built & loadable Action object\n",
        "        manual_action = default_dict.get('action_func', None)\n",
        "        manual_action_valid = isinstance(manual_action, Action) and manual_action.is_loadable()\n",
        "        if not sampler and not manual_action:\n",
        "            raise ValueError(\"Input 'sampler' is None but 'action_func' does NOT exist as a key in 'default_dict'. Note that 'action_func' is one parameter required for every Auto-hpo process\")\n",
        "        #IF ('action_func'->obj) exists, THEN check on its value.\n",
        "        if manual_action and not manual_action_valid:\n",
        "            msg = \"which is NOT an Action object\" if not isinstance(manual_action, Action) else \"which is NOT loadable\"\n",
        "            raise ValueError(f\"Input 'default_dict' has 'action_func' as a key but default_dict['action_func']->{manual_action}, {msg}\")\n",
        "\n",
        "    def sample(self, var_type: str, default_val = None):\n",
        "        #ERROR CHECKS\n",
        "        #No double sampling.\n",
        "        var_type_in_default = var_type in self.default_keys\n",
        "        if var_type in self.sampled_vars:\n",
        "            raise ValueError(f\"var_type: {var_type} has already been sampled. Only one sampling per var_type in each trial allowed. Note the following var_type(s) have already been sampled: {self.sampled_vars}\")\n",
        "\n",
        "        sampled_val = None\n",
        "        #IF var_type is in default, THEN sampled_val <- default_dict[var_type]\n",
        "        if var_type in self.default_keys:\n",
        "            sampled_val = self.default_dict[var_type]\n",
        "        elif self.sampler is None or var_type not in self.train_keys:\n",
        "            #IF var_type is NOT in default_dict AND (self.sampler is None OR var_type is NOT in self.sampler),\n",
        "            #THEN sampled_val <- default_val\n",
        "            sampled_val = default_val\n",
        "        else: #All False, THEN sampled_val <- sampled value from self.sampler\n",
        "            sampled_val = self.sampler.sample(var_type=var_type, trial=self.trial, default_val=default_val)\n",
        "\n",
        "        #Add 'var_type' to the set of sampled variables.\n",
        "        self.sampled_vars.add(var_type)\n",
        "\n",
        "        return sampled_val\n",
        "\n",
        "    def yield_execution_set(self):\n",
        "        #Dictionary of (key->default_val) for key among common parameters that appear in 'dls_func'\n",
        "        default_dls_map = {\n",
        "            'batch_size': 64,\n",
        "            'img_size': 224,\n",
        "            'normalize': True,\n",
        "            'summary': True\n",
        "        }\n",
        "        #dls_func <- sampled 'dls_func' from Sampler.\n",
        "        dls_func = self.sample('dls_func')\n",
        "        try:\n",
        "            #dls_sig <- signature parameters of 'dls_func'\n",
        "            dls_sig = set(signature(dls_func).parameters.keys())\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"dls_func: {dls_func}, retrieving the dls_sig from it via 'set(signature(dls_func).parameters.keys())' resulted in the following: {e}\")\n",
        "\n",
        "        #dls <- DataLoaders created from 'dls_func' with sampled signatures\n",
        "        dls = dls_func(\n",
        "            **{key:self.sample(key, default_dls_map[key]) for key in dls_sig}\n",
        "        )\n",
        "\n",
        "        #action <- Action object encapsulating the logic of sampled recipe\n",
        "        action = self.sample('action_func')\n",
        "        #action = self.sample(self.default_dict)\n",
        "        #action_func, action_state <- Useful properties of 'action'.\n",
        "        action_func = action.action_func\n",
        "        action_state = action.action_state\n",
        "        #model <- Model yielded from action. Note it's loaded onto the input 'device'.\n",
        "        model = action(device=self.device)\n",
        "        if not isinstance(model, nn.Module):\n",
        "            raise ValueError(f\"Model generated by Action: {action_func.__name__} must be of type 'nn.Module' but found: {model}\")\n",
        "\n",
        "        loss_func = self.sample('loss_func')\n",
        "        learner = Learner(dls=dls,\n",
        "                          model=model,\n",
        "                          loss_func=loss_func() if isinstance(loss_func, nn.Module) else loss_func,\n",
        "                          #opt_func=self.sample('opt_func'), NOT IMPLEMENTED YET!!!\n",
        "                          metrics=self.sample('metric')\n",
        "                          )\n",
        "\n",
        "        #Sample on whether to freeze the learner or not ONLY WHEN there's no saved 'action_state' for the given action_func\n",
        "        if action_state is None and self.sample('freeze', False):\n",
        "            learner.freeze()\n",
        "        else: #IF (action_state is not None) OR (action_state is None but sampled 'freeze' states False)\n",
        "              #THEN .unfreeze().\n",
        "              learner.unfreeze()\n",
        "\n",
        "        #Barebone cbs list:\n",
        "        cbs = []\n",
        "        #Fill the list:\n",
        "        if self.sample('gradient_clip',False): #Apply Gradient clipping, if exists and is True.\n",
        "            cbs.append(GradientClip(max_norm=self.sample('max_norm', 0.1))) #If exists, then 'max_norm' MUST exist, hence no safety guarantee.\n",
        "        if self.trial is None:\n",
        "            cbs.append(EarlyStoppingCallback(monitor='valid_loss',\n",
        "                                             min_delta=self.sample('min_delta', 0.1),\n",
        "                                             patience=self.sample('patience', 15)))\n",
        "        else: #IF trial is a type of optuna.Trail, then apply PruningCallback.\n",
        "            cbs.append(FastAIPruningCallback(trial=self.trial, monitor='valid_loss'))\n",
        "\n",
        "        #Make the action and return it.\n",
        "        trainer = None\n",
        "        if self.sample('one_cycle', True):\n",
        "            lr_low = self.sample('lr_low', 1e-3)\n",
        "            lr_high = self.sample('lr_high', lr_low)\n",
        "            trainer = partial(learner.fit_one_cycle,\n",
        "                              n_epoch=self.sample('n_epoch', 10),\n",
        "                              lr_max=slice(lr_low, lr_high),\n",
        "                              wd=self.sample('wd', 0.01), pct_start=self.sample('pct_start',0.3),\n",
        "                              cbs=cbs)\n",
        "        else:\n",
        "            trainer = partial(learner.fit,\n",
        "                               n_epoch=self.sample('n_epoch', 10),\n",
        "                               lr=self.sample('lr', 1e-3),\n",
        "                               wd=self.sample('wd', 0.01),\n",
        "                               cbs=cbs)\n",
        "\n",
        "        #Return the execution_set := (trainer, learner)\n",
        "        #NOTE: 'trainer' Executes training on the learer, when called.\n",
        "        return (trainer, learner)"
      ],
      "metadata": {
        "id": "FJE7gRBCagn5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test: Wrapper"
      ],
      "metadata": {
        "id": "xAvWWmAD0HvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class PolynomialDataset(Dataset):\n",
        "    def __init__(self, coeffs: torch.tensor, input_min: float, input_max: float, input_size: int):\n",
        "        #coeffs.shape == [degree+1, 1]\n",
        "        self.coeffs = coeffs.clone().detach()\n",
        "        #inputs.shape == [inputs]\n",
        "        self.inputs = torch.empty(size=(input_size,)).uniform_(input_min, input_max)\n",
        "        #Preprocess the output and retrieve it upon request.\n",
        "        self.outputs = self._f(X=self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.outputs[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.inputs.size(0) != self.outputs.size(0):\n",
        "            return ValueError(f\"len(inputs): {self.inputs.size(0)} != len(outputs): {self.outputs.size(0)}\")\n",
        "        return self.inputs.size(0)\n",
        "\n",
        "    def _f(self, X):\n",
        "        #power.shape == [1, degree+1]\n",
        "        powers = torch.arange(self.coeffs.size(0)).unsqueeze(0)\n",
        "        Y = self.inputs.unsqueeze(-1)**powers\n",
        "        return torch.matmul(Y, self.coeffs).squeeze(-1)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    degree = 6\n",
        "    coeffs_min, coeffs_max = -10.0, 10.0\n",
        "    coeffs = torch.empty(size=(degree+1,)).uniform_(coeffs_min, coeffs_max)\n",
        "\n",
        "    for c in coeffs:\n",
        "        print(f\"c: {c}\")\n",
        "\n",
        "    train_dset = PolynomialDataset(coeffs=coeffs, input_min=-100.0, input_max=100.0, input_size=8000)\n",
        "    valid_dset = PolynomialDataset(coeffs=coeffs, input_min=-300.12, input_max=500.78, input_size=2000)\n",
        "\n",
        "    #Test:\n",
        "    print(f\"Number of elements in Dataset; train_dset: {len(train_dset)}, valid_dset: {len(valid_dset)}\")\n",
        "    print()\n",
        "\n",
        "    print(f\"train first input: {train_dset[0][0]}, train first output: {train_dset[0][1]}\")\n",
        "    print()\n",
        "\n",
        "    print(f\"valid first input: {valid_dset[0][0]}, valid first output: {valid_dset[0][1]}\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6lO0cStOv07",
        "outputId": "c0ed522c-5ff6-46f3-f9ab-9efe29adff00"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c: -4.371528625488281\n",
            "c: -9.356799125671387\n",
            "c: 3.873828649520874\n",
            "c: 0.6507885456085205\n",
            "c: 5.898780822753906\n",
            "c: 3.7403082847595215\n",
            "c: 7.500274181365967\n",
            "Number of elements in Dataset; train_dset: 8000, valid_dset: 2000\n",
            "\n",
            "train first input: 99.92070007324219, train first output: 7502502559744.0\n",
            "\n",
            "valid first input: 256.47650146484375, valid first output: 2139003100856320.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    \"\"\"\n",
        "    Action functions:\n",
        "    \"\"\"\n",
        "    class ModelDefault(nn.Module):\n",
        "        def __init__(self, activation: nn.Module, preprocess: bool, start_neurons: int):\n",
        "            super().__init__()\n",
        "            self.preprocess = preprocess\n",
        "            if self.preprocess: start_neurons = max(start_neurons,degree+1)\n",
        "            self.net = nn.Sequential(\n",
        "                nn.Linear(in_features=degree+1 if self.preprocess else 1,\n",
        "                        out_features=start_neurons),\n",
        "                nn.BatchNorm1d(num_features=start_neurons),\n",
        "                activation(),\n",
        "                nn.Linear(in_features=start_neurons,out_features=start_neurons*2),\n",
        "                nn.BatchNorm1d(num_features=start_neurons*2),\n",
        "                activation(),\n",
        "                nn.Linear(in_features=start_neurons*2,out_features=1)\n",
        "            )\n",
        "\n",
        "        def _preprocess(self, X):\n",
        "            N = X.size(0)\n",
        "            #X <- [64,1]x[1,7] == [64,7], where each index (i,j) yields X[i]**j.\n",
        "            X = X.unsqueeze(-1)**torch.arange(degree+1).unsqueeze(0)\n",
        "            if X.size() != torch.Size([N,degree+1]):\n",
        "                raise ValueError(f\"X.size() MUST be torch.Size([{N},{degree+1}]) but found X.size()=={X.size()}\")\n",
        "            return X\n",
        "\n",
        "        def forward(self, X):\n",
        "            if X.dim() != 1:\n",
        "                X = X.reshape(-1)\n",
        "\n",
        "            if self.preprocess:\n",
        "                X = self._preprocess(X)\n",
        "            else:\n",
        "                X = X.unsqueeze(-1)\n",
        "            return self.net(X)\n",
        "\n",
        "    class ModelDropout(nn.Module):\n",
        "        def __init__(self, activation: nn.Module, dropout_p: int, preprocess: int, start_neurons: Int):\n",
        "            super().__init__()\n",
        "            self.preprocess = preprocess\n",
        "            if self.preprocess: start_neurons = max(start_neurons,degree+1)\n",
        "            self.net = nn.Sequential(\n",
        "                nn.Linear(in_features=degree+1 if self.preprocess else 1,\n",
        "                        out_features=start_neurons),\n",
        "                nn.BatchNorm1d(num_features=start_neurons),\n",
        "                activation(),\n",
        "                nn.Dropout(p=dropout_p),\n",
        "                nn.Linear(in_features=start_neurons,out_features=start_neurons*2),\n",
        "                nn.BatchNorm1d(num_features=start_neurons*2),\n",
        "                activation(),\n",
        "                nn.Linear(in_features=start_neurons*2,out_features=1)\n",
        "            )\n",
        "\n",
        "        def _preprocess(self, X):\n",
        "            N = X.size(0)\n",
        "            #X <- [64,1]x[1,7] == [64,7], where each index (i,j) yields X[i]**j.\n",
        "            X = X.unsqueeze(-1)**torch.arange(degree+1).unsqueeze(0)\n",
        "            if X.size() != torch.Size([N,degree+1]):\n",
        "                raise ValueError(f\"X.size() MUST be torch.Size([{N},{degree+1}]) but found X.size()=={X.size()}\")\n",
        "            return X\n",
        "\n",
        "        def forward(self, X):\n",
        "            if X.dim() != 1:\n",
        "                X = X.reshape(-1)\n",
        "\n",
        "            if self.preprocess:\n",
        "                X = self._preprocess(X)\n",
        "            else:\n",
        "                X = X.unsqueeze(-1)\n",
        "            return self.net(X)\n",
        "\n",
        "    def action_default(activation: nn.Module, preprocess: bool, start_neurons: int, device: torch.device):\n",
        "        if start_neurons < 1:\n",
        "            raise ValueError(f\"start_neurons MUST be a positive integer but found start_neurons: {start_neurons}\")\n",
        "        return ModelDefault(activation=activation,\n",
        "                            preprocess=preprocess,\n",
        "                            start_neurons=start_neurons).to(device)\n",
        "\n",
        "    def action_dropout(activation: nn.Module, dropout_p: int, preprocess: bool, start_neurons: int, device: torch.device):\n",
        "        if start_neurons < 1:\n",
        "            raise ValueError(f\"start_neurons MUST be a positive integer but found start_neurons: {start_neurons}\")\n",
        "        if dropout_p < 0.0 or dropout_p >= 1.0:\n",
        "            raise ValueError(f\"0.0 <= dropout_p < 1.0 required but found dropout_p: {dropout_p}\")\n",
        "        return ModelDropout(activation=activation,\n",
        "                            dropout_p=dropout_p,\n",
        "                            preprocess=preprocess,\n",
        "                            start_neurons=start_neurons).to(device)\n",
        "\n",
        "    #Define DataLoaders and training process\n",
        "    def get_dls(batch_size: int):\n",
        "        train_dataloader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
        "        valid_dataloader = DataLoader(valid_dset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        dls = DataLoaders(train_dataloader, valid_dataloader)\n",
        "        return dls\n",
        "\n",
        "    def custom_mse(Y_hat, Y):\n",
        "        Y_hat = Y_hat.reshape(-1)\n",
        "        Y = Y.reshape(-1)\n",
        "        if Y_hat.size() != Y.size():\n",
        "            raise ValueError(f\"Y_hat.size(): {Y_hat.size()} != Y.size(): {Y.size()}\")\n",
        "        return nn.MSELoss()(Y_hat, Y)"
      ],
      "metadata": {
        "id": "Uh-NmFiBOwf_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestWrapper(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.INIT_DICT = {\n",
        "            'dls_func': {\n",
        "                'params': {'choices': [get_dls]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'freeze': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'lr_low': {\n",
        "                'params': {'low': 1e-7, 'high': 9e-4, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'lr_high': {\n",
        "                'params': {'low': 9e-4, 'high': 1e-1, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'lr': {\n",
        "                'params': {'low': 1e-6, 'high': 1e-1, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'wd': {\n",
        "                'params': {'choices': [1e-4, 1e-3, 1e-2, 1e-1]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'gradient_clip': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'max_norm': {\n",
        "                'params': {'low': 0.0, 'high': 15.0, 'log': False},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'one_cycle': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'pct_start': {\n",
        "                'params': {'low': 0.10, 'high': 0.95,  'log': False, 'step': 0.05},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'n_epoch': {\n",
        "                'params': {'choices': [5, 10, 15]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'action_func': {\n",
        "                'params': {'choices': [action_default, action_dropout]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'activation': {\n",
        "                'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'loss_func': {\n",
        "                'params': {'choices': [custom_mse]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'metric': {\n",
        "                'params': {'choices': [custom_mse]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'preprocess': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'start_neurons': {\n",
        "                'params': {'choices': [1, 2, 4, 8, 16, 32]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'dropout_p': {\n",
        "                'params': {'low': 0.01, 'high': 0.95,  'log': False, 'step': 0.05},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'batch_size': {\n",
        "                'params': {'choices': [1, 2, 4, 8, 16, 32, 64]},\n",
        "                'sample': 'categorical'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.trial = optuna.create_study(direction='minimize').ask()\n",
        "        self.device = torch.device('cpu')\n",
        "\n",
        "    def test_initialization(self):\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        self.assertTrue(set(sampler.sig_keys())==set(['activation', 'dropout_p', 'preprocess', 'start_neurons']),\n",
        "                        msg=f\"sampler.sig_keys(): {set(sampler.sig_keys())}\")\n",
        "        self.assertTrue(set(sampler.train_keys())==set(self.INIT_DICT.keys())-set(['activation', 'dropout_p', 'preprocess', 'start_neurons']),\n",
        "                        msg=f\"sampler.train_keys(): {set(sampler.train_keys())}\")\n",
        "        self.assertTrue(set(sampler.action_funcs())==set([action_default, action_dropout]),\n",
        "                        msg=f\"sampler.action_funcs(): {set(sampler.action_funcs())}\")\n",
        "\n",
        "        sampled_dict = dict()\n",
        "        for key in sampler.train_keys():\n",
        "            sampled_dict[key] = sampler.sample(key, self.trial, default_val=None)\n",
        "\n",
        "        wrapper = Wrapper(trial=self.trial, sampler=sampler, device=self.device, default_dict={})\n",
        "        self.assertTrue(sampled_dict, wrapper.default_dict)\n",
        "\n",
        "    def test_yield_execution_set_trial(self):\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        wrapper = Wrapper(trial=self.trial, sampler=sampler, device=self.device, default_dict={})\n",
        "        trainer, learner = wrapper.yield_execution_set()\n",
        "        trainer()\n",
        "        self.assertIsInstance(learner, Learner)\n",
        "        model = learner.model\n",
        "        self.assertIsInstance(model, nn.Module)\n",
        "        self.assertEqual(model(torch.randn(size=[64,1])).shape, torch.Size([64,1]))\n",
        "\n",
        "    def test_yield_execution_set_frozen_trial(self):\n",
        "        #Create a FrozenTrial with all parameters pre-determined\n",
        "        trial_params = {\n",
        "            'dls_func': get_dls,\n",
        "            'freeze': True,\n",
        "            'lr_low': 1e-6,\n",
        "            'lr_high': 1e-2,\n",
        "            'lr': 1e-3,\n",
        "            'wd': 1e-4,\n",
        "            'gradient_clip': False,\n",
        "            'max_norm': 10.0,\n",
        "            'one_cycle': True,\n",
        "            'pct_start': 0.5,\n",
        "            'n_epoch': 10,\n",
        "            'action_func': action_dropout,\n",
        "            'activation': nn.ReLU,\n",
        "            'loss_func': custom_mse,\n",
        "            'metric': custom_mse,\n",
        "            'preprocess': False,\n",
        "            'start_neurons': 16,\n",
        "            'dropout_p': 0.5,\n",
        "            'batch_size': 64\n",
        "        }\n",
        "        frozen_trial = optuna.trial.FrozenTrial(\n",
        "            number=0,\n",
        "            trial_id=0,\n",
        "            state=optuna.trial.TrialState.COMPLETE,\n",
        "            value=None,\n",
        "            datetime_start=None,\n",
        "            datetime_complete=None,\n",
        "            params=trial_params,\n",
        "            distributions={\n",
        "                'dls_func': optuna.distributions.CategoricalDistribution(choices=[0]),\n",
        "                'freeze': optuna.distributions.CategoricalDistribution(choices=[0, 1]),\n",
        "                'lr_low': optuna.distributions.FloatDistribution(low=1e-7, high=9e-4, log=True),\n",
        "                'lr_high': optuna.distributions.FloatDistribution(low=9e-4, high=1e-1, log=True),\n",
        "                'lr': optuna.distributions.FloatDistribution(low=1e-6, high=1e-1, log=True),\n",
        "                'wd': optuna.distributions.CategoricalDistribution(choices=[0, 1, 2, 3]),\n",
        "                'gradient_clip': optuna.distributions.CategoricalDistribution(choices=[0, 1]),\n",
        "                'max_norm': optuna.distributions.FloatDistribution(low=0.0, high=15.0),\n",
        "                'one_cycle': optuna.distributions.CategoricalDistribution(choices=[0, 1]),\n",
        "                'pct_start': optuna.distributions.FloatDistribution(low=0.10, high=0.95, step=0.05),\n",
        "                'n_epoch': optuna.distributions.CategoricalDistribution(choices=[0,1,2]),\n",
        "                'action_func': optuna.distributions.CategoricalDistribution(choices=[0,1]),\n",
        "                'activation': optuna.distributions.CategoricalDistribution(choices=[0,1,2]),\n",
        "                'loss_func': optuna.distributions.CategoricalDistribution(choices=[0]),\n",
        "                'metric': optuna.distributions.CategoricalDistribution(choices=[0]),\n",
        "                'preprocess': optuna.distributions.CategoricalDistribution(choices=[0, 1]),\n",
        "                'start_neurons': optuna.distributions.CategoricalDistribution(choices=[0,1,2,3,4,5]),\n",
        "                'dropout_p': optuna.distributions.FloatDistribution(low=0.01, high=0.95, step=0.05),\n",
        "                'batch_size': optuna.distributions.CategoricalDistribution(choices=[0])\n",
        "            },\n",
        "            user_attrs={},\n",
        "            system_attrs={},\n",
        "            intermediate_values={}\n",
        "        )\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "\n",
        "        copy_params = dict()\n",
        "        #Change all the actual values in frozen_trial.params to indices(if applicable)\n",
        "        for var_type in set(sampler.train_keys())|sampler.sig_keys():\n",
        "            val = frozen_trial.params[var_type]\n",
        "            if var_type in sampler.sig_keys():\n",
        "                copy_params[var_type] = sampler.convert_val_to_idx(1, var_type, val)\n",
        "                var = sampler.get_var(1, var_type)\n",
        "            else:\n",
        "                copy_params[var_type] = sampler.convert_val_to_idx(var_type, val)\n",
        "                var = sampler.get_var(var_type)\n",
        "                self.assertEqual(\n",
        "                    copy_params[var_type],\n",
        "                    var.convert_val_to_idx(val),\n",
        "                    msg=f\"For Var:{var_type}, {var_type}.distribution: {var.distribution()}, copy_params[{var_type}]: {copy_params[var_type]} != \\n{var_type}.convert_val_to_idx({val}): {var.convert_val_to_idx(val)}\"\n",
        "                )\n",
        "                self.assertEqual(\n",
        "                    val,\n",
        "                    var.convert_idx_to_val(copy_params[var_type]),\n",
        "                    msg=f\"For Var:{var_type}, {var_type}.distribution: {var.distribution(indices=True)}, frozen_trial.params[{var_type}]: {val} != \\n{var_type}.convert_idx_to_val({copy_params[var_type]}): {var.convert_idx_to_val(copy_params[var_type])}\"\n",
        "                )\n",
        "\n",
        "        #Overwrite all the params of frozen_trial\n",
        "        frozen_trial.params |= copy_params\n",
        "\n",
        "        #CHECK: frozen_trial.params ONLY contain values that are either int or float\n",
        "        for var_type,idx in frozen_trial.params.items():\n",
        "            if not isinstance(idx, (int,float)):\n",
        "                raise ValueError(f\"var_type:{var_type}->idx:{idx} BUT type(idx):{type(idx)}!=(int,float)\")\n",
        "\n",
        "        #Initialize the Wrapper with the pre-determined FrozenTrial\n",
        "        wrapper = Wrapper(trial=frozen_trial, sampler=sampler, device=self.device, default_dict={})\n",
        "\n",
        "        #Generate the trainer and learner, and execute the trainer\n",
        "        trainer, learner = wrapper.yield_execution_set()\n",
        "        trainer()\n",
        "\n",
        "        #Verify that the frozen trial parameters are used without modification\n",
        "        self.assertEqual(frozen_trial.params, copy_params, msg=f\"Frozen_trial.params: {frozen_trial.params} != \\n original_frozen_trial_params: {copy_params}\")\n",
        "\n",
        "        #Update sampler with output of frozen trial\n",
        "        sampler.update(top_k_trials=[frozen_trial], model_train_window=1, device=self.device)\n",
        "\n",
        "        #ONLY one action_func shall be available.\n",
        "        action_func_var = sampler.get_var('action_func')\n",
        "        self.assertEqual(action_func_var.distribution(), [action_dropout],\n",
        "                        msg=f\"action_func_var.distribution(): {action_func_var.distribution()} != [action_dropout]\"\n",
        "        )\n",
        "\n",
        "        action = sampler.get_action(action_dropout)\n",
        "        action_compare_to = sampler.get_action(1)\n",
        "        action_compare_to_two = sampler.action_sampler.get_action(action_dropout)\n",
        "        self.assertEqual(action, action_compare_to)\n",
        "        self.assertEqual(action, action_compare_to_two)\n",
        "\n",
        "        #Go through each distribution of each var object, compare it against the value(s) from copy_params\n",
        "        for var_type in sampler.train_keys():\n",
        "            var = sampler.get_var(var_type)\n",
        "            distribution = var.distribution()\n",
        "            compare_to = [var.convert_idx_to_val(copy_params[var_type])] if var.sample_method == 'categorical' else distribution | {'low': copy_params[var_type], 'high': copy_params[var_type]}\n",
        "            self.assertEqual(\n",
        "                distribution,\n",
        "                compare_to,\n",
        "                msg=f\"{var_type}.distribution: {distribution} differs from expected distribution: {compare_to}\"\n",
        "            )\n",
        "\n",
        "        for var_type in action.keys():\n",
        "            var = action.get_var(var_type)\n",
        "            compare_to_var = sampler.get_var(action.action_func, var_type)\n",
        "            self.assertEqual(var, compare_to_var)\n",
        "            distribution = var.distribution()\n",
        "            compare_to = [var.convert_idx_to_val(copy_params[var_type])] if var.sample_method == 'categorical' else distribution | {'low': copy_params[var_type], 'high': copy_params[var_type]}\n",
        "            self.assertEqual(\n",
        "                distribution,\n",
        "                compare_to,\n",
        "                msg=f\"action_func: {action.action_func}::{var_type}.distribution: {distribution} differs from expected distribution: {compare_to}\"\n",
        "            )\n",
        "\n",
        "    def test_initialization_errors(self):\n",
        "        study = optuna.create_study(direction='minimize')\n",
        "\n",
        "        #Error Test Case 1: Invalid trial type\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        with self.assertRaises(ValueError) as context:\n",
        "            Wrapper(trial=\"invalid_trial_type\", sampler=sampler, device=self.device)\n",
        "        self.assertIn(\"Input 'trial' must either be 'None' or an instance in (optuna::Trial, optuna::FrozenTrial)\", str(context.exception),\n",
        "                    msg=str(context.exception))\n",
        "\n",
        "        #Error Test Case 2: Invalid sampler type\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        with self.assertRaises(ValueError) as context:\n",
        "            Wrapper(trial=study.ask(), sampler=\"invalid_sampler_type\", device=self.device)\n",
        "        self.assertIn(\"Input 'sampler' must either be None of type Sampler\", str(context.exception),\n",
        "                    msg=str(context.exception))\n",
        "\n",
        "        #Error Test Case 3: Both default_dict and sampler are empty\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        with self.assertRaises(ValueError) as context:\n",
        "            Wrapper(trial=None, sampler=None, device=self.device, default_dict={})\n",
        "        self.assertIn(\"Both default_dict and sampler are empty. Nothing to be sampled.\", str(context.exception),\n",
        "                    msg=str(context.exception))\n",
        "\n",
        "        #Error Test Case 4: 'action_func' in default_dict is not a valid Action object\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        with self.assertRaises(ValueError) as context:\n",
        "            Wrapper(trial=study.ask(), sampler=sampler, device=self.device, default_dict={'action_func': 'invalid_action'})\n",
        "        self.assertIn(\"Input 'default_dict' has 'action_func' as a key\", str(context.exception),\n",
        "                    msg=str(context.exception))\n",
        "        self.assertIn(\"which is NOT an Action object\", str(context.exception),\n",
        "                    msg=str(context.exception))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "id": "ykSuK-Gi0I6z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "83e6ec92-7377-4fa2-b46c-bb2fa64ab74a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:41:36,969] A new study created in memory with name: no-name-a909559c-4ba6-49b2-8160-1fdf188ba6c2\n",
            ".[I 2024-09-27 21:41:36,986] A new study created in memory with name: no-name-7e5a35ca-4863-4bec-b9d5-b06cc6d1c099\n",
            "[I 2024-09-27 21:41:36,993] A new study created in memory with name: no-name-42216ffd-0343-49e7-82ba-b99fb80a1527\n",
            ".[I 2024-09-27 21:41:37,004] A new study created in memory with name: no-name-06c7bd67-4123-496c-bb62-01e95910ae9e\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:689: UserWarning: The distribution is specified by [0.01, 0.95] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4378513696958552289050624.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4194657881079650705211392.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4257143920786332597616640.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4232131576974263204184064.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4471765447015667893010432.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4216089827159163535360000.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4228602772479037797302272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4225133343441299643039744.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4251674172938101563850752.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4279408564422547722993664.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4123985810459884047564800.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4291826970179044223483904.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4273658656648697225412608.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4311486875905976329830400.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4277494138264148053590016.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4283636615810317182566400.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4306541130881589108015104.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4303046914031501906542592.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4311133793695190482944000.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4206313052800097473003520.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".[I 2024-09-27 21:42:09,549] A new study created in memory with name: no-name-7b09ba62-44e7-4a6b-98f9-828fb7fd0a13\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4362664773265098115383296.000000</td>\n",
              "      <td>740999881643994042711476101185536.000000</td>\n",
              "      <td>740999881643994042711476101185536.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4179488316382786116124672.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4309172385985478084526080.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4432190839909285567135744.000000</td>\n",
              "      <td>740999959015246498047743282380800.000000</td>\n",
              "      <td>740999959015246498047743282380800.000000</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4144926035517682057478144.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 46.112s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: HpoTrainer"
      ],
      "metadata": {
        "id": "Ebi8cz_iT8jS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HpoTrainer:\n",
        "    def __init__(self, sampler: Sampler, n_trials: int, device: torch.device, prev_top_k_trials: list = [],\n",
        "                 pruner: optuna.pruners = None, timeout: int = 14400, eta: int = 2, learner_bar: bool = False, learner_logging: bool = False):\n",
        "        \"\"\"\n",
        "        Class Explanation: HpoTrainer is a TEMPORARY wrapper for running a single HPO process.\n",
        "        \"\"\"\n",
        "        self.sampler = sampler\n",
        "        self.device = device\n",
        "        self.eta = eta\n",
        "        self.timeout = timeout\n",
        "        self.learner_bar = learner_bar\n",
        "        self.learner_logging = learner_logging\n",
        "\n",
        "        #Enqueue ALL the previous_top_k_trials.\n",
        "        #NOTE: This allows the optimizer to efficiently search the new space.\n",
        "        self.prior_trials = prev_top_k_trials\n",
        "\n",
        "        # Use the user-defined n_trials for new trials (ignore the prior trial count)\n",
        "        self.n_trials = n_trials\n",
        "\n",
        "        # Select a pruner if not specified\n",
        "        choices = (optuna.pruners.HyperbandPruner, optuna.pruners.SuccessiveHalvingPruner)\n",
        "        self.pruner = random.choice(choices) if pruner is None else pruner\n",
        "\n",
        "    def run(self):\n",
        "        print(\"*****************RUNNING: HPO PROCESS*****************\")\n",
        "\n",
        "        # To get logging info on the HPO process:\n",
        "        optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
        "\n",
        "        # Create the study object with pruner\n",
        "        study = optuna.create_study(\n",
        "            direction='minimize',\n",
        "            pruner=self.pruner(reduction_factor=self.eta)\n",
        "        )\n",
        "\n",
        "        # Enqueue the prior trials (these will run first)\n",
        "        for trial in self.prior_trials:\n",
        "            study.enqueue_trial(trial.params)\n",
        "\n",
        "        # Run the optimization for the user-defined n_trials (new trials only)\n",
        "        study.optimize(func=self.objective, n_trials=self.n_trials, timeout=self.timeout)\n",
        "\n",
        "        # Return the optimized study\n",
        "        return study\n",
        "\n",
        "    def objective(self, trial):\n",
        "        # Sanity check\n",
        "        if not isinstance(trial, (Trial, FrozenTrial)):\n",
        "            raise ValueError(f\"Input 'trial' MUST be an instance of optuna::Trial OR optuna::FrozenTrial but found trial: {trial}. \"\n",
        "                             f\"NOTE: FrozenTrial is NOT allowed for optimization via HpoTrainer!\")\n",
        "\n",
        "        #Initialize a wrapper with the trial and sampler\n",
        "        sample_wrapper = Wrapper(trial=trial, sampler=self.sampler, device=self.device)\n",
        "\n",
        "        #Unpack the execution set yielded by the 'text_vars'\n",
        "        trainer, learner = sample_wrapper.yield_execution_set()\n",
        "\n",
        "        #Run the trainer with logging and progress bar management\n",
        "        if not self.learner_bar and not self.learner_logging:\n",
        "            with learner.no_bar(), learner.no_logging():\n",
        "                trainer()\n",
        "        elif not self.learner_bar:\n",
        "            with learner.no_bar():\n",
        "                trainer()\n",
        "        elif not self.learner_logging:\n",
        "            with learner.no_logging():\n",
        "                trainer()\n",
        "        else:\n",
        "            trainer()\n",
        "\n",
        "        #Return the validation loss (index 0 of learner.validate())\n",
        "        return learner.validate()[0]"
      ],
      "metadata": {
        "id": "6aLuEwSsLsO_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test: HpoTrainer"
      ],
      "metadata": {
        "id": "npIqWHWz127V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestHpoTrainer(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.INIT_DICT = {\n",
        "            'dls_func': {\n",
        "                'params': {'choices': [get_dls]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'freeze': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'lr_low': {\n",
        "                'params': {'low': 1e-7, 'high': 9e-4, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'lr_high': {\n",
        "                'params': {'low': 9e-4, 'high': 1e-1, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'lr': {\n",
        "                'params': {'low': 1e-6, 'high': 1e-1, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'wd': {\n",
        "                'params': {'choices': [1e-4, 1e-3, 1e-2, 1e-1]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'gradient_clip': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'max_norm': {\n",
        "                'params': {'low': 0.0, 'high': 15.0, 'log': False},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'one_cycle': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'pct_start': {\n",
        "                'params': {'low': 0.10, 'high': 0.95,  'log': False, 'step': 0.05},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'n_epoch': {\n",
        "                'params': {'choices': list(range(1,11))},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'action_func': {\n",
        "                'params': {'choices': [action_default, action_dropout]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'activation': {\n",
        "                'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'loss_func': {\n",
        "                'params': {'choices': [custom_mse]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'metric': {\n",
        "                'params': {'choices': [custom_mse]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'preprocess': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'start_neurons': {\n",
        "                'params': {'choices': [1, 2, 4, 8, 16, 32]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'dropout_p': {\n",
        "                'params': {'low': 0.01, 'high': 0.95,  'log': False, 'step': 0.05},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'batch_size': {\n",
        "                'params': {'choices': [64]},\n",
        "                'sample': 'categorical'\n",
        "            }\n",
        "        }\n",
        "        self.device = torch.device('cpu')\n",
        "\n",
        "    def test_initialization(self):\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        hpo_trainer = HpoTrainer(\n",
        "            sampler = sampler,\n",
        "            n_trials = 2,\n",
        "            device = self.device\n",
        "        )\n",
        "        self.assertIsInstance(hpo_trainer, HpoTrainer)\n",
        "        self.assertIsInstance(hpo_trainer.sampler, Sampler)\n",
        "        self.assertEqual(hpo_trainer.n_trials, 2)\n",
        "        self.assertEqual(hpo_trainer.device, self.device)\n",
        "        self.assertEqual(hpo_trainer.eta, 2)\n",
        "        self.assertEqual(hpo_trainer.timeout, 14400)\n",
        "        self.assertEqual(hpo_trainer.eta, 2)\n",
        "        self.assertEqual(hpo_trainer.learner_bar, False)\n",
        "        self.assertEqual(hpo_trainer.learner_logging, False)\n",
        "\n",
        "    def test_run(self):\n",
        "        n_trials = [4, 2, 1]\n",
        "        top_ks = random.choices(list(range(1,10)), k=len(n_trials))\n",
        "        for n,k in zip(n_trials,top_ks):\n",
        "            sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "            hpo_trainer = HpoTrainer(\n",
        "                sampler = sampler,\n",
        "                n_trials = n,\n",
        "                device = self.device\n",
        "            )\n",
        "            study = hpo_trainer.run()\n",
        "            prev_trials = study.trials\n",
        "            top_k = min(len(prev_trials), k)\n",
        "            top_k_trials = sorted(\n",
        "                prev_trials,\n",
        "                key=lambda trial: trial.value if trial.value is not None else float('inf')\n",
        "            )[:top_k]\n",
        "            sampler.update(\n",
        "                top_k_trials=top_k_trials,\n",
        "                model_train_window=2,\n",
        "                device=self.device\n",
        "        )\n",
        "        print(\"****************************************\")\n",
        "        print(sampler)\n",
        "        print(\"****************************************\")\n",
        "        print()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ezJYciEa17Y8",
        "outputId": "28ccc6ed-f561-405a-d05d-87965ea6d8c3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".[I 2024-09-27 21:42:23,203] A new study created in memory with name: no-name-08479a87-affc-411d-8f77-d30466e06c61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-08479a87-affc-411d-8f77-d30466e06c61\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:689: UserWarning: The distribution is specified by [0.01, 0.95] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:42:25,821] Trial 0 finished with value: 7.409996495302367e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'dropout_p': 0.46, 'start_neurons': 0, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 3, 'lr': 0.01128815872068802, 'wd': 0}. Best is trial 0 with value: 7.409996495302367e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 7.409996495302367e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'dropout_p': 0.46, 'start_neurons': 0, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 3, 'lr': 0.01128815872068802, 'wd': 0}. Best is trial 0 with value: 7.409996495302367e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:42:26,620] Trial 1 finished with value: 7.409997269014891e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 1, 'preprocess': 0, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.2430321419643243e-07, 'lr_high': 0.021416597729128798, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.75}. Best is trial 0 with value: 7.409996495302367e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 finished with value: 7.409997269014891e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 1, 'preprocess': 0, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.2430321419643243e-07, 'lr_high': 0.021416597729128798, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.75}. Best is trial 0 with value: 7.409996495302367e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:42:33,735] Trial 2 finished with value: 7.409997269014891e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'dropout_p': 0.91, 'start_neurons': 5, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 0.0007990061346268746, 'lr_high': 0.0014715271485415168, 'n_epoch': 9, 'wd': 2, 'pct_start': 0.7000000000000001}. Best is trial 0 with value: 7.409996495302367e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 finished with value: 7.409997269014891e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'dropout_p': 0.91, 'start_neurons': 5, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 0.0007990061346268746, 'lr_high': 0.0014715271485415168, 'n_epoch': 9, 'wd': 2, 'pct_start': 0.7000000000000001}. Best is trial 0 with value: 7.409996495302367e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:42:36,380] Trial 3 finished with value: 7.409998042727416e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 3, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 4, 'lr': 0.07818196926676896, 'wd': 1}. Best is trial 0 with value: 7.409996495302367e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 finished with value: 7.409998042727416e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 3, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 4, 'lr': 0.07818196926676896, 'wd': 1}. Best is trial 0 with value: 7.409996495302367e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4290858804345550623735808.000000</td>\n",
              "      <td>740999881643994042711476101185536.000000</td>\n",
              "      <td>740999881643994042711476101185536.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4303752501992321296891904.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4287217590003626049273856.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4231157934763622721912832.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4219934532146651218313216.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:42:39,739] A new study created in memory with name: no-name-a6a7f24a-451d-4b6a-9380-91c1e60dbbf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-a6a7f24a-451d-4b6a-9380-91c1e60dbbf5\n",
            "A new study created in memory with name: no-name-a6a7f24a-451d-4b6a-9380-91c1e60dbbf5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:42:44,498] Trial 0 finished with value: 7.409998042727416e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 0, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 2.493644125316069e-06, 'lr_high': 0.03536015624191447, 'n_epoch': 6, 'wd': 0, 'pct_start': 0.7000000000000001}. Best is trial 0 with value: 7.409998042727416e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 7.409998042727416e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 0, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 2.493644125316069e-06, 'lr_high': 0.03536015624191447, 'n_epoch': 6, 'wd': 0, 'pct_start': 0.7000000000000001}. Best is trial 0 with value: 7.409998042727416e+32.\n",
            "Trial 0 finished with value: 7.409998042727416e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 0, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 2.493644125316069e-06, 'lr_high': 0.03536015624191447, 'n_epoch': 6, 'wd': 0, 'pct_start': 0.7000000000000001}. Best is trial 0 with value: 7.409998042727416e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:42:45,481] Trial 1 finished with value: 7.409997269014891e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 5, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 0, 'lr': 5.843434259914674e-05, 'wd': 3}. Best is trial 1 with value: 7.409997269014891e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 finished with value: 7.409997269014891e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 5, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 0, 'lr': 5.843434259914674e-05, 'wd': 3}. Best is trial 1 with value: 7.409997269014891e+32.\n",
            "Trial 1 finished with value: 7.409997269014891e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 5, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 0, 'lr': 5.843434259914674e-05, 'wd': 3}. Best is trial 1 with value: 7.409997269014891e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4324629316367365930221568.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:42:46,314] A new study created in memory with name: no-name-84f8648d-e7ec-42c8-92fe-555664a3d9e3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-84f8648d-e7ec-42c8-92fe-555664a3d9e3\n",
            "A new study created in memory with name: no-name-84f8648d-e7ec-42c8-92fe-555664a3d9e3\n",
            "A new study created in memory with name: no-name-84f8648d-e7ec-42c8-92fe-555664a3d9e3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:42:52,150] Trial 0 finished with value: 7.409998042727416e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 5, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 0.00024926903473564664, 'lr_high': 0.007835680793606033, 'n_epoch': 9, 'wd': 3, 'pct_start': 0.2}. Best is trial 0 with value: 7.409998042727416e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 7.409998042727416e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 5, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 0.00024926903473564664, 'lr_high': 0.007835680793606033, 'n_epoch': 9, 'wd': 3, 'pct_start': 0.2}. Best is trial 0 with value: 7.409998042727416e+32.\n",
            "Trial 0 finished with value: 7.409998042727416e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 5, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 0.00024926903473564664, 'lr_high': 0.007835680793606033, 'n_epoch': 9, 'wd': 3, 'pct_start': 0.2}. Best is trial 0 with value: 7.409998042727416e+32.\n",
            "Trial 0 finished with value: 7.409998042727416e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 5, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 0.00024926903473564664, 'lr_high': 0.007835680793606033, 'n_epoch': 9, 'wd': 3, 'pct_start': 0.2}. Best is trial 0 with value: 7.409998042727416e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4400005306725928523530240.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4382613485828934236897280.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4243745243520544125485056.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4393443742212834805678080.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4257658700238139554791424.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4337428474450758841925632.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4318518255932197337825280.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4303309491904176115941376.000000</td>\n",
              "      <td>740999881643994042711476101185536.000000</td>\n",
              "      <td>740999881643994042711476101185536.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4255024562830489061163008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4275838254753156469620736.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".[I 2024-09-27 21:43:00,316] A new study created in memory with name: no-name-c9986183-fa66-45aa-aa6c-018501fb426a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************\n",
            "Sampler:\n",
            "**********ActionSampler**********\n",
            "Action of func: action_dropout\n",
            "Signature Vars:\n",
            "Var of type: dropout_p\n",
            "Configuration Space:\n",
            "'low': 0.01, 'high': 0.95, 'log': False, 'step': 0.05\n",
            " Var of type: start_neurons\n",
            "Configuration Space:\n",
            "'choices' = [1, 2, 4, 8, 16, 32]\n",
            " Var of type: preprocess\n",
            "Configuration Space:\n",
            "'choices' = [True, False]\n",
            " Var of type: activation\n",
            "Configuration Space:\n",
            "'choices' = [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.PReLU'>, <class 'torch.nn.modules.activation.SiLU'>]\n",
            "\n",
            "\n",
            "Action of func: action_default\n",
            "Signature Vars:\n",
            "Var of type: start_neurons\n",
            "Configuration Space:\n",
            "'choices' = [32]\n",
            " Var of type: preprocess\n",
            "Configuration Space:\n",
            "'choices' = [False]\n",
            " Var of type: activation\n",
            "Configuration Space:\n",
            "'choices' = [<class 'torch.nn.modules.activation.SiLU'>]\n",
            "\n",
            "Model loader parameters: start_neurons=32 preprocess=False activation=<class 'torch.nn.modules.activation.SiLU'>\n",
            "\n",
            "\n",
            "**********TrainSampler**********\n",
            "Var of type: lr_high\n",
            "Configuration Space:\n",
            "'low': 0.007835680793606033, 'high': 0.007835680793606033, 'log': True, 'step': unspecified\n",
            "\n",
            "Var of type: lr_low\n",
            "Configuration Space:\n",
            "'low': 0.00024926903473564664, 'high': 0.00024926903473564664, 'log': True, 'step': unspecified\n",
            "\n",
            "Var of type: metric\n",
            "Configuration Space:\n",
            "'choices' = [<function custom_mse at 0x7a1038915480>]\n",
            "\n",
            "Var of type: batch_size\n",
            "Configuration Space:\n",
            "'choices' = [64]\n",
            "\n",
            "Var of type: pct_start\n",
            "Configuration Space:\n",
            "'low': 0.2, 'high': 0.2, 'log': False, 'step': 0.05\n",
            "\n",
            "Var of type: n_epoch\n",
            "Configuration Space:\n",
            "'choices' = [10]\n",
            "\n",
            "Var of type: action_func\n",
            "Configuration Space:\n",
            "'choices' = [<function action_default at 0x7a1038914f70>]\n",
            "\n",
            "Var of type: max_norm\n",
            "Configuration Space:\n",
            "'low': 0.0, 'high': 15.0, 'log': False, 'step': unspecified\n",
            "\n",
            "Var of type: lr\n",
            "Configuration Space:\n",
            "'low': 1e-06, 'high': 0.1, 'log': True, 'step': unspecified\n",
            "\n",
            "Var of type: wd\n",
            "Configuration Space:\n",
            "'choices' = [0.1]\n",
            "\n",
            "Var of type: one_cycle\n",
            "Configuration Space:\n",
            "'choices' = [True]\n",
            "\n",
            "Var of type: gradient_clip\n",
            "Configuration Space:\n",
            "'choices' = [False]\n",
            "\n",
            "Var of type: dls_func\n",
            "Configuration Space:\n",
            "'choices' = [<function get_dls at 0x7a10389153f0>]\n",
            "\n",
            "Var of type: freeze\n",
            "Configuration Space:\n",
            "'choices' = [True]\n",
            "\n",
            "Var of type: loss_func\n",
            "Configuration Space:\n",
            "'choices' = [<function custom_mse at 0x7a1038915480>]\n",
            "\n",
            "\n",
            "\n",
            "****************************************\n",
            "\n",
            "A new study created in memory with name: no-name-c9986183-fa66-45aa-aa6c-018501fb426a\n",
            "A new study created in memory with name: no-name-c9986183-fa66-45aa-aa6c-018501fb426a\n",
            "A new study created in memory with name: no-name-c9986183-fa66-45aa-aa6c-018501fb426a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".[I 2024-09-27 21:43:00,332] A new study created in memory with name: no-name-4c2adae9-a8c9-489e-9bf3-b81564fa30ca\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A new study created in memory with name: no-name-4c2adae9-a8c9-489e-9bf3-b81564fa30ca\n",
            "A new study created in memory with name: no-name-4c2adae9-a8c9-489e-9bf3-b81564fa30ca\n",
            "A new study created in memory with name: no-name-4c2adae9-a8c9-489e-9bf3-b81564fa30ca\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 21:43:00,337] A new study created in memory with name: no-name-96f2adc7-5c4d-4c5c-aa64-4d3f4e2ecc91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A new study created in memory with name: no-name-96f2adc7-5c4d-4c5c-aa64-4d3f4e2ecc91\n",
            "A new study created in memory with name: no-name-96f2adc7-5c4d-4c5c-aa64-4d3f4e2ecc91\n",
            "A new study created in memory with name: no-name-96f2adc7-5c4d-4c5c-aa64-4d3f4e2ecc91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".[I 2024-09-27 21:43:00,344] A new study created in memory with name: no-name-70129a53-214d-40da-b5b2-134c42fddb30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A new study created in memory with name: no-name-70129a53-214d-40da-b5b2-134c42fddb30\n",
            "A new study created in memory with name: no-name-70129a53-214d-40da-b5b2-134c42fddb30\n",
            "A new study created in memory with name: no-name-70129a53-214d-40da-b5b2-134c42fddb30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4301971238267703718313984.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4275759567860467052314624.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4275477678552590678228992.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4319638607404299041374208.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4354946252022131426590720.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4152582875460152279957504.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4321506340241762133475328.000000</td>\n",
              "      <td>740999494787731766030140195209216.000000</td>\n",
              "      <td>740999494787731766030140195209216.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4210261232492623620472832.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4126399451629778481709056.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4208542514759630963343360.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4153461689877038849064960.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4237744287089065486974976.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4242977974259228268822528.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4334917699644101280923648.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4377585306916967625523200.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>4385744244174694129860608.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>4278789157344197694455808.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>4200388477418299038105600.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>4283284398290659790815232.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>740999649530236676702674557599744.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>4226241589237602974695424.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>740999804272741587375208919990272.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".[I 2024-09-27 21:43:15,626] A new study created in memory with name: no-name-f7f9f9d2-3cd1-41cd-b5e4-9ee76648b8f9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A new study created in memory with name: no-name-f7f9f9d2-3cd1-41cd-b5e4-9ee76648b8f9\n",
            "A new study created in memory with name: no-name-f7f9f9d2-3cd1-41cd-b5e4-9ee76648b8f9\n",
            "A new study created in memory with name: no-name-f7f9f9d2-3cd1-41cd-b5e4-9ee76648b8f9\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3292479798132599995498496.000000</td>\n",
              "      <td>740999417416479310693873014013952.000000</td>\n",
              "      <td>740999417416479310693873014013952.000000</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4765693849473522826477568.000000</td>\n",
              "      <td>740999959015246498047743282380800.000000</td>\n",
              "      <td>740999959015246498047743282380800.000000</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3987002306581149979246592.000000</td>\n",
              "      <td>740999881643994042711476101185536.000000</td>\n",
              "      <td>740999881643994042711476101185536.000000</td>\n",
              "      <td>00:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3819679961539062884466688.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>740999726901489132038941738795008.000000</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4615235287279320082415616.000000</td>\n",
              "      <td>740999107931469489348804289232896.000000</td>\n",
              "      <td>740999107931469489348804289232896.000000</td>\n",
              "      <td>00:09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 6 tests in 102.172s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ConfigSpace"
      ],
      "metadata": {
        "id": "OThKX2ckhkSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConfigSpace:\n",
        "    def __init__(self, INIT_DICT: dict=None):\n",
        "        \"\"\"\n",
        "        Initialize the hyperparameter configuration.\n",
        "\n",
        "        Parameters:\n",
        "        - INIT_DICT (dict, optional): An initial hyperparameter configuration dictionary.\n",
        "        \"\"\"\n",
        "        if INIT_DICT is not None:\n",
        "            self.config = INIT_DICT.copy()\n",
        "        else:\n",
        "            self.config = {}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.config)\n",
        "\n",
        "    def get_params(self, names):\n",
        "        if isinstance(names, str):\n",
        "            names = [names]\n",
        "        return {name: self.config[name] for name in names}\n",
        "\n",
        "    def set_float(self, name: str, low: float, high: float, *, step=None, log=False):\n",
        "        \"\"\"\n",
        "        Define a float hyperparameter.\n",
        "\n",
        "        Parameters:\n",
        "        - name (str): The name of the hyperparameter.\n",
        "        - low (float): The lower bound of the hyperparameter.\n",
        "        - high (float): The upper bound of the hyperparameter.\n",
        "        - step (float, optional): The step size between values.\n",
        "        - log (bool, optional): Whether to sample the value logarithmically.\n",
        "        \"\"\"\n",
        "        params = {'low': low, 'high': high, 'log': log}\n",
        "        if step is not None:\n",
        "            params['step'] = step\n",
        "\n",
        "        self.config[name] = {\n",
        "            'params': params,\n",
        "            'sample': 'float'\n",
        "        }\n",
        "\n",
        "    def set_int(self, name: str, low: int, high: int, *, step=1, log=False):\n",
        "        \"\"\"\n",
        "        Define an integer hyperparameter.\n",
        "\n",
        "        Parameters:\n",
        "        - name (str): The name of the hyperparameter.\n",
        "        - low (int): The lower bound of the hyperparameter.\n",
        "        - high (int): The upper bound of the hyperparameter.\n",
        "        - step (int, optional): The step size between values.\n",
        "        - log (bool, optional): Whether to sample the value logarithmically.\n",
        "        \"\"\"\n",
        "        params = {'low': low, 'high': high, 'step': step, 'log': log}\n",
        "\n",
        "        self.config[name] = {\n",
        "            'params': params,\n",
        "            'sample': 'int'\n",
        "        }\n",
        "\n",
        "    def set_categorical(self, name: str, choices: list):\n",
        "        \"\"\"\n",
        "        Define a categorical hyperparameter.\n",
        "\n",
        "        Parameters:\n",
        "        - name (str): The name of the hyperparameter.\n",
        "        - choices (list): A list of possible values.\n",
        "        \"\"\"\n",
        "        self.config[name] = {\n",
        "            'params': {'choices': choices},\n",
        "            'sample': 'categorical'\n",
        "        }"
      ],
      "metadata": {
        "id": "1EKFoTGthhPc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: Auto"
      ],
      "metadata": {
        "id": "TbbIOisFWDBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Auto:\n",
        "    def __init__(self, INIT_ARG, storage_dir: str = '/content/trial_storage/'):\n",
        "        if not isinstance(INIT_ARG, (dict, ConfigSpace)):\n",
        "            raise ValueError(f\"Input 'INIT_ARG' must be an instance of (dict, ConfigSpace) but found: {type(INIT_ARG)}\")\n",
        "        INIT_DICT = INIT_ARG.config if isinstance(INIT_ARG, ConfigSpace) else INIT_ARG\n",
        "        self.sampler = Sampler(INIT_DICT=INIT_DICT)\n",
        "        if self.sampler.is_fixed():\n",
        "            raise ValueError(\"Input 'INIT_ARG' is completely determined from the beginning. Nothing to optimize for\")\n",
        "\n",
        "        self.prev_top_k_trials = []\n",
        "        self.storage_dir = storage_dir\n",
        "        os.makedirs(self.storage_dir, exist_ok=True)\n",
        "        self._n_study = None\n",
        "\n",
        "    def optimize(self, n_auto: int, top_k: int, model_train_window: int, device: torch.device):\n",
        "        list_n_trials = self._get_list_n_trials(n_auto=n_auto)\n",
        "        print(\"*****************************************************************\")\n",
        "        print(f\"n_auto: {n_auto}, list_n_trials: {list_n_trials}\")\n",
        "        print()\n",
        "\n",
        "        for idx, n_trials in enumerate(list_n_trials):\n",
        "            hpo_pointer = HpoTrainer(\n",
        "                sampler=self.sampler,\n",
        "                n_trials=n_trials,\n",
        "                device=device,\n",
        "                prev_top_k_trials=self.prev_top_k_trials\n",
        "            )\n",
        "            optimized_study = hpo_pointer.run()\n",
        "            self._update(\n",
        "                idx=idx,\n",
        "                optimized_study=optimized_study,\n",
        "                top_k=top_k,\n",
        "                model_train_window=model_train_window,\n",
        "                device=device\n",
        "            )\n",
        "            self._n_study = len(list_n_trials)\n",
        "\n",
        "    def num_study(self):\n",
        "        return self._n_study\n",
        "\n",
        "    def get_study(self, idx: int):\n",
        "        if self._n_study is None:\n",
        "            raise SyntaxError(\".visualization_trials is requested w/o saved data. Call .optimize() first and once it's finished, request visualization again.\")\n",
        "        if idx < 0 or idx >= self._n_study:\n",
        "            raise ValueError(f\"Input 'idx':{idx} must satisfy 0 <= idx < {self._n_study} but failed.\")\n",
        "\n",
        "        return self._load_study_from_pickle(idx)\n",
        "\n",
        "    def _get_list_n_trials(self, n_auto: int):\n",
        "        \"\"\"\n",
        "        ACCEPTS:\n",
        "        n_auto := Positive integer power of 2. IF n_auto <= 1, THEN n_auto <- 2\n",
        "                                               IF n_auto > 1 but NOT a power of 2, THEN n_auto <- (nearest power of 2) - 1.\n",
        "        RETURNS:\n",
        "        Exponential distribution of [2^m, 2^(m-1), ..., 2^1, 2^0] + (n_auto==power of 2)*[2^0] trials returned.\n",
        "        \"\"\"\n",
        "        n_auto = max(n_auto, 2)\n",
        "        pow2 = n_auto & (n_auto-1) == 0\n",
        "\n",
        "        output = [1<<e for e in range(math.ceil(math.log2(n_auto)) - 1, -1, -1)]\n",
        "\n",
        "        if pow2:\n",
        "            output.append(1)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def _update(self, idx: int, optimized_study: optuna.study, top_k: int, model_train_window: int, device: torch.device):\n",
        "        prev_trials = optimized_study.trials\n",
        "        top_k = min(top_k, len(prev_trials))\n",
        "        model_train_window = min(model_train_window, top_k)\n",
        "\n",
        "        top_k_trials = sorted(prev_trials, key=lambda trial: trial.value if trial.value is not None else float('inf'))[:top_k]\n",
        "\n",
        "        #Save the whole study, not just top_k_trials\n",
        "        self._save_study_to_pickle(idx, optimized_study)\n",
        "        self.prev_top_k_trials = top_k_trials\n",
        "\n",
        "        self.sampler.update(\n",
        "            top_k_trials=top_k_trials,\n",
        "            model_train_window=model_train_window,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "    def _save_study_to_pickle(self, idx: int, study: optuna.study):\n",
        "        save_path = os.path.join(self.storage_dir, f'study_{idx}.pkl')\n",
        "        with gzip.open(save_path, 'wb') as f:\n",
        "            pickle.dump(study, f)\n",
        "        print(f\"Saved study to: {save_path}\")\n",
        "\n",
        "    def _load_study_from_pickle(self, idx: int):\n",
        "        load_path = os.path.join(self.storage_dir, f'study_{idx}.pkl')\n",
        "        if not os.path.exists(load_path):\n",
        "            raise FileNotFoundError(f\"No study found at: {load_path}\")\n",
        "\n",
        "        with gzip.open(load_path, 'rb') as f:\n",
        "            study = pickle.load(f)\n",
        "        print(f\"Loaded study from: {load_path}\")\n",
        "        return study"
      ],
      "metadata": {
        "id": "XuQD5DRKelm0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prep: FINAL_TEST"
      ],
      "metadata": {
        "id": "vDa7V_pjgwS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    from torch.utils.data import Dataset\n",
        "\n",
        "    class PolynomialDataset(Dataset):\n",
        "        def __init__(self, coeffs: torch.tensor, input_min: float, input_max: float, input_size: int):\n",
        "            #coeffs.shape == [degree+1, 1]\n",
        "            self.coeffs = coeffs.clone().detach()\n",
        "            #inputs.shape == [inputs]\n",
        "            self.inputs = torch.empty(size=(input_size,)).uniform_(input_min, input_max)\n",
        "            #Preprocess the output and retrieve it upon request.\n",
        "            self.outputs = self._f(X=self.inputs)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            return self.inputs[idx], self.outputs[idx]\n",
        "\n",
        "        def __len__(self):\n",
        "            if self.inputs.size(0) != self.outputs.size(0):\n",
        "                return ValueError(f\"len(inputs): {self.inputs.size(0)} != len(outputs): {self.outputs.size(0)}\")\n",
        "            return self.inputs.size(0)\n",
        "\n",
        "        def _f(self, X):\n",
        "            #power.shape == [1, degree+1]\n",
        "            powers = torch.arange(self.coeffs.size(0)).unsqueeze(0)\n",
        "            Y = self.inputs.unsqueeze(-1)**powers\n",
        "            return torch.matmul(Y, self.coeffs).squeeze(-1)\n",
        "\n",
        "    degree = 6\n",
        "    coeffs_min, coeffs_max = -10.0, 10.0\n",
        "    coeffs = torch.empty(size=(degree+1,)).uniform_(coeffs_min, coeffs_max)\n",
        "\n",
        "    for c in coeffs:\n",
        "        print(f\"c: {c}\")\n",
        "\n",
        "    train_dset = PolynomialDataset(coeffs=coeffs, input_min=-100.0, input_max=100.0, input_size=8000)\n",
        "    valid_dset = PolynomialDataset(coeffs=coeffs, input_min=-300.12, input_max=500.78, input_size=2000)\n",
        "\n",
        "    #Test:\n",
        "    print(f\"Number of elements in Dataset; train_dset: {len(train_dset)}, valid_dset: {len(valid_dset)}\")\n",
        "    print()\n",
        "\n",
        "    print(f\"train first input: {train_dset[0][0]}, train first output: {train_dset[0][1]}\")\n",
        "    print()\n",
        "\n",
        "    print(f\"valid first input: {valid_dset[0][0]}, valid first output: {valid_dset[0][1]}\")\n",
        "    print()\n",
        "\n",
        "    \"\"\"\n",
        "    Action functions:\n",
        "    \"\"\"\n",
        "    class ModelDefault(nn.Module):\n",
        "        def __init__(self, activation: nn.Module, preprocess: bool, start_neurons: int):\n",
        "            super().__init__()\n",
        "            self.preprocess = preprocess\n",
        "            if self.preprocess: start_neurons = max(start_neurons,degree+1)\n",
        "            self.net = nn.Sequential(\n",
        "                nn.Linear(in_features=degree+1 if self.preprocess else 1,\n",
        "                        out_features=start_neurons),\n",
        "                nn.BatchNorm1d(num_features=start_neurons),\n",
        "                activation(),\n",
        "                nn.Linear(in_features=start_neurons,out_features=start_neurons*2),\n",
        "                nn.BatchNorm1d(num_features=start_neurons*2),\n",
        "                activation(),\n",
        "                nn.Linear(in_features=start_neurons*2,out_features=1)\n",
        "            )\n",
        "\n",
        "        def _preprocess(self, X):\n",
        "            N = X.size(0)\n",
        "            #X <- [64,1]x[1,7] == [64,7], where each index (i,j) yields X[i]**j.\n",
        "            X = X.unsqueeze(-1)**torch.arange(degree+1).unsqueeze(0)\n",
        "            if X.size() != torch.Size([N,degree+1]):\n",
        "                raise ValueError(f\"X.size() MUST be torch.Size([{N},{degree+1}]) but found X.size()=={X.size()}\")\n",
        "            return X\n",
        "\n",
        "        def forward(self, X):\n",
        "            if X.dim() != 1:\n",
        "                raise ValueError(f\"X.dim() MUST be 1 but found X.dim()=={X.dim()}\")\n",
        "\n",
        "            if self.preprocess:\n",
        "                X = self._preprocess(X)\n",
        "            else:\n",
        "                X = X.unsqueeze(-1)\n",
        "            return self.net(X)\n",
        "\n",
        "    class ModelDropout(nn.Module):\n",
        "        def __init__(self, activation: nn.Module, dropout_p: int, preprocess: int, start_neurons: Int):\n",
        "            super().__init__()\n",
        "            self.preprocess = preprocess\n",
        "            if self.preprocess: start_neurons = max(start_neurons,degree+1)\n",
        "            self.net = nn.Sequential(\n",
        "                nn.Linear(in_features=degree+1 if self.preprocess else 1,\n",
        "                        out_features=start_neurons),\n",
        "                nn.BatchNorm1d(num_features=start_neurons),\n",
        "                activation(),\n",
        "                nn.Dropout(p=dropout_p),\n",
        "                nn.Linear(in_features=start_neurons,out_features=start_neurons*2),\n",
        "                nn.BatchNorm1d(num_features=start_neurons*2),\n",
        "                activation(),\n",
        "                nn.Linear(in_features=start_neurons*2,out_features=1)\n",
        "            )\n",
        "\n",
        "        def _preprocess(self, X):\n",
        "            N = X.size(0)\n",
        "            #X <- [64,1]x[1,7] == [64,7], where each index (i,j) yields X[i]**j.\n",
        "            X = X.unsqueeze(-1)**torch.arange(degree+1).unsqueeze(0)\n",
        "            if X.size() != torch.Size([N,degree+1]):\n",
        "                raise ValueError(f\"X.size() MUST be torch.Size([{N},{degree+1}]) but found X.size()=={X.size()}\")\n",
        "            return X\n",
        "\n",
        "        def forward(self, X):\n",
        "            if X.dim() != 1:\n",
        "                raise ValueError(f\"X.dim() MUST be 1 but found X.dim()=={X.dim()}\")\n",
        "\n",
        "            if self.preprocess:\n",
        "                X = self._preprocess(X)\n",
        "            else:\n",
        "                X = X.unsqueeze(-1)\n",
        "            return self.net(X)\n",
        "\n",
        "    def action_default(activation: nn.Module, preprocess: bool, start_neurons: int, device: torch.device):\n",
        "        if start_neurons < 1:\n",
        "            raise ValueError(f\"start_neurons MUST be a positive integer but found start_neurons: {start_neurons}\")\n",
        "        return ModelDefault(activation=activation,\n",
        "                            preprocess=preprocess,\n",
        "                            start_neurons=start_neurons).to(device)\n",
        "\n",
        "    def action_dropout(activation: nn.Module, dropout_p: int, preprocess: bool, start_neurons: int, device: torch.device):\n",
        "        if start_neurons < 1:\n",
        "            raise ValueError(f\"start_neurons MUST be a positive integer but found start_neurons: {start_neurons}\")\n",
        "        if dropout_p < 0.0 or dropout_p >= 1.0:\n",
        "            raise ValueError(f\"0.0 <= dropout_p < 1.0 required but found dropout_p: {dropout_p}\")\n",
        "        return ModelDropout(activation=activation,\n",
        "                            dropout_p=dropout_p,\n",
        "                            preprocess=preprocess,\n",
        "                            start_neurons=start_neurons).to(device)\n",
        "\n",
        "    #Define DataLoaders and training process\n",
        "    def get_dls(batch_size: int):\n",
        "        train_dataloader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
        "        valid_dataloader = DataLoader(valid_dset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        dls = DataLoaders(train_dataloader, valid_dataloader)\n",
        "        return dls\n",
        "\n",
        "    # Now you can use this DataLoaders object with Learner\n",
        "    # Example usage:\n",
        "    train_dls, valid_dls = get_dls(batch_size=64)\n",
        "\n",
        "    print(f\"len(train_dls): {len(train_dls)}\")\n",
        "    print(f\"len(valid_dls): {len(valid_dls)}\")\n",
        "    print()\n",
        "\n",
        "    print(\"*****CHECKING data integrity of returned 'dls'******\")\n",
        "    for blob in iter(train_dls):\n",
        "        if not isinstance(blob, tuple):\n",
        "            raise ValueError(f\"Sampled 'blob' from 'iter(train_dls)' MUST have a type 'tuple' but found: {type(blob)}\")\n",
        "        inputs, outputs = blob\n",
        "        if inputs.size() != outputs.size():\n",
        "            raise ValueError(f\"train_dls contains (inputs,outputs) where inputs.size(): {inputs.size()} != outputs.size(): {outputs.size()}\")\n",
        "\n",
        "    for blob in iter(valid_dls):\n",
        "        if not isinstance(blob, tuple):\n",
        "            raise ValueError(f\"Sampled 'blob' from 'iter(valid_dls)' MUST have a type 'tuple' but found: {type(blob)}\")\n",
        "        inputs, outputs = blob\n",
        "        if inputs.size() != outputs.size():\n",
        "            raise ValueError(f\"valid_dls contains (inputs,outputs) where inputs.size(): {inputs.size()} != outputs.size(): {outputs.size()}\")\n",
        "\n",
        "    inputs, _ = next(iter(train_dls))\n",
        "    print(inputs.size())\n",
        "    inputs, _ = next(iter(valid_dls))\n",
        "    print(inputs.size())\n",
        "\n",
        "    model_default = ModelDefault(activation=nn.ReLU, preprocess=False, start_neurons=7)\n",
        "    model_dropout = ModelDropout(activation=nn.ReLU, dropout_p=0.5, preprocess=False, start_neurons=7)\n",
        "\n",
        "    print(\"*********************model_default*********************\")\n",
        "    print(model_default)\n",
        "    print()\n",
        "    print(\"*********************model_dropout*********************\")\n",
        "    print(model_dropout)\n",
        "    print()\n",
        "\n",
        "    learner = Learner(\n",
        "        dls=get_dls(batch_size=64),\n",
        "        model=ModelDefault(activation=nn.ReLU, preprocess=False, start_neurons=7),\n",
        "        loss_func=custom_mse,\n",
        "        metrics=[custom_mse]\n",
        "    )\n",
        "    learner.fit_one_cycle(n_epoch=10, lr_max=slice(1e-6,1e-3), pct_start=0.3, wd=0.01)"
      ],
      "metadata": {
        "id": "ObeKjyVhLgvX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0054a469-c176-4869-a3a4-bdc3af5cee20"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c: -9.434732437133789\n",
            "c: -6.319784164428711\n",
            "c: -3.426584005355835\n",
            "c: 5.433167457580566\n",
            "c: 5.635682106018066\n",
            "c: 7.37066650390625\n",
            "c: 3.9590811729431152\n",
            "Number of elements in Dataset; train_dset: 8000, valid_dset: 2000\n",
            "\n",
            "train first input: -60.87129211425781, train first output: 195320954880.0\n",
            "\n",
            "valid first input: -150.75328063964844, valid first output: 45901380845568.0\n",
            "\n",
            "len(train_dls): 125\n",
            "len(valid_dls): 32\n",
            "\n",
            "*****CHECKING data integrity of returned 'dls'******\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n",
            "*********************model_default*********************\n",
            "ModelDefault(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=1, out_features=7, bias=True)\n",
            "    (1): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=7, out_features=14, bias=True)\n",
            "    (4): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=14, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "*********************model_dropout*********************\n",
            "ModelDropout(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=1, out_features=7, bias=True)\n",
            "    (1): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=7, out_features=14, bias=True)\n",
            "    (5): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): Linear(in_features=14, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1194567551369037616250880.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1235158819069701067374592.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1198489069751769730383872.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1202638001901285545082880.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1199996946964607410372608.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1185710664255459741925376.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1214767672878472068333568.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1196759255149295232352256.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1188722959916621281361920.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1227454853460730040025088.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    def custom_mse(Y_hat, Y):\n",
        "        Y_hat = Y_hat.reshape(-1)\n",
        "        Y = Y.reshape(-1)\n",
        "        if Y_hat.size() != Y.size():\n",
        "            raise ValueError(f\"Y_hat.size(): {Y_hat.size()} != Y.size(): {Y.size()}\")\n",
        "        return nn.MSELoss()(Y_hat, Y)\n",
        "\n",
        "    INIT_DICT = {\n",
        "        'dls_func': {\n",
        "            'params': {'choices': [get_dls]},\n",
        "            'sample': 'categorical'\n",
        "        },\n",
        "        'freeze': {\n",
        "            'params': {'choices': [True, False]},\n",
        "            'sample': 'categorical'\n",
        "        },\n",
        "        'lr_low': {\n",
        "            'params': {'low': 1e-7, 'high': 9e-4, 'log': True},\n",
        "            'sample': 'float'\n",
        "        },\n",
        "        'lr_high': {\n",
        "            'params': {'low': 9e-4, 'high': 1e-1, 'log': True},\n",
        "            'sample': 'float'\n",
        "        },\n",
        "        'lr': {\n",
        "            'params': {'low': 1e-6, 'high': 1e-1, 'log': True},\n",
        "            'sample': 'float'\n",
        "        },\n",
        "        'wd': {\n",
        "            'params': {'choices': [1e-4, 1e-3, 1e-2, 1e-1]},\n",
        "            'sample': 'categorical'\n",
        "        },\n",
        "        'gradient_clip': {\n",
        "            'params': {'choices': [True, False]},\n",
        "            'sample': 'categorical'\n",
        "        },\n",
        "        'max_norm': {\n",
        "            'params': {'low': 0.0, 'high': 15.0, 'log': False},\n",
        "            'sample': 'float'\n",
        "        },\n",
        "        'one_cycle': {\n",
        "            'params': {'choices': [True, False]},\n",
        "            'sample': 'categorical'\n",
        "        },\n",
        "        'pct_start': {\n",
        "            'params': {'low': 0.10, 'high': 0.95,  'log': False, 'step': 0.05},\n",
        "            'sample': 'float'\n",
        "        },\n",
        "        'n_epoch': {\n",
        "            'params': {'choices': [5, 10, 15]},\n",
        "            'sample': 'categorical'\n",
        "        },\n",
        "        'action_func': {\n",
        "            'params': {'choices': [action_default, action_dropout]},\n",
        "            'sample': 'categorical'\n",
        "        },\n",
        "        'activation': {\n",
        "            'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]},\n",
        "            'sample': 'categorical'\n",
        "        },\n",
        "        'loss_func': {\n",
        "            'params': {'choices': [custom_mse]},\n",
        "            'sample': 'categorical'\n",
        "        },\n",
        "        'metric': {\n",
        "            'params': {'choices': [custom_mse]},\n",
        "            'sample': 'categorical'\n",
        "        },\n",
        "        'preprocess': {\n",
        "            'params': {'choices': [True, False]},\n",
        "            'sample': 'categorical'\n",
        "        },\n",
        "        'start_neurons': {\n",
        "            'params': {'choices': [1, 2, 4, 8, 16, 32,]},\n",
        "            'sample': 'categorical'\n",
        "        },\n",
        "        'dropout_p': {\n",
        "            'params': {'low': 0.05, 'high': 0.95,  'log': False, 'step': 0.05},\n",
        "            'sample': 'float'\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'params': {'choices': [32, 64, 128]},\n",
        "            'sample': 'categorical'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    config = ConfigSpace(INIT_DICT=INIT_DICT)"
      ],
      "metadata": {
        "id": "xsIcM8kI8eWc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FINAL_TEST"
      ],
      "metadata": {
        "id": "jDCVotsAbqxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    auto = Auto(INIT_ARG=config)\n",
        "    auto.optimize(n_auto=10, top_k=2, model_train_window=2, device=torch.device('cpu'))\n",
        "\n",
        "    #Print out the optimized sampler.\n",
        "    print()\n",
        "    print(\"*****************************************************************\")\n",
        "    print()\n",
        "    print(auto.sampler)\n",
        "    print()\n",
        "    print(\"*****************************************************************\")\n",
        "    print()\n",
        "\n",
        "    #TEST: Optuna's visualization capabilities\n",
        "    print(auto.num_study())\n",
        "    study = auto.get_study(2)\n",
        "    #One can now perform all the optuna visualizations as one sees fit\n",
        "    optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "id": "7bBSlC_p-gIR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dbdd44a4-1081-40dd-cf6f-d3e765d42b28"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:04,851] A new study created in memory with name: no-name-d5bd08df-2137-4aba-94b3-f483e2ba54e8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************************************************************\n",
            "n_auto: 10, list_n_trials: [8, 4, 2, 1]\n",
            "\n",
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-d5bd08df-2137-4aba-94b3-f483e2ba54e8\n",
            "A new study created in memory with name: no-name-d5bd08df-2137-4aba-94b3-f483e2ba54e8\n",
            "A new study created in memory with name: no-name-d5bd08df-2137-4aba-94b3-f483e2ba54e8\n",
            "A new study created in memory with name: no-name-d5bd08df-2137-4aba-94b3-f483e2ba54e8\n",
            "A new study created in memory with name: no-name-d5bd08df-2137-4aba-94b3-f483e2ba54e8\n",
            "A new study created in memory with name: no-name-d5bd08df-2137-4aba-94b3-f483e2ba54e8\n",
            "A new study created in memory with name: no-name-d5bd08df-2137-4aba-94b3-f483e2ba54e8\n",
            "A new study created in memory with name: no-name-d5bd08df-2137-4aba-94b3-f483e2ba54e8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:09,317] Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 1, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 1, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 1, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 1, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 1, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 1, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 1, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 1, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 1, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:18,141] Trial 1 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 2, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 3.8670344240117567, 'one_cycle': 1, 'n_epoch': 2, 'lr': 0.0051711553180824035, 'wd': 2}. Best is trial 0 with value: 2.0231069909084932e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 2, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 3.8670344240117567, 'one_cycle': 1, 'n_epoch': 2, 'lr': 0.0051711553180824035, 'wd': 2}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 2, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 3.8670344240117567, 'one_cycle': 1, 'n_epoch': 2, 'lr': 0.0051711553180824035, 'wd': 2}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 2, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 3.8670344240117567, 'one_cycle': 1, 'n_epoch': 2, 'lr': 0.0051711553180824035, 'wd': 2}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 2, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 3.8670344240117567, 'one_cycle': 1, 'n_epoch': 2, 'lr': 0.0051711553180824035, 'wd': 2}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 2, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 3.8670344240117567, 'one_cycle': 1, 'n_epoch': 2, 'lr': 0.0051711553180824035, 'wd': 2}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 2, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 3.8670344240117567, 'one_cycle': 1, 'n_epoch': 2, 'lr': 0.0051711553180824035, 'wd': 2}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 2, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 3.8670344240117567, 'one_cycle': 1, 'n_epoch': 2, 'lr': 0.0051711553180824035, 'wd': 2}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 2, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 3.8670344240117567, 'one_cycle': 1, 'n_epoch': 2, 'lr': 0.0051711553180824035, 'wd': 2}. Best is trial 0 with value: 2.0231069909084932e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:25,110] Trial 2 finished with value: 2.023106604052231e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 2 with value: 2.023106604052231e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 finished with value: 2.023106604052231e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 2 finished with value: 2.023106604052231e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 2 finished with value: 2.023106604052231e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 2 finished with value: 2.023106604052231e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 2 finished with value: 2.023106604052231e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 2 finished with value: 2.023106604052231e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 2 finished with value: 2.023106604052231e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 2 finished with value: 2.023106604052231e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 2 with value: 2.023106604052231e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:30,115] Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.8500000000000001, 'start_neurons': 0, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.02952912436411788, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.8500000000000001, 'start_neurons': 0, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.02952912436411788, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.8500000000000001, 'start_neurons': 0, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.02952912436411788, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.8500000000000001, 'start_neurons': 0, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.02952912436411788, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.8500000000000001, 'start_neurons': 0, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.02952912436411788, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.8500000000000001, 'start_neurons': 0, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.02952912436411788, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.8500000000000001, 'start_neurons': 0, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.02952912436411788, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.8500000000000001, 'start_neurons': 0, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.02952912436411788, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.8500000000000001, 'start_neurons': 0, 'preprocess': 0, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.02952912436411788, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:32,084] Trial 4 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.05, 'start_neurons': 0, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.983798511504245, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0008316530762848041, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 4 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.05, 'start_neurons': 0, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.983798511504245, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0008316530762848041, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 4 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.05, 'start_neurons': 0, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.983798511504245, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0008316530762848041, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 4 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.05, 'start_neurons': 0, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.983798511504245, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0008316530762848041, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 4 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.05, 'start_neurons': 0, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.983798511504245, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0008316530762848041, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 4 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.05, 'start_neurons': 0, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.983798511504245, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0008316530762848041, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 4 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.05, 'start_neurons': 0, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.983798511504245, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0008316530762848041, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 4 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.05, 'start_neurons': 0, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.983798511504245, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0008316530762848041, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 4 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.05, 'start_neurons': 0, 'preprocess': 1, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.983798511504245, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0008316530762848041, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:34,031] Trial 5 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.95, 'start_neurons': 4, 'preprocess': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 7.439720950483327e-06, 'lr_high': 0.06563550658528035, 'n_epoch': 2, 'wd': 2, 'pct_start': 0.5}. Best is trial 2 with value: 2.023106604052231e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.95, 'start_neurons': 4, 'preprocess': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 7.439720950483327e-06, 'lr_high': 0.06563550658528035, 'n_epoch': 2, 'wd': 2, 'pct_start': 0.5}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 5 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.95, 'start_neurons': 4, 'preprocess': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 7.439720950483327e-06, 'lr_high': 0.06563550658528035, 'n_epoch': 2, 'wd': 2, 'pct_start': 0.5}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 5 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.95, 'start_neurons': 4, 'preprocess': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 7.439720950483327e-06, 'lr_high': 0.06563550658528035, 'n_epoch': 2, 'wd': 2, 'pct_start': 0.5}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 5 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.95, 'start_neurons': 4, 'preprocess': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 7.439720950483327e-06, 'lr_high': 0.06563550658528035, 'n_epoch': 2, 'wd': 2, 'pct_start': 0.5}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 5 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.95, 'start_neurons': 4, 'preprocess': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 7.439720950483327e-06, 'lr_high': 0.06563550658528035, 'n_epoch': 2, 'wd': 2, 'pct_start': 0.5}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 5 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.95, 'start_neurons': 4, 'preprocess': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 7.439720950483327e-06, 'lr_high': 0.06563550658528035, 'n_epoch': 2, 'wd': 2, 'pct_start': 0.5}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 5 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.95, 'start_neurons': 4, 'preprocess': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 7.439720950483327e-06, 'lr_high': 0.06563550658528035, 'n_epoch': 2, 'wd': 2, 'pct_start': 0.5}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 5 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'dropout_p': 0.95, 'start_neurons': 4, 'preprocess': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 7.439720950483327e-06, 'lr_high': 0.06563550658528035, 'n_epoch': 2, 'wd': 2, 'pct_start': 0.5}. Best is trial 2 with value: 2.023106604052231e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:35,855] Trial 6 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 1.3418474070416664e-05, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 6 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 1.3418474070416664e-05, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 6 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 1.3418474070416664e-05, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 6 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 1.3418474070416664e-05, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 6 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 1.3418474070416664e-05, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 6 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 1.3418474070416664e-05, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 6 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 1.3418474070416664e-05, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 6 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 1.3418474070416664e-05, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 6 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'start_neurons': 4, 'preprocess': 1, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 1.3418474070416664e-05, 'wd': 2}. Best is trial 2 with value: 2.023106604052231e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:39,677] Trial 7 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.55, 'start_neurons': 4, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 0.00014081499058995754, 'wd': 0}. Best is trial 2 with value: 2.023106604052231e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 7 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.55, 'start_neurons': 4, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 0.00014081499058995754, 'wd': 0}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 7 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.55, 'start_neurons': 4, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 0.00014081499058995754, 'wd': 0}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 7 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.55, 'start_neurons': 4, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 0.00014081499058995754, 'wd': 0}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 7 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.55, 'start_neurons': 4, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 0.00014081499058995754, 'wd': 0}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 7 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.55, 'start_neurons': 4, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 0.00014081499058995754, 'wd': 0}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 7 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.55, 'start_neurons': 4, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 0.00014081499058995754, 'wd': 0}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 7 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.55, 'start_neurons': 4, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 0.00014081499058995754, 'wd': 0}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Trial 7 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'dropout_p': 0.55, 'start_neurons': 4, 'preprocess': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 0.00014081499058995754, 'wd': 0}. Best is trial 2 with value: 2.023106604052231e+32.\n",
            "Saved study to: /content/trial_storage/study_0.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1179917377809998411726848.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1261299873034780563996672.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1255847419009118632935424.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1222638379760046860926976.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1173846453454708945190912.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:46,791] A new study created in memory with name: no-name-91835f33-58b3-4805-a50c-f5e7ec2edc20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-91835f33-58b3-4805-a50c-f5e7ec2edc20\n",
            "A new study created in memory with name: no-name-91835f33-58b3-4805-a50c-f5e7ec2edc20\n",
            "A new study created in memory with name: no-name-91835f33-58b3-4805-a50c-f5e7ec2edc20\n",
            "A new study created in memory with name: no-name-91835f33-58b3-4805-a50c-f5e7ec2edc20\n",
            "A new study created in memory with name: no-name-91835f33-58b3-4805-a50c-f5e7ec2edc20\n",
            "A new study created in memory with name: no-name-91835f33-58b3-4805-a50c-f5e7ec2edc20\n",
            "A new study created in memory with name: no-name-91835f33-58b3-4805-a50c-f5e7ec2edc20\n",
            "A new study created in memory with name: no-name-91835f33-58b3-4805-a50c-f5e7ec2edc20\n",
            "A new study created in memory with name: no-name-91835f33-58b3-4805-a50c-f5e7ec2edc20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:53,411] Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:56,654] Trial 1 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 1 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 1 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 1 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 1 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 1 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 1 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 1 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 1 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.091289544526283, 'one_cycle': 1, 'n_epoch': 0, 'lr': 4.195944382743136e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:26:58,714] Trial 2 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.158807870207538, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.00011457488857181809, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.158807870207538, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.00011457488857181809, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 2 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.158807870207538, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.00011457488857181809, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 2 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.158807870207538, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.00011457488857181809, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 2 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.158807870207538, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.00011457488857181809, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 2 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.158807870207538, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.00011457488857181809, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 2 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.158807870207538, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.00011457488857181809, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 2 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.158807870207538, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.00011457488857181809, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 2 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.158807870207538, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.00011457488857181809, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 2 finished with value: 2.0231075711928866e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.158807870207538, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.00011457488857181809, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:27:00,998] Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 3 with value: 2.0231071843366243e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 3 with value: 2.0231071843366243e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 3 with value: 2.0231071843366243e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 3 with value: 2.0231071843366243e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 3 with value: 2.0231071843366243e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 3 with value: 2.0231071843366243e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 3 with value: 2.0231071843366243e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 3 with value: 2.0231071843366243e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 3 with value: 2.0231071843366243e+32.\n",
            "Trial 3 finished with value: 2.0231071843366243e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 3 with value: 2.0231071843366243e+32.\n",
            "Saved study to: /content/trial_storage/study_1.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1158272501540103504527360.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1200398379820992706904064.000000</td>\n",
              "      <td>202310757119288661940792077582336.000000</td>\n",
              "      <td>202310757119288661940792077582336.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1190741797528781908344832.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1212050957468054109290496.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1209210591226267065909248.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:27:10,553] A new study created in memory with name: no-name-92368bf4-be6b-4c31-a013-49b12b1762e4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-92368bf4-be6b-4c31-a013-49b12b1762e4\n",
            "A new study created in memory with name: no-name-92368bf4-be6b-4c31-a013-49b12b1762e4\n",
            "A new study created in memory with name: no-name-92368bf4-be6b-4c31-a013-49b12b1762e4\n",
            "A new study created in memory with name: no-name-92368bf4-be6b-4c31-a013-49b12b1762e4\n",
            "A new study created in memory with name: no-name-92368bf4-be6b-4c31-a013-49b12b1762e4\n",
            "A new study created in memory with name: no-name-92368bf4-be6b-4c31-a013-49b12b1762e4\n",
            "A new study created in memory with name: no-name-92368bf4-be6b-4c31-a013-49b12b1762e4\n",
            "A new study created in memory with name: no-name-92368bf4-be6b-4c31-a013-49b12b1762e4\n",
            "A new study created in memory with name: no-name-92368bf4-be6b-4c31-a013-49b12b1762e4\n",
            "A new study created in memory with name: no-name-92368bf4-be6b-4c31-a013-49b12b1762e4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:27:16,343] Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 0 finished with value: 2.0231069909084932e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:27:24,290] Trial 1 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Trial 1 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 13.165246844741375, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.0014583219489116535, 'wd': 3}. Best is trial 0 with value: 2.0231069909084932e+32.\n",
            "Saved study to: /content/trial_storage/study_2.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1170874654161396721254400.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1225039338793390619754496.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1244437963684341199405056.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1197863970123490705539072.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1213790716018505841377280.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:27:28,777] A new study created in memory with name: no-name-8fcc33fc-a634-4d93-bba6-6d9ccf551209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-8fcc33fc-a634-4d93-bba6-6d9ccf551209\n",
            "A new study created in memory with name: no-name-8fcc33fc-a634-4d93-bba6-6d9ccf551209\n",
            "A new study created in memory with name: no-name-8fcc33fc-a634-4d93-bba6-6d9ccf551209\n",
            "A new study created in memory with name: no-name-8fcc33fc-a634-4d93-bba6-6d9ccf551209\n",
            "A new study created in memory with name: no-name-8fcc33fc-a634-4d93-bba6-6d9ccf551209\n",
            "A new study created in memory with name: no-name-8fcc33fc-a634-4d93-bba6-6d9ccf551209\n",
            "A new study created in memory with name: no-name-8fcc33fc-a634-4d93-bba6-6d9ccf551209\n",
            "A new study created in memory with name: no-name-8fcc33fc-a634-4d93-bba6-6d9ccf551209\n",
            "A new study created in memory with name: no-name-8fcc33fc-a634-4d93-bba6-6d9ccf551209\n",
            "A new study created in memory with name: no-name-8fcc33fc-a634-4d93-bba6-6d9ccf551209\n",
            "A new study created in memory with name: no-name-8fcc33fc-a634-4d93-bba6-6d9ccf551209\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-27 22:27:32,904] Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Trial 0 finished with value: 2.0231073777647555e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 0, 'max_norm': 12.626330626734708, 'one_cycle': 1, 'n_epoch': 0, 'lr': 7.357972600141196e-06, 'wd': 3}. Best is trial 0 with value: 2.0231073777647555e+32.\n",
            "Saved study to: /content/trial_storage/study_3.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1246505728402853579456512.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1189930212847132726001664.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>202310737776475548106725282283520.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1211811870371036264398848.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>202310718433662434272658486984704.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1231222745052973291798528.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1216624452961641395388416.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>202310699090849320438591691685888.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*****************************************************************\n",
            "\n",
            "Sampler:\n",
            "**********ActionSampler**********\n",
            "Action of func: action_dropout\n",
            "Signature Vars:\n",
            "Var of type: dropout_p\n",
            "Configuration Space:\n",
            "'low': 0.05, 'high': 0.95, 'log': False, 'step': 0.05\n",
            " Var of type: start_neurons\n",
            "Configuration Space:\n",
            "'choices' = [1, 2, 4, 8, 16, 32]\n",
            " Var of type: preprocess\n",
            "Configuration Space:\n",
            "'choices' = [True, False]\n",
            " Var of type: activation\n",
            "Configuration Space:\n",
            "'choices' = [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.PReLU'>, <class 'torch.nn.modules.activation.SiLU'>]\n",
            "\n",
            "Model loader parameters: dropout_p=0.55 start_neurons=16 preprocess=False activation=<class 'torch.nn.modules.activation.ReLU'>\n",
            "\n",
            "Action of func: action_default\n",
            "Signature Vars:\n",
            "Var of type: start_neurons\n",
            "Configuration Space:\n",
            "'choices' = [2, 16]\n",
            " Var of type: preprocess\n",
            "Configuration Space:\n",
            "'choices' = [True, False]\n",
            " Var of type: activation\n",
            "Configuration Space:\n",
            "'choices' = [<class 'torch.nn.modules.activation.PReLU'>, <class 'torch.nn.modules.activation.SiLU'>]\n",
            "\n",
            "Model loader parameters: start_neurons=16 preprocess=False activation=<class 'torch.nn.modules.activation.PReLU'>\n",
            "\n",
            "\n",
            "**********TrainSampler**********\n",
            "Var of type: lr_high\n",
            "Configuration Space:\n",
            "'low': 0.0009, 'high': 0.1, 'log': True, 'step': unspecified\n",
            "\n",
            "Var of type: lr_low\n",
            "Configuration Space:\n",
            "'low': 1e-07, 'high': 0.0009, 'log': True, 'step': unspecified\n",
            "\n",
            "Var of type: metric\n",
            "Configuration Space:\n",
            "'choices' = [<function custom_mse at 0x7a10386856c0>]\n",
            "\n",
            "Var of type: batch_size\n",
            "Configuration Space:\n",
            "'choices' = [64]\n",
            "\n",
            "Var of type: pct_start\n",
            "Configuration Space:\n",
            "'low': 0.1, 'high': 0.95, 'log': False, 'step': 0.05\n",
            "\n",
            "Var of type: n_epoch\n",
            "Configuration Space:\n",
            "'choices' = [5]\n",
            "\n",
            "Var of type: action_func\n",
            "Configuration Space:\n",
            "'choices' = [<function action_default at 0x7a1035b317e0>]\n",
            "\n",
            "Var of type: max_norm\n",
            "Configuration Space:\n",
            "'low': 12.626330626734708, 'high': 12.626330626734708, 'log': False, 'step': unspecified\n",
            "\n",
            "Var of type: lr\n",
            "Configuration Space:\n",
            "'low': 7.357972600141196e-06, 'high': 7.357972600141196e-06, 'log': True, 'step': unspecified\n",
            "\n",
            "Var of type: wd\n",
            "Configuration Space:\n",
            "'choices' = [0.1]\n",
            "\n",
            "Var of type: one_cycle\n",
            "Configuration Space:\n",
            "'choices' = [False]\n",
            "\n",
            "Var of type: gradient_clip\n",
            "Configuration Space:\n",
            "'choices' = [True]\n",
            "\n",
            "Var of type: dls_func\n",
            "Configuration Space:\n",
            "'choices' = [<function get_dls at 0x7a1035b32dd0>]\n",
            "\n",
            "Var of type: freeze\n",
            "Configuration Space:\n",
            "'choices' = [False]\n",
            "\n",
            "Var of type: loss_func\n",
            "Configuration Space:\n",
            "'choices' = [<function custom_mse at 0x7a10386856c0>]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "*****************************************************************\n",
            "\n",
            "4\n",
            "Loaded study from: /content/trial_storage/study_2.pkl\n"
          ]
        }
      ]
    }
  ]
}