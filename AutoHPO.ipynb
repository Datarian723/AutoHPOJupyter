{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOzIXvqgf1aWy1T2onIelk3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Datarian723/AutoHPO/blob/main/AutoHPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TODO"
      ],
      "metadata": {
        "id": "jsclqRyJhDXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "(1)FIGURE_OUT: WHY ON EARTH Wrapper's retrieval of 'dls_func' is returning [get_sig] INSTEAD of get_sig.\n",
        "   MODIFY: UNTIL Wrapper Testing passes.\n",
        "(2)MODIFY: HpoTrainer, Auto.\n",
        "   TEST: The entire Auto-HPO process.\n",
        "(3)START: The new Kaggle competition(check your recent Gmail notification about it)\n",
        "   TEST: The entire Auto-HPO process ON: 3D Image reconstruction Challenge\n",
        "   TEST: The entire Auto-HPO process ON: 3D Image reconstruction Challenge + CapsuleNetwork\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rWuRvNI7hGC4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "d3106cd9-f811-4919-d2d0-1bedceb272cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n(1)FIGURE_OUT: WHY ON EARTH Wrapper's retrieval of 'dls_func' is returning [get_sig] INSTEAD of get_sig.\\n   MODIFY: UNTIL Wrapper Testing passes.\\n(2)MODIFY: HpoTrainer, Auto.\\n   TEST: The entire Auto-HPO process.\\n(3)START: The new Kaggle competition(check your recent Gmail notification about it)\\n   TEST: The entire Auto-HPO process ON: 3D Image reconstruction Challenge\\n   TEST: The entire Auto-HPO process ON: 3D Image reconstruction Challenge + CapsuleNetwork\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prep"
      ],
      "metadata": {
        "id": "Z1SWvwUo9mTR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-pqUbpl9ihB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8cbeecb-2643-43b3-9d61-c24f229933a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/362.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m358.4/362.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.8/362.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install fastai --upgrade --quiet\n",
        "!pip install optuna --upgrade --quiet\n",
        "!pip install optuna-integration --upgrade --quiet #Where Fast.ai's FastAIPruningCallback is in.\n",
        "!pip install scipy --upgrade --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Special Imports\n",
        "# ---------------------------\n",
        "from __future__ import annotations  # Enable forward references for type hints\n",
        "\n",
        "# ---------------------------\n",
        "# Standard Libraries\n",
        "# ---------------------------\n",
        "import os  # Operating system utilities\n",
        "import gc  # Garbage collection for memory management\n",
        "import logging  # Logging utilities\n",
        "import sys  # System-specific parameters and functions\n",
        "import unittest  # For unit-testing Python code\n",
        "import copy  # For deep and shallow copying of objects\n",
        "import math  # Math operations\n",
        "import random  # Random number generation\n",
        "import gzip  # For compressing and decompressing data\n",
        "from functools import partial  # Partial function application\n",
        "from collections import defaultdict  # Dictionary subclass with default values\n",
        "from sortedcontainers import SortedSet  # Sorted set implementation\n",
        "from unittest.mock import Mock, patch  # For mocking and patching in unit tests\n",
        "from inspect import signature  # Inspecting callable signatures\n",
        "from typing import Callable, Union  # Type annotations for type hints\n",
        "from ast import Is  # Abstract syntax tree utilities\n",
        "from abc import ABC, abstractmethod  # Abstract Base Classes for inheritance\n",
        "\n",
        "# ---------------------------\n",
        "# Scientific Libraries\n",
        "# ---------------------------\n",
        "import numpy as np  # Array and matrix operations\n",
        "import pandas as pd  # Data manipulation and analysis\n",
        "import matplotlib.pyplot as plt  # Plotting and visualization\n",
        "\n",
        "# ---------------------------\n",
        "# PyTorch and Related Modules\n",
        "# ---------------------------\n",
        "import torch  # Core PyTorch library for tensor operations\n",
        "import torch.nn as nn  # Neural network modules\n",
        "import torch.nn.functional as F  # Functional API for neural networks\n",
        "import torchvision.models as models  # Pre-trained models from torchvision\n",
        "from torch.multiprocessing import Pool, set_start_method  # Multiprocessing utilities for PyTorch\n",
        "\n",
        "# ---------------------------\n",
        "# FastAI Libraries\n",
        "# ---------------------------\n",
        "from fastai.vision.all import *  # All-in-one import for vision-specific modules\n",
        "from fastai.metrics import *  # Evaluation metrics for model performance\n",
        "from fastai.callback.hook import *  # Hooks for capturing intermediate model states\n",
        "from fastai.callback.tracker import *  # Training callback trackers (e.g., early stopping)\n",
        "from fastai.learner import Learner  # Core Learner object for model training\n",
        "\n",
        "# ---------------------------\n",
        "# Optuna for Hyperparameter Optimization\n",
        "# ---------------------------\n",
        "import optuna  # Core Optuna library for optimization\n",
        "from optuna.integration import FastAIPruningCallback  # Pruning callback for FastAI integration\n",
        "from optuna.trial import Trial, FrozenTrial  # Trial classes for defining and managing trials\n",
        "\n",
        "# ---------------------------\n",
        "# Google Colab Utilities\n",
        "# ---------------------------\n",
        "from google.colab import files  # File utilities for Colab\n",
        "from google.colab import drive  # Mounting Google Drive in Colab"
      ],
      "metadata": {
        "id": "GFAbjN7j9ov0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Empty the cache.\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "QeGSLT_N9shk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Upload your kaggle token.\"\"\"\n",
        "from google.colab import files\n",
        "files.upload()  #Use the file chooser to upload 'kaggle.json'"
      ],
      "metadata": {
        "id": "yuaqT__U9upq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"After uploading, set up API Kaggle token\"\"\"\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "cA7q3Vho9weV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Download the dataset.\"\"\"\n",
        "!kaggle competitions download -c image-matching-challenge-2024"
      ],
      "metadata": {
        "id": "I6s8PlpC9yac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Unzip the dataset.\"\"\"\n",
        "!unzip -q image-matching-challenge-2024.zip -d competition_data"
      ],
      "metadata": {
        "id": "9TL0PE4290gL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Base path\n",
        "path = '/content/competition_data'\n",
        "#Set up the 'Path' object.\n",
        "path = Path(path)\n",
        "#Upload the 'train_labels.csv' to Pandas DataFrame\n",
        "df = pd.read_csv(path / 'train/train_labels.csv')\n",
        "#Take a look at its head.\n",
        "df.head()"
      ],
      "metadata": {
        "id": "PY_BGV2Y93ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assuming 'df' is your DataFrame and 'path' is a Path object or string with the base path\n",
        "def check_file_paths(df, base_path):\n",
        "    # Vectorized creation of the first and second check file paths\n",
        "    first_check_paths = base_path / 'train' / df['dataset'] / 'images' / df['image_name']\n",
        "    second_check_paths = base_path / 'train' / df['scene'] / 'images' / df['image_name']\n",
        "\n",
        "    # Vectorized check if paths exist\n",
        "    first_check_exists = first_check_paths.map(os.path.exists)\n",
        "    second_check_exists = second_check_paths.map(os.path.exists)\n",
        "\n",
        "    # Identify rows where both checks failed\n",
        "    both_checks_failed = ~first_check_exists & ~second_check_exists\n",
        "\n",
        "    # Drop rows where both checks failed\n",
        "    df = df[~both_checks_failed]\n",
        "    return df\n",
        "\n",
        "# Usage\n",
        "# df = your pandas DataFrame\n",
        "# path = your base path, ensure it's a Path object from pathlib or a string\n",
        "df = check_file_paths(df, path)\n",
        "print(f\"Length of df after sift: {len(df)}\")"
      ],
      "metadata": {
        "id": "RA5jRrxu94-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "WARNING: 'train' dataset is to be used for train/valid.\n",
        "         'test' dataset is to be used for submission.\n",
        "\"\"\"\n",
        "def get_x(row):\n",
        "    \"\"\"\n",
        "    ACCEPTS: Each row of the DataFrame.\n",
        "    RETURNS: Valid image path of that row.\n",
        "             (IF does NOT exist, THEN it will raise FileNotFoundError())\n",
        "    \"\"\"\n",
        "    first_check_path = path / 'train' / row['dataset'] / 'images' / row['image_name']\n",
        "    second_check_path = path / 'train' / row['scene'] / 'images' / row['image_name']\n",
        "\n",
        "    if first_check_path.exists():\n",
        "        return first_check_path\n",
        "    elif second_check_path.exists():\n",
        "        return second_check_path\n",
        "    else:\n",
        "        raise FileNotFoundError()\n",
        "\n",
        "def get_y(row):\n",
        "    \"\"\"\n",
        "    ACCEPTS: Each row of the DataFrame.\n",
        "    RETURNS: Label for that row.\n",
        "    NOTE: For every row, label will be [R,t], where R := rotation matrix(flattened), t := translation vector.\n",
        "          and label.shape == [12](9 entreis for R, 3 at the end for t)\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    rotation = df['rotation_matrix'].str.split(';').apply(lambda x: [float(i) for i in x])\n",
        "    rotation = torch.tensor(rotation.tolist(), dtype=torch.float32)\n",
        "    translation = df['translation_vector'].str.split(';').apply(lambda x: [float(i) for i in x])\n",
        "    translation = torch.tensor(translation.tolist(), dtype=torch.float32)\n",
        "    \"\"\"\n",
        "    #Directly convert 'rotation' to a list of floats.\n",
        "    rotation = [float(i) for i in row['rotation_matrix'].split(';')]\n",
        "    #Then, convert the list of floats to an np.array\n",
        "    rotation = torch.tensor((rotation), dtype=torch.float32)\n",
        "    #Directly convert 'translation' to a list of floats.\n",
        "    translation = [float(i) for i in row['translation_vector'].split(';')]\n",
        "    #To torch.tensor.\n",
        "    translation = torch.tensor((translation), dtype=torch.float32)\n",
        "    #Produce the label.\n",
        "    #Concat them along dim=0.\n",
        "    #(Will become of shape==[12] s.t first 9 are rotations, last 3 are translation)\n",
        "    label = torch.cat((rotation, translation), dim=0)\n",
        "    #Return the label.\n",
        "    return label\n",
        "\n",
        "#Test\n",
        "print(get_x(df.iloc[0]))\n",
        "print(get_y(df.iloc[0]))"
      ],
      "metadata": {
        "id": "oV9iDyyQ-FzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"CREATE & CHECK the DataLoaders\"\"\"\n",
        "\n",
        "def get_dls(bs, img_size, normalize, summary=False):\n",
        "    \"\"\"\n",
        "    Returns a DataLoader object with the specified args.\n",
        "    \"\"\"\n",
        "    #batch_tfms defined.\n",
        "    batch_tfms = [*aug_transforms(\n",
        "        #Args for augmentation transforms.\n",
        "        size = img_size, min_scale=0.75,\n",
        "        mult=1.5, do_flip=False, flip_vert=False,\n",
        "        max_rotate=0.0, min_zoom=0.5, max_zoom=1.5,\n",
        "        max_lighting=0.5, max_warp=0.2, p_affine=0.75, p_lighting=0.75)]\n",
        "    #IF normalization is set to 'True', THEN append nomalization as well.\n",
        "    #(This will normalize inputs, obviously)\n",
        "    if normalize:\n",
        "        batch_tfms.append(Normalize.from_stats(*imagenet_stats))\n",
        "\n",
        "    #Get the dataloader.\n",
        "    db = DataBlock(\n",
        "        blocks=(ImageBlock, RegressionBlock(12)),\n",
        "        get_x=get_x,\n",
        "        get_y=get_y,\n",
        "        splitter=RandomSplitter(),\n",
        "        item_tfms=Resize(460),\n",
        "        batch_tfms = batch_tfms\n",
        "    )\n",
        "\n",
        "    #IF summary==True, THEN provide the summary of this DataBlock.\n",
        "    if summary:\n",
        "        db.summary(df)\n",
        "\n",
        "    #Return the actual dataloder:\n",
        "    #source = df(train_labels)\n",
        "    #bs = user-specified batch size.\n",
        "    return db.dataloaders(source=df, bs=bs)"
      ],
      "metadata": {
        "id": "5Cn3zY4u-J6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def r2q(R):\n",
        "    \"\"\"\n",
        "    ACCEPTS: R = A collection of batches of 9-element rotation tensors.\n",
        "                 R.shape == [K,N,9] WHERE K := Number of batches\n",
        "                                            N := Number of elements in each batch\n",
        "    RETURNS: quats = Corresponding collection of batches of quaternion(i,j,k,l) tensors.\n",
        "                     quats.shape == [K,N,4]\n",
        "    \"\"\"\n",
        "    #KN <- Tensor of integers with elements [K,N]\n",
        "    KN = R.size()[:-1]\n",
        "    #ENSURE: R is shaped to be (K,N,3,3)\n",
        "    R = R.reshape(*KN,3,3)\n",
        "    #quats <- Variable to hold computed quaternions\n",
        "    quats = torch.zeros(size=(*KN, 4), dtype=torch.float32, device=R.device)\n",
        "\n",
        "    #Compute the trace for each matrix in the batch\n",
        "    #tr.shape == [K,N]\n",
        "    tr = torch.einsum(\"ijkk->ij\" ,R)\n",
        "\n",
        "    #Initialize masks for different conditions\n",
        "    mask1 = tr > 0\n",
        "    mask2 = (~mask1) & (R[:, :, 0, 0] > R[:, :, 1, 1]) & (R[:, :, 0, 0] > R[:, :, 2, 2])\n",
        "    mask3 = (~mask1) & (~mask2) & (R[:, :, 1, 1] > R[:, :, 2, 2])\n",
        "    mask4 = (~mask1) & (~mask2) & (~mask3)\n",
        "    mask1, mask2, mask3, mask4 = (torch.nonzero(x, as_tuple=True) for x in (mask1, mask2, mask3, mask4))\n",
        "\n",
        "    #Case 1: Trace > 0\n",
        "    x, y = mask1\n",
        "    S = torch.sqrt(tr[mask1] + 1.0) * 2\n",
        "    quats[x, y, 0] = 0.25 * S\n",
        "    quats[x, y, 1] = (R[x, y, 2, 1] - R[x, y, 1, 2]) / S\n",
        "    quats[x, y, 2] = (R[x, y, 0, 2] - R[x, y, 2, 0]) / S\n",
        "    quats[x, y, 3] = (R[x, y, 1, 0] - R[x, y, 0, 1]) / S\n",
        "\n",
        "    #Case 2: The first element is the largest diagonal element\n",
        "    x, y = mask2\n",
        "    S = torch.sqrt(1.0 + 2.0 * R[x, y, 0, 0] - tr[mask2]) * 2\n",
        "    quats[x, y, 0] = (R[x, y, 2, 1] - R[x, y, 1, 2]) / S\n",
        "    quats[x, y, 1] = 0.25 * S\n",
        "    quats[x, y, 2] = (R[x, y, 0, 1] + R[x, y, 1, 0]) / S\n",
        "    quats[x, y, 3] = (R[x, y, 0, 2] + R[x, y, 2, 0]) / S\n",
        "\n",
        "    #Case 3: The second element is the largest diagonal element\n",
        "    x, y = mask3\n",
        "    S = torch.sqrt(1.0 + 2.0 * R[x, y, 1, 1] - tr[mask3]) * 2\n",
        "    quats[x, y, 0] = (R[x, y, 0, 2] - R[x, y, 2, 0]) / S\n",
        "    quats[x, y, 1] = (R[x, y, 0, 1] + R[x, y, 1, 0]) / S\n",
        "    quats[x, y, 2] = 0.25 * S\n",
        "    quats[x, y, 3] = (R[x, y, 1, 2] + R[x, y, 2, 1]) / S\n",
        "\n",
        "    #Case 4: The third element is the largest diagonal element\n",
        "    x, y = mask4\n",
        "    S = torch.sqrt(1.0 + 2.0 * R[x, y, 2, 2] - tr[mask4]) * 2\n",
        "    quats[x, y, 0] = (R[x, y, 1, 0] - R[x, y, 0, 1]) / S\n",
        "    quats[x, y, 1] = (R[x, y, 0, 2] + R[x, y, 2, 0]) / S\n",
        "    quats[x, y, 2] = (R[x, y, 1, 2] + R[x, y, 2, 1]) / S\n",
        "    quats[x, y, 3] = 0.25 * S\n",
        "\n",
        "    #Returns a tuple of split quats; (quats_hat, quats)\n",
        "    #NOTE: No normalization of quaternions applied.\n",
        "    return (x.squeeze(0) for x in torch.split(quats, [1,1]))\n",
        "\n",
        "def rots_mse(rots_hat, rots):\n",
        "    quats_hat, quats = r2q(torch.stack((rots_hat, rots), dim=0))\n",
        "    #total_rots_hat = torch.cat((quats_hat.squeeze(0), rots_hat), dim=-1)\n",
        "    total_rots_hat = torch.cat((quats_hat, rots_hat), dim=-1)\n",
        "    #total_rots = torch.cat((quats.squeeze(0), rots), dim=-1)\n",
        "    total_rots = torch.cat((quats, rots), dim=-1)\n",
        "    return nn.MSELoss()(total_rots_hat, total_rots)\n",
        "\n",
        "def trans_mse(trans_hat, trans):\n",
        "    return nn.MSELoss()(trans_hat, trans)\n",
        "\n",
        "def loss_func(Y_hat, Y):\n",
        "    \"\"\"\n",
        "    ACCEPTS: Y_hat = A tensor of shape [N,12], representing the model;\n",
        "             9 rots, 3 trans\n",
        "             Y = A tensor of shape [N,12], representing the ground truth;\n",
        "             9 rots, 3 trans\n",
        "    RETURNS: A scalar tensor representing the total loss.\n",
        "    \"\"\"\n",
        "    N = Y.shape[0]\n",
        "    #Extract rotations and translations.\n",
        "    rots_hat, rots = Y_hat[:,:9], Y[:,:9]\n",
        "    trans_hat, trans = Y_hat[:,9:], Y[:,9:]\n",
        "    #Compute rots_mse, trans_mse separately\n",
        "    rots_loss = rots_mse(rots_hat=rots_hat, rots=rots)\n",
        "    trans_loss = trans_mse(trans_hat=trans_hat, trans=trans)\n",
        "    #Return total loss s:= rots_loss + trans_loss\n",
        "    return rots_loss + trans_loss\n",
        "\n",
        "#Test\n",
        "Y_hat = torch.randn(64, 12)\n",
        "Y = torch.randn(64, 12)\n",
        "loss_func(Y_hat, Y)def r2q(R):\n",
        "    \"\"\"\n",
        "    ACCEPTS: R = A collection of batches of 9-element rotation tensors.\n",
        "                 R.shape == [K,N,9] WHERE K := Number of batches\n",
        "                                            N := Number of elements in each batch\n",
        "    RETURNS: quats = Corresponding collection of batches of quaternion(i,j,k,l) tensors.\n",
        "                     quats.shape == [K,N,4]\n",
        "    \"\"\"\n",
        "    #KN <- Tensor of integers with elements [K,N]\n",
        "    KN = R.size()[:-1]\n",
        "    #ENSURE: R is shaped to be (K,N,3,3)\n",
        "    R = R.reshape(*KN,3,3)\n",
        "    #quats <- Variable to hold computed quaternions\n",
        "    quats = torch.zeros(size=(*KN, 4), dtype=torch.float32, device=R.device)\n",
        "\n",
        "    #Compute the trace for each matrix in the batch\n",
        "    #tr.shape == [K,N]\n",
        "    tr = torch.einsum(\"ijkk->ij\" ,R)\n",
        "\n",
        "    #Initialize masks for different conditions\n",
        "    mask1 = tr > 0\n",
        "    mask2 = (~mask1) & (R[:, :, 0, 0] > R[:, :, 1, 1]) & (R[:, :, 0, 0] > R[:, :, 2, 2])\n",
        "    mask3 = (~mask1) & (~mask2) & (R[:, :, 1, 1] > R[:, :, 2, 2])\n",
        "    mask4 = (~mask1) & (~mask2) & (~mask3)\n",
        "    mask1, mask2, mask3, mask4 = (torch.nonzero(x, as_tuple=True) for x in (mask1, mask2, mask3, mask4))\n",
        "\n",
        "    #Case 1: Trace > 0\n",
        "    x, y = mask1\n",
        "    S = torch.sqrt(tr[mask1] + 1.0) * 2\n",
        "    quats[x, y, 0] = 0.25 * S\n",
        "    quats[x, y, 1] = (R[x, y, 2, 1] - R[x, y, 1, 2]) / S\n",
        "    quats[x, y, 2] = (R[x, y, 0, 2] - R[x, y, 2, 0]) / S\n",
        "    quats[x, y, 3] = (R[x, y, 1, 0] - R[x, y, 0, 1]) / S\n",
        "\n",
        "    #Case 2: The first element is the largest diagonal element\n",
        "    x, y = mask2\n",
        "    S = torch.sqrt(1.0 + 2.0 * R[x, y, 0, 0] - tr[mask2]) * 2\n",
        "    quats[x, y, 0] = (R[x, y, 2, 1] - R[x, y, 1, 2]) / S\n",
        "    quats[x, y, 1] = 0.25 * S\n",
        "    quats[x, y, 2] = (R[x, y, 0, 1] + R[x, y, 1, 0]) / S\n",
        "    quats[x, y, 3] = (R[x, y, 0, 2] + R[x, y, 2, 0]) / S\n",
        "\n",
        "    #Case 3: The second element is the largest diagonal element\n",
        "    x, y = mask3\n",
        "    S = torch.sqrt(1.0 + 2.0 * R[x, y, 1, 1] - tr[mask3]) * 2\n",
        "    quats[x, y, 0] = (R[x, y, 0, 2] - R[x, y, 2, 0]) / S\n",
        "    quats[x, y, 1] = (R[x, y, 0, 1] + R[x, y, 1, 0]) / S\n",
        "    quats[x, y, 2] = 0.25 * S\n",
        "    quats[x, y, 3] = (R[x, y, 1, 2] + R[x, y, 2, 1]) / S\n",
        "\n",
        "    #Case 4: The third element is the largest diagonal element\n",
        "    x, y = mask4\n",
        "    S = torch.sqrt(1.0 + 2.0 * R[x, y, 2, 2] - tr[mask4]) * 2\n",
        "    quats[x, y, 0] = (R[x, y, 1, 0] - R[x, y, 0, 1]) / S\n",
        "    quats[x, y, 1] = (R[x, y, 0, 2] + R[x, y, 2, 0]) / S\n",
        "    quats[x, y, 2] = (R[x, y, 1, 2] + R[x, y, 2, 1]) / S\n",
        "    quats[x, y, 3] = 0.25 * S\n",
        "\n",
        "    #Returns a tuple of split quats; (quats_hat, quats)\n",
        "    #NOTE: No normalization of quaternions applied.\n",
        "    return (x.squeeze(0) for x in torch.split(quats, [1,1]))\n",
        "\n",
        "def rots_mse(rots_hat, rots):\n",
        "    quats_hat, quats = r2q(torch.stack((rots_hat, rots), dim=0))\n",
        "    #total_rots_hat = torch.cat((quats_hat.squeeze(0), rots_hat), dim=-1)\n",
        "    total_rots_hat = torch.cat((quats_hat, rots_hat), dim=-1)\n",
        "    #total_rots = torch.cat((quats.squeeze(0), rots), dim=-1)\n",
        "    total_rots = torch.cat((quats, rots), dim=-1)\n",
        "    return nn.MSELoss()(total_rots_hat, total_rots)\n",
        "\n",
        "def trans_mse(trans_hat, trans):\n",
        "    return nn.MSELoss()(trans_hat, trans)\n",
        "\n",
        "def loss_func(Y_hat, Y):\n",
        "    \"\"\"\n",
        "    ACCEPTS: Y_hat = A tensor of shape [N,12], representing the model;\n",
        "             9 rots, 3 trans\n",
        "             Y = A tensor of shape [N,12], representing the ground truth;\n",
        "             9 rots, 3 trans\n",
        "    RETURNS: A scalar tensor representing the total loss.\n",
        "    \"\"\"\n",
        "    N = Y.shape[0]\n",
        "    #Extract rotations and translations.\n",
        "    rots_hat, rots = Y_hat[:,:9], Y[:,:9]\n",
        "    trans_hat, trans = Y_hat[:,9:], Y[:,9:]\n",
        "    #Compute rots_mse, trans_mse separately\n",
        "    rots_loss = rots_mse(rots_hat=rots_hat, rots=rots)\n",
        "    trans_loss = trans_mse(trans_hat=trans_hat, trans=trans)\n",
        "    #Return total loss s:= rots_loss + trans_loss\n",
        "    return rots_loss + trans_loss\n",
        "\n",
        "#Test\n",
        "Y_hat = torch.randn(64, 12)\n",
        "Y = torch.randn(64, 12)\n",
        "loss_func(Y_hat, Y)"
      ],
      "metadata": {
        "id": "MT1JLamu-M1L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "c28f756c-6487-4855-e327-0d449143d640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-6-69368f5d5fb8>, line 95)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-69368f5d5fb8>\"\u001b[0;36m, line \u001b[0;32m95\u001b[0m\n\u001b[0;31m    loss_func(Y_hat, Y)def r2q(R):\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: Var"
      ],
      "metadata": {
        "id": "VwK_hENk-VzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Var:\n",
        "    def __init__(self, var_type: str, source: dict):\n",
        "        #Extract distribution, sample_method for error checking.\n",
        "        sample_method = source['sample']\n",
        "        distribution = source['params']['choices'] if sample_method=='categorical' else source['params']\n",
        "        #ERROR CHECK:\n",
        "        self._error_check(distribution, sample_method)\n",
        "\n",
        "        #Member initializations:\n",
        "        self.var_type = var_type\n",
        "        self.sample_method = sample_method\n",
        "        #frozen_dist is used for value conversion, in case value NOT currently in 'self.get_dist()' is requested for conversion.\n",
        "        self._frozen_dist = distribution.copy()\n",
        "        self._dist = list(range(len(self._frozen_dist))) if sample_method=='categorical' else distribution.copy()\n",
        "        #fixed <- IF (categorical distribution has one element) OR (low==high)\n",
        "        self.fixed = (self.sample_method=='categorical' and len(self._dist)==1) or (self.sample_method!='categorical' and self._dist['low']==self._dist['high'])\n",
        "\n",
        "    def _error_check(self, distribution, sample_method: str):\n",
        "        if not isinstance(distribution, (list,dict)):\n",
        "            raise ValueError(f\"Input 'distribution' MUST be of type in (list,dict) but found: {type(distribution)}\")\n",
        "        if sample_method not in ['categorical', 'float', 'int']:\n",
        "            raise ValueError(f\"sample method MUST be one of ['categorical', 'float', 'int'] but found: {sample_method}\")\n",
        "        if sample_method!='categorical' and not isinstance(distribution, dict) or sample_method=='categorical' and not isinstance(distribution, list):\n",
        "            raise ValueError(f\"sample_method: {sample_method} is not compatible with distribution: {distribution}. Categorical sampling requires a list, rest requires a dictionary\")\n",
        "        cat_valid_params = sample_method!='categorical' or len(distribution)\n",
        "        non_cat_valid_params = sample_method=='categorical' or (distribution.get('low', 0) <= distribution.get('high', -1))\n",
        "        if not cat_valid_params or not non_cat_valid_params:\n",
        "            msg = f\"Categorical distribution needs at least one value in it: {distribution}\" if sample_method=='categorical' else f\"distribution needs (low,high) as keys and distribution[low]<=distribution[high] but found: {distribution}\"\n",
        "            raise ValueError(msg)\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self.var_type, self.sample_method))\n",
        "\n",
        "    def __eq__(self, other: Var):\n",
        "        \"\"\"Two Var objects are considered 'equal'\n",
        "           IFF (1)other is Var object\n",
        "               (2)self.var_type == other.var_type\n",
        "               (3)self.params == other.params\n",
        "        \"\"\"\n",
        "        return all([\n",
        "            isinstance(other, Var),\n",
        "            self.var_type == other.var_type,\n",
        "            self.sample_method == other.sample_method,\n",
        "            self._frozen_dist == other._frozen_dist,\n",
        "            self._dist == other._dist\n",
        "        ])\n",
        "\n",
        "    def __str__(self):\n",
        "        if self.sample_method == 'categorical':\n",
        "            config_space = f\"'choices' = {[self._frozen_dist[idx] for idx in self._dist]}\"\n",
        "        else:\n",
        "            config_space = (\n",
        "                f\"'low': {self._dist['low']}, \"\n",
        "                f\"'high': {self._dist['high']}, \"\n",
        "                f\"'log': {self._dist.get('log', False)}, \"\n",
        "                f\"'step': {self._dist.get('step', 'unspecified')}\"\n",
        "            )\n",
        "        output = f\"Var of type: {self.var_type}\\nConfiguration Space:\\n{config_space}\\n\"\n",
        "        return output\n",
        "\n",
        "    def contain_idx(self, idx, current: bool = False):\n",
        "        if self.sample_method!='categorical' and type(idx)!=eval(self.sample_method) or self.sample_method=='categorical' and type(idx)!=int:\n",
        "            return False\n",
        "        if self.sample_method!='categorical':\n",
        "            dist = self._dist if current else self._frozen_dist\n",
        "            return dist['low'] <= idx <= dist['high']\n",
        "        return idx in self._dist if current else 0 <= idx < len(self._frozen_dist)\n",
        "\n",
        "    def contain_val(self, val, current: bool = False):\n",
        "        if self.sample_method != 'categorical':\n",
        "            return self.contain_idx(idx=val, current=current)\n",
        "        if self.var_type=='action_func' and isinstance(val, Action):\n",
        "            val = val.action_func\n",
        "        return val in self.distribution() if current else val in self._frozen_dist\n",
        "\n",
        "    def convert_idx_to_val(self, idx):\n",
        "        if not self.contain_idx(idx=idx, current=False):\n",
        "            raise ValueError(f\"Input index 'idx' is NOT a proper index for conversion via Var:{self.var_type}'s distribution: {list(range(len(self._frozen_dist))) if self.sample_method=='categorical' else self._frozen_dist}\")\n",
        "        if self.sample_method!='categorical':\n",
        "            return idx\n",
        "        return self._frozen_dist[idx]\n",
        "\n",
        "    def convert_val_to_idx(self, val):\n",
        "        if not self.contain_val(val=val, current=False):\n",
        "            raise ValueError(f\"Input value 'val': {val} is NOT a proper value for conversion via Var:{self.var_type}'s distribution: {self._frozen_dist}\")\n",
        "        if self.sample_method!='categorical':\n",
        "            return val\n",
        "        return self._frozen_dist.index(val)\n",
        "\n",
        "    def distribution(self, indices: bool = False):\n",
        "        if self.sample_method!='categorical':\n",
        "            return self._dist\n",
        "        if indices:\n",
        "            return self._dist\n",
        "        return [self._frozen_dist[idx] for idx in self._dist]\n",
        "\n",
        "    def sample(self, trial):\n",
        "        if not isinstance(trial, (Trial, FrozenTrial)):\n",
        "            raise ValueError(f\"Input 'trial' must be of type in (optuna::Trial, optuna::FrozenTrial) but found: {trial}\")\n",
        "\n",
        "        if isinstance(trial, FrozenTrial):\n",
        "            idx_or_val = trial.params[self.var_type]\n",
        "            #sample_method=='categorical' <-> retrieved value is an index NOT an actual value.\n",
        "            sampled_val = self.convert_idx_to_val(idx_or_val) if self.sample_method=='categorical' else idx_or_val\n",
        "            return sampled_val\n",
        "\n",
        "        sampled_val = None\n",
        "        if self.sample_method == 'categorical':\n",
        "            idx = trial.suggest_categorical(self.var_type, choices=self._dist)\n",
        "            sampled_val = self._frozen_dist[idx]\n",
        "        elif self.sample_method == 'float':\n",
        "            sampled_val = trial.suggest_float(self.var_type, **self._dist)\n",
        "        elif self.sample_method == 'int':\n",
        "            sampled_val = trial.suggest_int(self.var_type, **self._dist)\n",
        "\n",
        "        return sampled_val\n",
        "\n",
        "    def update(self, vals: list):\n",
        "        #Proior processing:\n",
        "        if not len(vals):\n",
        "            return\n",
        "        if not all(isinstance(val, (int,float)) for val in vals):\n",
        "            raise ValueError(f\"Var of type: {self.var_type} with sample_method: {self.sample_method} recieved update request with 'vals': {vals} which contain element(s) NOT of type in (int,float)\")\n",
        "        vals = sorted(vals.copy()) if self.sample_method=='categorical' else vals\n",
        "\n",
        "        set_vals = set(vals)\n",
        "        if len(set_vals)==1:\n",
        "            vals = [vals[0]]\n",
        "            self.fixed = True\n",
        "\n",
        "        #ERROR CHECKS:\n",
        "        if self.sample_method!='categorical' and (min(vals)<self._dist['low'] or max(vals)>self._dist['high']):\n",
        "            raise ValueError(f\"Var of type: {self.var_type} with sample_method: {self.sample_method} recieved update request with 'vals': {vals} NOT in valid range: [{self._dist['low']},{self._dist['high']}]. Note the initial search space: [{self._frozen_dist['low']},{self._frozen_dist['high']}].\")\n",
        "        if self.sample_method=='categorical' and not set_vals.issubset(set(self._dist)):\n",
        "            raise ValueError(f\"Var of type: {self.var_type} with sample_method: {self.sample_method} recieved update request with 'vals': {vals} NOT in valid range: {self._dist}. Note the initial search space: {self._frozen_dist}\")\n",
        "\n",
        "        #UPDATE: configuration space.\n",
        "        if self.sample_method=='categorical':\n",
        "            self._dist = vals\n",
        "        else:\n",
        "            self._dist['low'] = min(vals)\n",
        "            self._dist['high'] = max(vals)"
      ],
      "metadata": {
        "id": "6FfK4Xv9-ZeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test: Var"
      ],
      "metadata": {
        "id": "Yr4PS-9cU9Py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestVar(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        self.categorical_source = {\n",
        "            'params': {'choices': [1, 2, 3, 4, 5]},\n",
        "            'sample': 'categorical'\n",
        "        }\n",
        "        self.float_source = {\n",
        "            'params': {'low': 0.1, 'high': 1.0},\n",
        "            'sample': 'float'\n",
        "        }\n",
        "        self.int_source = {\n",
        "            'params': {'low': 1, 'high': 10},\n",
        "            'sample': 'int'\n",
        "        }\n",
        "\n",
        "    def test_init_categorical(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        self.assertEqual(var.var_type, 'test_var')\n",
        "        self.assertEqual(var.sample_method, 'categorical')\n",
        "        self.assertEqual(var._frozen_dist, [1, 2, 3, 4, 5])\n",
        "        self.assertEqual(var._dist, [0, 1, 2, 3, 4])\n",
        "        self.assertFalse(var.fixed)\n",
        "\n",
        "    def test_init_float(self):\n",
        "        var = Var(var_type='test_var', source=self.float_source)\n",
        "        self.assertEqual(var.var_type, 'test_var')\n",
        "        self.assertEqual(var.sample_method, 'float')\n",
        "        self.assertEqual(var._frozen_dist, {'low': 0.1, 'high': 1.0})\n",
        "        self.assertEqual(var._dist, {'low': 0.1, 'high': 1.0})\n",
        "        self.assertFalse(var.fixed)\n",
        "\n",
        "    def test_init_int(self):\n",
        "        var = Var(var_type='test_var', source=self.int_source)\n",
        "        self.assertEqual(var.var_type, 'test_var')\n",
        "        self.assertEqual(var.sample_method, 'int')\n",
        "        self.assertEqual(var._frozen_dist, {'low': 1, 'high': 10})\n",
        "        self.assertEqual(var._dist, {'low': 1, 'high': 10})\n",
        "        self.assertFalse(var.fixed)\n",
        "\n",
        "    def test_init_error_invalid_sample_method(self):\n",
        "        with self.assertRaises(ValueError):\n",
        "            Var(var_type='test_var', source={'params': {'choices': [1, 2]}, 'sample': 'invalid'})\n",
        "\n",
        "    def test_init_error_invalid_distribution_type(self):\n",
        "        with self.assertRaises(ValueError):\n",
        "            Var(var_type='test_var', source={'params': {'choices': {'key': 'value'}}, 'sample': 'categorical'})\n",
        "\n",
        "    def test_contain_idx(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        self.assertTrue(var.contain_idx(2))\n",
        "        self.assertFalse(var.contain_idx(5))\n",
        "\n",
        "        var_float = Var(var_type='test_var', source=self.float_source)\n",
        "        self.assertTrue(var_float.contain_idx(0.5))\n",
        "        self.assertFalse(var_float.contain_idx(1.1))\n",
        "\n",
        "    def test_contain_val(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        self.assertTrue(var.contain_val(3))\n",
        "        self.assertFalse(var.contain_val(6))\n",
        "\n",
        "        var_float = Var(var_type='test_var', source=self.float_source)\n",
        "        self.assertTrue(var_float.contain_val(0.5))\n",
        "        self.assertFalse(var_float.contain_val(1.1))\n",
        "\n",
        "    def test_convert_idx_to_val(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        self.assertEqual(var.convert_idx_to_val(2), 3)\n",
        "\n",
        "        var_float = Var(var_type='test_var', source=self.float_source)\n",
        "        self.assertEqual(var_float.convert_idx_to_val(0.5), 0.5)\n",
        "\n",
        "    def test_convert_val_to_idx(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        self.assertEqual(var.convert_val_to_idx(3), 2)\n",
        "\n",
        "        with self.assertRaises(ValueError):\n",
        "            var.convert_val_to_idx(6)\n",
        "\n",
        "    def test_distribution(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        self.assertEqual(var.distribution(), [1, 2, 3, 4, 5])\n",
        "\n",
        "        var_float = Var(var_type='test_var', source=self.float_source)\n",
        "        self.assertEqual(var_float.distribution(), {'low': 0.1, 'high': 1.0})\n",
        "\n",
        "    def test_sample_categorical(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        trial = optuna.create_study(direction='minimize').ask()\n",
        "        trial.suggest_categorical = Mock(return_value=2)\n",
        "        sampled_val = var.sample(trial)\n",
        "        self.assertEqual(sampled_val, 3)\n",
        "\n",
        "    def test_sample_float(self):\n",
        "        var = Var(var_type='test_var', source=self.float_source)\n",
        "        trial = optuna.create_study(direction='minimize').ask()\n",
        "        trial.suggest_float = Mock(return_value=0.5)\n",
        "        sampled_val = var.sample(trial)\n",
        "        self.assertEqual(sampled_val, 0.5)\n",
        "\n",
        "    def test_sample_error(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        with self.assertRaises(ValueError):\n",
        "            var.sample('not_a_trial')\n",
        "\n",
        "    def test_update_categorical(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        var.update([1, 2])\n",
        "        self.assertEqual(var.distribution(indices=True), [1,2])\n",
        "        self.assertEqual(var.distribution(), [2,3])\n",
        "        self.assertFalse(var.fixed)\n",
        "\n",
        "    def test_update_float(self):\n",
        "        var = Var(var_type='test_var', source=self.float_source)\n",
        "        var.update([0.2, 0.9])\n",
        "        self.assertEqual(var._dist['low'], 0.2)\n",
        "        self.assertEqual(var._dist['high'], 0.9)\n",
        "\n",
        "    def test_update_error_out_of_range(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        with self.assertRaises(ValueError):\n",
        "            var.update([0, 6])\n",
        "\n",
        "    def test_str(self):\n",
        "        var = Var(var_type='test_var', source=self.categorical_source)\n",
        "        expected_str = \"Var of type: test_var\\nConfiguration Space:\\n'choices' = [1, 2, 3, 4, 5]\\n\"\n",
        "        self.assertEqual(str(var), expected_str)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s272DsrVA_q",
        "outputId": "5ea5ba3a-393a-433e-faea-c5fb9c3f0006"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "..........[I 2024-09-19 18:31:38,557] A new study created in memory with name: no-name-78dcfdff-fcad-4672-aad3-835a09053d4d\n",
            "..[I 2024-09-19 18:31:38,576] A new study created in memory with name: no-name-1e245ab3-c105-4091-b0ee-a88af4c0b8ff\n",
            ".....\n",
            "----------------------------------------------------------------------\n",
            "Ran 17 tests in 0.119s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: Action"
      ],
      "metadata": {
        "id": "PFzep6tqVNNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Action:\n",
        "    def __init__(self, action_func: Callable, sig_dict: dict):\n",
        "        if not all(isinstance(var,Var) for var in sig_dict.values()):\n",
        "            raise ValueError(f\"Constructor of object 'Action' with action_func: '{action_func.__name__}' received an invalid dictionary sig_dict: {sig_dict}\")\n",
        "        self.action_func = action_func\n",
        "        self.sig_dict = sig_dict\n",
        "        self.sig = frozenset(sig_dict.keys())\n",
        "        self.params = {}\n",
        "        self.action_state = None\n",
        "        self._model_loader = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sig_dict)\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash(self.sig)\n",
        "\n",
        "    def __eq__(self, other: Action):\n",
        "        \"\"\"Two Action objects are considered 'equal'\n",
        "        IFF (1)other is Action object\n",
        "            (2)self.action_func == other.action_func\n",
        "            (3)self.params == other.params\n",
        "            (4)self.action_state == other.action_state\n",
        "        \"\"\"\n",
        "        self_params = self._model_loader.keywords if self._model_loader is not None else self._model_loader\n",
        "        other_params = other._model_loader.keywords if other._model_loader is not None else other._model_loader\n",
        "        if self_params != other_params:\n",
        "            return False\n",
        "\n",
        "        # Compare action states if both are dictionaries\n",
        "        if isinstance(self.action_state, dict) and isinstance(other.action_state, dict):\n",
        "            if self.action_state.keys() != other.action_state.keys():\n",
        "                return False\n",
        "            if not all(torch.equal(self.action_state[key], other.action_state[key]) for key in self.action_state.keys()):\n",
        "                return False\n",
        "        elif self.action_state != other.action_state: #IF one is None and the other is not None.\n",
        "            return False\n",
        "\n",
        "        return all([\n",
        "            self.action_func == other.action_func,\n",
        "            self.sig_dict == other.sig_dict,\n",
        "        ])\n",
        "\n",
        "\n",
        "    def __str__(self):\n",
        "        signature = \" \".join([f\"{var}\" for var in self.sig_dict.values()])\n",
        "        output = f\"Action of func: {self.action_func.__name__}\\nSignature Vars:\\n{signature}\\n\"\n",
        "        if self._model_loader:\n",
        "            parameters = \" \".join([f\"{key}={val}\" for key,val in self._model_loader.keywords.items()])\n",
        "            output += f\"Model loader parameters: {parameters}\\n\"\n",
        "        return output\n",
        "\n",
        "    def get_var(self, var_type):\n",
        "        if var_type not in self.keys():\n",
        "            raise ValueError(f\"'{var_type}' is not a valid signature key for Action: '{self.action_func.__name__}'. Available keys: {set(self.keys())}\")\n",
        "        return self.sig_dict[var_type]\n",
        "\n",
        "    def keys(self):\n",
        "        return self.sig_dict.keys()\n",
        "\n",
        "    def values(self):\n",
        "        return self.sig_dict.values()\n",
        "\n",
        "    def items(self):\n",
        "        return self.sig_dict.items()\n",
        "\n",
        "    def is_loadable(self):\n",
        "        return self._model_loader is not None\n",
        "\n",
        "    def is_fixed(self):\n",
        "        return all(var.fixed for var in self.sig_dict.values())\n",
        "\n",
        "    def parameterize(self, trial: optuna.Trial):\n",
        "        \"\"\"\n",
        "        ACCEPTS:\n",
        "        trial := Active optuna trial objet.\n",
        "                 IF input 'manual_action_params' is not empty, THEN 'trial' will NOT be used.\n",
        "        RETURNS: void.\n",
        "                 The function parameterizes the caller Action object.\n",
        "                 Without any saved action_state, the caller Action object needs to be parameterized every time before .__call__()\n",
        "        \"\"\"\n",
        "        #ERROR CHECKS:\n",
        "        if self.action_state is not None and not self.params:\n",
        "            raise ValueError(f\"Action: {self.action_func.__name__} has a saved action state(self.action_state!=None) but NO saved params(self.params==None).\")\n",
        "        if self.action_state is None and trial is None:\n",
        "            raise ValueError(f\"Action: {self.action_func.__name__} has no saved action state(self.action_state==None) and no input trial passed in(self.trial==None). No sampling can be done.\")\n",
        "\n",
        "        if self.action_state is None:\n",
        "            self.params = {cat:var.sample(trial=trial) for cat,var in self.items()}\n",
        "\n",
        "        #self._model_loader <- Fully parameterized model with self.params\n",
        "        #NOTE: IF it has a saved action state, the consistent self.params will restore the recenmost state(based on the recentmost top sampling results)\n",
        "        self._model_loader = partial(self.action_func, **self.params)\n",
        "\n",
        "    def __call__(self, device: torch.device):\n",
        "        if self.action_state is not None and not self.params:\n",
        "            raise ValueError(f\"Action: {self.action_func.__name__} has a saved action state(self.action_state!=None) but no saved params exists(self.params empty). Likely an internal logic issue\")\n",
        "        if self._model_loader is None:\n",
        "            raise ValueError(f\"Action: {self.action_func.__name__} cannot be called. Call Action.parameterize() first and then try it again.\")\n",
        "\n",
        "        #model <- Load the model onto 'device'.\n",
        "        model = self._model_loader(device=device)\n",
        "\n",
        "        #IF 'self.action_state' exists, THEN load the saved weights from the state dictionary(=self.action_state) to the model\n",
        "        if self.action_state:\n",
        "            try:\n",
        "                name = self.action_func.__name__\n",
        "                model.load_state_dict(self.action_state)\n",
        "            except torch.nn.modules.module.ModuleAttributeError as e:\n",
        "                print(f\"Attribute error: {e}. The state dictionary of Action: '{name}' may not match the model.\")\n",
        "            except RuntimeError as e:\n",
        "                print(f\"Runtime error: {e}. The state dictionary of Action: '{name}' may have unmatching layer sizes or missing keys.\")\n",
        "            except Exception as e:\n",
        "                print(f\"An unexpected error occurred while loading state dictionary to Action '{name}': {e}\")\n",
        "\n",
        "        #Last but not least, return the model.\n",
        "        return model\n",
        "\n",
        "    def update_sig(self, update_params: dict):\n",
        "        #IF Action (1)has a saved 'action_state' OR (2)0 elements in the 'update_params'\n",
        "        #THEN NO update shall be done.\n",
        "        if self.action_state or not len(update_params):\n",
        "            return\n",
        "\n",
        "        #ERROR CHECK: Make sure that ALL the keys in 'self.sig_dict' belong to 'sig_params'\n",
        "        leftovers = set(self.keys()) - set(update_params.keys())\n",
        "        if leftovers:\n",
        "            raise ValueError(f\"Updating Action: {self.action_func.__name__} requires following missing keys in 'sig_params': {leftovers}\")\n",
        "        if not all(isinstance(val,list) for val in update_params.values()):\n",
        "            raise ValueError(f\"Updating Action: {self.action_func.__name__} with input 'update_params' failed. ALL the values in 'update_params' MUST be of type 'list' but found: {update_params}\")\n",
        "\n",
        "        #Update: signature configuration space(=='self.sig_dict')\n",
        "        for cat,var in self.items():\n",
        "            var.update(vals=update_params[cat])\n",
        "\n",
        "    def update_state(self, obj):\n",
        "        \"\"\"\n",
        "        profile := A dictionary that contains the caller's signature(except 'device') as its subset.\n",
        "                   Additionally, every (sig->value) must contain the same value as what initialized the passed in 'obj'.\n",
        "        \"\"\"\n",
        "        #ERROR CHECK1: Type of obj.\n",
        "        if not isinstance(obj, (nn.Module, Learner, dict)):\n",
        "            raise ValueError(f\"Updating action state of Action: {self.action_func.__name__} failed. Input object 'obj' must be of type in (nn.Module, Learner, dict) but found: {type(obj)}\")\n",
        "        #ERROR CHECK2: This catches if one attempts to update the Action object with overriden\n",
        "        if self.action_state is not None and self.params != self._model_loader.keywords:\n",
        "            raise ValueError(f\"Updating action state of Action: {self.action_func.__name__} failed. Make sure that this object was sampled with valid Trialin the previuos HPO run. If .get_loadable_action() was used, then .update_state is NOT allowed.\")\n",
        "\n",
        "        if isinstance(obj, dict):\n",
        "            self.action_state = obj\n",
        "        else:\n",
        "            self.action_state = obj.model.state_dict() if isinstance(obj, Learner) else obj.state_dict()\n",
        "\n",
        "        #Manually set 'self.params'. This way, saved action_state -> self.params available!\n",
        "        self.params = self._model_loader.keywords.copy()"
      ],
      "metadata": {
        "id": "Y2qBB2qFHoUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test: Action"
      ],
      "metadata": {
        "id": "57JeyleVJWz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Parameters used in the testin of class 'Action' defined in this cell\n",
        "\"\"\"\n",
        "class ModelDefault(nn.Module):\n",
        "    def __init__(self, rand_number: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Linear(16,10)\n",
        "        self.rand_number = torch.tensor(rand_number)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x) + self.rand_number\n",
        "\n",
        "class ModelDropout(nn.Module):\n",
        "    def __init__(self, activation: nn.Module, dropout_p: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=16,out_features=10),\n",
        "            activation(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "            nn.Linear(in_features=10,out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def action_default(rand_number: int, device: torch.device):\n",
        "    return ModelDefault(rand_number=rand_number).to(device)\n",
        "\n",
        "def action_dropout(activation, dropout_p, device: torch.device):\n",
        "    #model_dropout := Class header of 'ModelDropout'\n",
        "    return ModelDropout(activation=activation, dropout_p=dropout_p).to(device)\n",
        "\n",
        "#ASSUMED: Input size of 10x16. (Single batch == 10 (4x4 flattened vector)s )\n",
        "#FIRST_LAYER: Fully connected linear layer of size 16x10\n",
        "#ACTIVATION: One of nn.ReLU, nn.PReLU, nn.SiLU\n",
        "#DROPOUT: nn.Dropout(p=dropout_p)\n",
        "#OUT: .shape == [10,10]\n",
        "#NOTE: Input 'model: Callable' will be the class header 'Model'."
      ],
      "metadata": {
        "id": "WouVr4SYNPPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestAction(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        default_sig_dict = {\n",
        "            'rand_number': Var(var_type='rand_number', source={'params': {'choices': list(range(1, 11))}, 'sample': 'categorical'})\n",
        "        }\n",
        "        dropout_sig_dict = {\n",
        "            'activation': Var(var_type='activation', source={'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]}, 'sample': 'categorical'}),\n",
        "            'dropout_p': Var(var_type='dropout_p', source={'params': {'low': 0.0, 'high': 1.0}, 'sample': 'float'})\n",
        "        }\n",
        "\n",
        "        self.action_sampler = {\n",
        "            action_default: Action(action_default, default_sig_dict),\n",
        "            action_dropout: Action(action_dropout, dropout_sig_dict)\n",
        "        }\n",
        "\n",
        "        # Create a trial object for parameterization\n",
        "        self.trial = optuna.create_study(direction='minimize').ask()\n",
        "\n",
        "    def test_initialization(self):\n",
        "        default_action = self.action_sampler[action_default]\n",
        "        dropout_action = self.action_sampler[action_dropout]\n",
        "\n",
        "        # Test if Action objects are initialized correctly\n",
        "        self.assertIsInstance(default_action, Action)\n",
        "        self.assertIsInstance(dropout_action, Action)\n",
        "\n",
        "        self.assertTrue(default_action.action_func == action_default)\n",
        "        self.assertIsInstance(default_action.get_var('rand_number'), Var)\n",
        "        self.assertTrue(\n",
        "            default_action.get_var('rand_number').distribution() == list(range(1, 11)),\n",
        "            msg=f\"{default_action.get_var('rand_number').distribution()} != {list(range(1, 11))}\"\n",
        "        )\n",
        "        self.assertFalse(default_action.params)\n",
        "        self.assertIsNone(default_action.action_state)\n",
        "        self.assertIsNone(default_action._model_loader)\n",
        "\n",
        "        self.assertTrue(dropout_action.action_func == action_dropout)\n",
        "        self.assertIsInstance(dropout_action.get_var('activation'), Var)\n",
        "        self.assertIsInstance(dropout_action.get_var('dropout_p'), Var)\n",
        "        self.assertTrue(dropout_action.get_var('activation').distribution() == [nn.ReLU, nn.PReLU, nn.SiLU])\n",
        "        self.assertFalse(dropout_action.params)\n",
        "        self.assertIsNone(dropout_action.action_state)\n",
        "        self.assertIsNone(dropout_action._model_loader)\n",
        "\n",
        "    def test_default_parameterize_with_action_state(self):\n",
        "        default_action = self.action_sampler[action_default]\n",
        "        default_action.action_state = 'dummy'\n",
        "        default_action.params = {'rand_number': 1}\n",
        "\n",
        "        # Test parameterization with the default action\n",
        "        default_action.parameterize(trial=self.trial)\n",
        "\n",
        "        # Posterior testing\n",
        "        self.assertIsInstance(default_action, Action)\n",
        "        self.assertIsNotNone(default_action.params)\n",
        "        self.assertIsNotNone(default_action.action_state)\n",
        "        self.assertIsNotNone(default_action._model_loader)\n",
        "\n",
        "        try:\n",
        "            model = default_action(device=torch.device('cpu'))\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "    def test_default_parameterize(self):\n",
        "        default_action = self.action_sampler[action_default]\n",
        "        # Test parameterization with the default action\n",
        "        default_action.parameterize(trial=self.trial)\n",
        "        self.assertTrue(set(default_action.params.keys()), set(['rand_number']))\n",
        "        self.assertTrue(default_action.params['rand_number'] in list(range(1, 11)))\n",
        "        self.assertIsNone(default_action.action_state)\n",
        "        self.assertIsNotNone(default_action._model_loader)\n",
        "        model = default_action(device=torch.device('cpu'))\n",
        "        X = torch.randn(size=[10, 16])\n",
        "        Y = model(X)\n",
        "        self.assertEqual(Y.shape, torch.Size([10, 10]))\n",
        "\n",
        "        self.assertIsNotNone(default_action.params)\n",
        "        self.assertIsNone(default_action.action_state)\n",
        "        self.assertIsNotNone(default_action._model_loader)\n",
        "\n",
        "    def test_dropout_parameterize_with_action_state(self):\n",
        "        dropout_action = self.action_sampler[action_dropout]\n",
        "        dropout_action.params = {\n",
        "            'activation': nn.ReLU,\n",
        "            'dropout_p': 0.5\n",
        "        }\n",
        "        model = ModelDropout(activation=nn.ReLU, dropout_p=0.5).to(torch.device('cpu'))\n",
        "        dropout_action.action_state = model.state_dict()\n",
        "\n",
        "        # Test parameterization with the default action\n",
        "        dropout_action.parameterize(trial=self.trial)\n",
        "\n",
        "        # Posterior testing\n",
        "        self.assertIsInstance(dropout_action, Action)\n",
        "        self.assertIsNotNone(dropout_action.params)\n",
        "        self.assertIsNotNone(dropout_action.action_state)\n",
        "        self.assertIsNotNone(dropout_action._model_loader)\n",
        "\n",
        "        try:\n",
        "            model = dropout_action(device=torch.device('cpu'))\n",
        "            self.assertTrue(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "        # Final testing\n",
        "        self.assertIsNotNone(dropout_action.params)\n",
        "        self.assertIsNotNone(dropout_action.action_state)\n",
        "        self.assertIsNotNone(dropout_action._model_loader)\n",
        "\n",
        "    def test_dropout_parameterize(self):\n",
        "        dropout_action = self.action_sampler[action_dropout]\n",
        "\n",
        "        # Prior Testing\n",
        "        self.assertIsInstance(dropout_action, Action)\n",
        "        self.assertTrue(dropout_action.params == {})\n",
        "        self.assertIsNone(dropout_action.action_state)\n",
        "        self.assertIsNone(dropout_action._model_loader)\n",
        "\n",
        "        # Test parameterization with the default action\n",
        "        dropout_action.parameterize(trial=self.trial)\n",
        "\n",
        "        # Posterior Testing\n",
        "        self.assertTrue(set(dropout_action.params.keys()), set(['activation', 'dropout_p']))\n",
        "        self.assertTrue(dropout_action.params['activation'] in [nn.ReLU, nn.PReLU, nn.SiLU])\n",
        "        self.assertTrue(0.0 <= dropout_action.params['dropout_p'] <= 1.0)\n",
        "        self.assertIsNone(dropout_action.action_state)\n",
        "        self.assertIsNotNone(dropout_action._model_loader)\n",
        "\n",
        "        # Model loading & testing\n",
        "        model = dropout_action(device=torch.device('cpu'))\n",
        "        self.assertEqual(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "        # Final testing\n",
        "        self.assertIsNotNone(dropout_action.params)\n",
        "        self.assertIsNone(dropout_action.action_state)\n",
        "        self.assertIsNotNone(dropout_action._model_loader)\n",
        "\n",
        "    def test_update_sig(self):\n",
        "        # Preparation\n",
        "        default_action = self.action_sampler[action_default]\n",
        "        dropout_action = self.action_sampler[action_dropout]\n",
        "\n",
        "        default_new_sig_params = {\n",
        "            'rand_number': [2]\n",
        "        }\n",
        "        dropout_new_sig_params = {\n",
        "            'activation': [1, 2],\n",
        "            'dropout_p': [0.45, 0.5, 0.72]\n",
        "        }\n",
        "\n",
        "        # TEST: default_action FOR: sig_dict\n",
        "        default_action.update_sig(update_params=default_new_sig_params)\n",
        "        self.assertIsInstance(default_action.get_var('rand_number'), Var)\n",
        "        self.assertTrue(default_action.get_var('rand_number').distribution() == [3])\n",
        "        self.assertTrue(default_action.get_var('rand_number').distribution(indices=True) == [2])\n",
        "\n",
        "        # TEST: dropout_action FOR: sig_dict\n",
        "        dropout_action.update_sig(update_params=dropout_new_sig_params)\n",
        "        self.assertIsInstance(dropout_action.get_var('activation'), Var)\n",
        "        self.assertTrue(dropout_action.get_var('activation').distribution() == [nn.PReLU, nn.SiLU],\n",
        "                        msg=f\"{dropout_action.get_var('activation').distribution()} != {[nn.PReLU, nn.SiLU]}\")\n",
        "        self.assertTrue(dropout_action.get_var('activation').distribution(True) == [1, 2],\n",
        "                        msg=f\"{dropout_action.get_var('activation').distribution(True)} != {[1, 2]}\")\n",
        "        self.assertIsInstance(dropout_action.get_var('dropout_p'), Var)\n",
        "        dropout_p_var = dropout_action.get_var('dropout_p')\n",
        "        self.assertTrue(dropout_p_var.distribution()['low'] == 0.45 and dropout_p_var.distribution()['high'] == 0.72)\n",
        "\n",
        "    # Additional method to test update_state if needed\n",
        "    def test_update_state(self):\n",
        "        for i in range(5):\n",
        "            default_action = self.action_sampler[action_default]\n",
        "            dropout_action = self.action_sampler[action_dropout]\n",
        "\n",
        "            if not i:\n",
        "                self.assertTrue(default_action.params == {})\n",
        "                self.assertIsNone(default_action.action_state)\n",
        "                self.assertIsNone(default_action._model_loader)\n",
        "\n",
        "                self.assertTrue(dropout_action.params == {})\n",
        "                self.assertIsNone(dropout_action.action_state)\n",
        "                self.assertIsNone(dropout_action._model_loader)\n",
        "            else:\n",
        "                self.assertFalse(default_action.params == {})\n",
        "                self.assertIsNotNone(default_action.action_state)\n",
        "                self.assertIsNotNone(default_action._model_loader)\n",
        "\n",
        "                self.assertFalse(dropout_action.params == {})\n",
        "                self.assertIsNotNone(dropout_action.action_state)\n",
        "                self.assertIsNotNone(dropout_action._model_loader)\n",
        "\n",
        "            default_action.parameterize(trial=self.trial)\n",
        "            dropout_action.parameterize(trial=self.trial)\n",
        "\n",
        "            default_model = default_action(device=torch.device('cpu'))\n",
        "            dropout_model = dropout_action(device=torch.device('cpu'))\n",
        "\n",
        "            self.assertEqual(default_model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "            self.assertEqual(dropout_model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "            default_action.update_state(obj=default_model)\n",
        "            dropout_action.update_state(obj=dropout_model)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9nYGFwtTzAh",
        "outputId": "58538833-a862-4e67-c9ef-5955d6cf62b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 18:31:39,084] A new study created in memory with name: no-name-8e163b81-eb16-4fbf-ad67-74fe362f85c7\n",
            ".[I 2024-09-19 18:31:39,231] A new study created in memory with name: no-name-efba4c8b-8bf1-4f45-9c88-c88eec405fa0\n",
            ".[I 2024-09-19 18:31:39,235] A new study created in memory with name: no-name-50b75d62-0825-4e36-8d0d-fb2bc74c4c36\n",
            ".[I 2024-09-19 18:31:39,311] A new study created in memory with name: no-name-63929eed-d7de-4979-b134-f8e2a59e8732\n",
            ".[I 2024-09-19 18:31:39,337] A new study created in memory with name: no-name-94d47efc-7583-412e-a827-36c5118973b4\n",
            ".[I 2024-09-19 18:31:39,346] A new study created in memory with name: no-name-554667dd-14c2-4ea8-8e06-503c934fcf50\n",
            ".[I 2024-09-19 18:31:39,354] A new study created in memory with name: no-name-110055c0-9650-4d3d-ba9a-822bfc99d0be\n",
            "...........[I 2024-09-19 18:31:39,453] A new study created in memory with name: no-name-53fa1e92-8068-4e8d-a917-00cb8533a6a0\n",
            "..[I 2024-09-19 18:31:39,464] A new study created in memory with name: no-name-dc9a2023-ed38-404f-ab15-0dfd93c09d17\n",
            ".....\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 0.402s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: ActionSampler"
      ],
      "metadata": {
        "id": "NpxMBQTBeH4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ActionSampler:\n",
        "    def __init__(self, INIT_ACTION_DICT: dict):\n",
        "        self.actions = dict()\n",
        "\n",
        "        for action_func,sig_dict in INIT_ACTION_DICT.items():\n",
        "            if not all(isinstance(var,Var) for var in sig_dict.values()):\n",
        "                raise ValueError(f\"Input dictionary for initializing object 'ActionSampler' with action_func: {action_func.__name__} has a non-Var value in it. Input Dictionary: {sig_dict}\")\n",
        "            self.actions[action_func] = Action(action_func=action_func, sig_dict=sig_dict)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.actions)\n",
        "\n",
        "    def __eq__(self, other: ActionSampler):\n",
        "        return isinstance(other, ActionSampler) and self.actions == other.actions\n",
        "\n",
        "    def __str__(self):\n",
        "        output = \"**********ActionSampler**********\\n\"\n",
        "        output += \"\".join([f\"{action}\\n\" for action in self.actions.values()])\n",
        "        return output\n",
        "\n",
        "    def get_action(self, action_func):\n",
        "        if action_func not in self.keys():\n",
        "            raise KeyError(f\"ActionSampler cannot retrieve Requested Action: {action_func.__name__ if callable(action_func) else action_func}, since it does NOT belong to: {self.keys()}\")\n",
        "        return self.actions[action_func]\n",
        "\n",
        "    def keys(self):\n",
        "        return self.actions.keys()\n",
        "\n",
        "    def values(self):\n",
        "        return self.actions.values()\n",
        "\n",
        "    def items(self):\n",
        "        return self.actions.items()\n",
        "\n",
        "    def sample(self, action_func: Callable, trial: Trial):\n",
        "        \"\"\"\n",
        "        SAMPLING THROUGH ActionSampler WILL ENFORCE THAT input 'trial'!=None.\n",
        "        (Much like the TrainSampler)\n",
        "        \"\"\"\n",
        "        if trial is not None and not isinstance(trial, (Trial, FrozenTrial)):\n",
        "            raise ValueError(f\"Input 'trial' should be an object optuna::Trial or optuna::FrozenTrial but found: {trial}\")\n",
        "        if trial is None:\n",
        "            raise ValueError(f\"Input 'trial' cannot be None when sampling is requested through ActionSampler. Either pass in as trial an active TrialOR manually build an Action function\")\n",
        "\n",
        "        #action <- Action object that encapsulates 'action_func'\n",
        "        action = self.get_action(action_func)\n",
        "\n",
        "        #Parameterize 'action'.\n",
        "        action.parameterize(trial=trial)\n",
        "\n",
        "        #RETURN: Fully parameterized 'action'.\n",
        "        #NOTE: 'action' could be either be sampled from 'trial' or loaded from saved signatures(if 'action' has a saved action_state or trial==None)\n",
        "        return action\n",
        "\n",
        "    def get_loadable_action(self, action_func: Callable, source):\n",
        "        \"\"\"\n",
        "        ASSUMPTION: source is a dictionary of parameters whose categorical values are all indices.\n",
        "        \"\"\"\n",
        "        if not isinstance(source, (Trial, FrozenTrial, dict)):\n",
        "            raise ValueError(f\"Input 'source' must be of type in (optuna::Trial, optuna::FrozenTrial, dict) but found: {source}\")\n",
        "\n",
        "        action = self.get_action(action_func)\n",
        "        #IF action has a saved 'action_state', THEN return action object.\n",
        "        if action.action_state:\n",
        "            return action\n",
        "\n",
        "        #source <- source.params if isinstance(Trial, FrozenTrial)\n",
        "        source = source if isinstance(source, dict) else source.params\n",
        "        #leftovers <- action.keys() that are not covered by source.keys()\n",
        "        leftovers = set(action.keys()) - set(source.keys())\n",
        "        if leftovers:\n",
        "            raise ValueError(f\"Action: {action_func.__name__} requires following missing keys in 'source': {leftovers}\")\n",
        "\n",
        "        #Recast the values of 'source' using action.items()\n",
        "        source = {key:var.convert_idx_to_val(idx=source[key]) for key,var in action.items()}\n",
        "\n",
        "        #OVERRIDE: action._model_loader\n",
        "        action._model_loader = partial(action_func, **source)\n",
        "\n",
        "        return action\n",
        "\n",
        "    def get_action_to_profile(self, list_params: list):\n",
        "        \"\"\"\n",
        "        TO BE CALLED IN Sampler.get_default_dict() AFTER .get_evaluated_params()\n",
        "        list_of_params := list of params produced by .get_evaluated_params() on each trial of top_k_trials.\n",
        "        \"\"\"\n",
        "        action_to_profile = defaultdict(lambda: defaultdict(list))\n",
        "        profiled_actions = set()\n",
        "        action_funcs = self.keys()\n",
        "\n",
        "        for params in list_params:\n",
        "            if 'action_func' not in params.keys(): continue\n",
        "            #action_func <- Callable 'action_func'\n",
        "            action_func = params['action_func']\n",
        "            #Sanity Check1:\n",
        "            assert action_func in action_funcs\n",
        "            #action <- Action object that reprs 'action_func'\n",
        "            action = self.get_action(action_func)\n",
        "            #Sanity Check2:\n",
        "            assert isinstance(action, Action)\n",
        "            #action_state <- state dictionary of the 'action' object.\n",
        "            action_state = action.action_state\n",
        "            params_sig_keys = set(params.keys() & action.keys())\n",
        "            params_train_keys = set(params.keys()) - params_sig_keys\n",
        "\n",
        "            #ERROR CHECKS:\n",
        "            if action_state and params_sig_keys:\n",
        "                raise ValueError(f\"Action: {action.action_func.__name__} has a saved action_state but 'params' has the following keys: {params_sig_keys}\")\n",
        "            if not action_state and params_sig_keys!=set(action.keys()):\n",
        "                raise ValueError(f\"Action: {action.action_func.__name__} does NOT have a saved action_state but params_sig_keys: {params_sig_keys} != action.keys(): {action.keys()}\")\n",
        "\n",
        "            #profile <- Dict of lists according to the 'action_func'\n",
        "            profile = action_to_profile[action_func]\n",
        "            profile.update({key:profile[key] + [val] for key,val in params.items() if key in params_sig_keys})\n",
        "            if action_func not in profiled_actions:\n",
        "                profiled_actions.add(action_func)\n",
        "                profile.update({key:profile[key] + [val] for key,val in params.items() if key in params_train_keys})\n",
        "\n",
        "        return action_to_profile\n",
        "\n",
        "    def update_vars(self, action_to_profile: dict):\n",
        "        for action_func,profile in action_to_profile.items():\n",
        "            self.get_action(action_func).update_sig(update_params=profile)\n",
        "\n",
        "    def update_states(self, action_to_profile: dict, model_train_window: int, device: torch.device):\n",
        "        m = model_train_window\n",
        "\n",
        "        for action_func, profile in list(action_to_profile.items())[:m]:\n",
        "            #default_dict <- only the best value(s) for each (signature)parameter extracted.\n",
        "            default_dict = {var_type:vals[0] for var_type,vals in profile.items()}\n",
        "            #action <- loadable action created with best signature parameters\n",
        "            action = self.get_loadable_action(\n",
        "                action_func=action_func,\n",
        "                source=default_dict\n",
        "            )\n",
        "\n",
        "            assert action.is_loadable(), f\"action: {action}\"\n",
        "\n",
        "            #UPDATE: 'default_dict' with ('action_func'->manual_action)\n",
        "            default_dict.update({'action_func':action})\n",
        "\n",
        "            trainer, learner = Wrapper(\n",
        "                trial=None,\n",
        "                sampler=None,\n",
        "                device=device,\n",
        "                default_dict=default_dict\n",
        "            ).yield_execution_set()\n",
        "            trainer()\n",
        "            action.update_state(obj=learner)"
      ],
      "metadata": {
        "id": "7F91cihMfry0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test: ActionSampler"
      ],
      "metadata": {
        "id": "Ihwh3f14Wl_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelDefault(nn.Module):\n",
        "    def __init__(self, rand_number: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Linear(16,10)\n",
        "        self.rand_number = torch.tensor(rand_number)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x) + self.rand_number\n",
        "\n",
        "class ModelDropout(nn.Module):\n",
        "    def __init__(self, activation: nn.Module, dropout_p: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=16,out_features=10),\n",
        "            activation(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "            nn.Linear(in_features=10,out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def action_default(rand_number: int, device: torch.device):\n",
        "    return ModelDefault(rand_number=rand_number).to(device)\n",
        "\n",
        "def action_dropout(activation, dropout_p, device: torch.device):\n",
        "    #model_dropout := Class header of 'ModelDropout'\n",
        "    return ModelDropout(activation=activation, dropout_p=dropout_p).to(device)\n",
        "\n",
        "#Wrapper <- Mock object\n",
        "#NOTE: Details of this object will be filled in the next cell(inside test(s) of 'TestActionSampler')\n",
        "Wrapper = Mock()"
      ],
      "metadata": {
        "id": "tNhUlYpwrQBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestActionSampler(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.INIT_DICT = {\n",
        "            'rand_number': Var(var_type='rand_number', source={'params': {'choices': list(range(1, 11))}, 'sample': 'categorical'}),\n",
        "            'activation': Var(var_type='activation', source={'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]}, 'sample': 'categorical'}),\n",
        "            'dropout_p': Var(var_type='dropout_p', source={'params': {'low': 0.0, 'high': 1.0}, 'sample': 'float'})\n",
        "        }\n",
        "\n",
        "        action_to_sig = {func: set(signature(func).parameters.keys()) - {'device'} for func in [action_default, action_dropout]}\n",
        "        self.INIT_ACTION_DICT = {func: {key: self.INIT_DICT[key] for key in sig} for func, sig in action_to_sig.items()}\n",
        "        self.trial = optuna.create_study(direction='minimize').ask()\n",
        "\n",
        "    def test_initialization(self):\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        self.assertEqual(len(action_sampler.actions), 2)\n",
        "        self.assertIn(action_default, action_sampler.actions)\n",
        "        self.assertIn(action_dropout, action_sampler.actions)\n",
        "        self.assertTrue(all(isinstance(action, Action) for action in action_sampler.actions.values()))\n",
        "\n",
        "        default_sig_dict = {'rand_number': Var(var_type='rand_number', source={'params': {'choices': list(range(1, 11))}, 'sample': 'categorical'})}\n",
        "        dropout_sig_dict = {\n",
        "            'activation': Var(var_type='activation', source={'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]}, 'sample': 'categorical'}),\n",
        "            'dropout_p': Var(var_type='dropout_p', source={'params': {'low': 0.0, 'high': 1.0}, 'sample': 'float'})\n",
        "        }\n",
        "\n",
        "        self.assertTrue(action_sampler.get_action(action_default) == Action(action_default, default_sig_dict))\n",
        "        self.assertTrue(action_sampler.get_action(action_dropout) == Action(action_dropout, dropout_sig_dict))\n",
        "\n",
        "    def test_sample_action(self):\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        for func in [action_default, action_dropout]:\n",
        "            sampled_action = action_sampler.sample(\n",
        "                action_func=func,\n",
        "                trial=optuna.create_study(direction='minimize').ask()\n",
        "            )\n",
        "            self.assertIsInstance(sampled_action, Action)\n",
        "            expected_keys = ['rand_number'] if func == action_default else ['activation', 'dropout_p']\n",
        "            self.assertTrue(set(sampled_action.params.keys()) == set(expected_keys))\n",
        "            self.assertTrue(set(sampled_action._model_loader.keywords.keys()) == set(expected_keys))\n",
        "            self.assertIsNone(sampled_action.action_state)\n",
        "            model = sampled_action(device=torch.device('cpu'))\n",
        "            self.assertIsInstance(model, nn.Module)\n",
        "            self.assertEqual(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "    def test_get_loadable_action_with_dict(self):\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        for func in [action_default, action_dropout]:\n",
        "            loadable_action = action_sampler.get_loadable_action(\n",
        "                action_func=func,\n",
        "                source={'rand_number': 1} if func == action_default else {'activation': 0, 'dropout_p': 0.5}\n",
        "            )\n",
        "            self.assertIsInstance(loadable_action, Action)\n",
        "            self.assertTrue(\n",
        "                set(loadable_action._model_loader.keywords.keys()) == set(['rand_number']) if func == action_default else set(['activation', 'dropout_p']),\n",
        "                msg=f\"loadable_action._model_loader.keywords: {loadable_action._model_loader.keywords}\"\n",
        "            )\n",
        "            self.assertIsNone(loadable_action.action_state)\n",
        "            model = loadable_action(device=torch.device('cpu'))\n",
        "            self.assertIsInstance(model, nn.Module)\n",
        "            self.assertEqual(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "    def test_get_loadable_action_with_trial(self):\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        for func in [action_default, action_dropout]:\n",
        "            trial = optuna.create_study(direction='minimize').ask()\n",
        "            dummy = action_sampler.sample(action_func=func, trial=trial)  # Sample to simulate state changes.\n",
        "            loadable_action = action_sampler.get_loadable_action(\n",
        "                action_func=func,\n",
        "                source=trial\n",
        "            )\n",
        "            self.assertIsInstance(loadable_action, Action)\n",
        "            expected_keys = ['rand_number'] if func == action_default else ['activation', 'dropout_p']\n",
        "            self.assertTrue(set(loadable_action.params.keys()) == set(expected_keys),\n",
        "                            msg=f\"loadable_action.params: {loadable_action.params}\")\n",
        "            self.assertTrue(set(loadable_action._model_loader.keywords.keys()) == set(expected_keys),\n",
        "                            msg=f\"loadable_action._model_loader.keywords: {loadable_action._model_loader.keywords}\")\n",
        "            self.assertIsNone(loadable_action.action_state)\n",
        "            model = loadable_action(device=torch.device('cpu'))\n",
        "            self.assertIsInstance(model, nn.Module)\n",
        "            self.assertEqual(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "    def test_sample_with_invalid_trial(self):\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        with self.assertRaises(ValueError):\n",
        "            action_sampler.sample(action_default, None)\n",
        "        with self.assertRaises(ValueError):\n",
        "            action_sampler.sample(action_dropout, None)\n",
        "\n",
        "        # Test sampling with invalid trial type\n",
        "        with self.assertRaises(ValueError):\n",
        "            action_sampler.sample(action_default, \"invalid_trial\")\n",
        "        with self.assertRaises(ValueError):\n",
        "            action_sampler.sample(action_dropout, \"invalid_trial\")\n",
        "\n",
        "    def test_get_action_to_profile(self):\n",
        "        list_params = [\n",
        "            {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "            {'action_func': action_default, 'rand_number': 1, 'lr': 1e-2, 'n_epoch': 12},\n",
        "            {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "            {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20},\n",
        "            {'action_func': action_default, 'rand_number': 3, 'lr': 2e-3, 'n_epoch': 1}\n",
        "        ]\n",
        "\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        action_to_profile = action_sampler.get_action_to_profile(list_params=list_params)\n",
        "\n",
        "        for action_func, profile in action_to_profile.items():\n",
        "            self.assertIn(action_func, action_sampler.keys())\n",
        "\n",
        "            if action_func == action_default:\n",
        "                self.assertEqual(profile['rand_number'], [1, 1, 3], msg=f\"profile['rand_number']: {profile['rand_number']}\")\n",
        "                self.assertEqual(profile['lr'], [1e-2], msg=f\"profile['lr']: {profile['lr']}\")\n",
        "                self.assertEqual(profile['n_epoch'], [12], msg=f\"profile['n_epoch']: {profile['n_epoch']}\")\n",
        "            else:\n",
        "                self.assertEqual(profile['dropout_p'], [0.78, 0.123], msg=f\"profile['dropout_p']: {profile['dropout_p']}\")\n",
        "                self.assertEqual(profile['activation'], [1, 2], msg=f\"profile['activation']: {profile['activation']}\")\n",
        "                self.assertEqual(profile['lr'], [1e-1], msg=f\"profile['lr']: {profile['lr']}\")\n",
        "                self.assertEqual(profile['n_epoch'], [10], msg=f\"profile['n_epoch']: {profile['n_epoch']}\")\n",
        "\n",
        "    def test_update_vars(self):\n",
        "        list_params = [\n",
        "            {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "            {'action_func': action_default, 'rand_number': 1, 'lr': 1e-2, 'n_epoch': 12},\n",
        "            {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "            {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20},\n",
        "            {'action_func': action_default, 'rand_number': 3, 'lr': 2e-3, 'n_epoch': 1}\n",
        "        ]\n",
        "        action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "        action_to_profile = action_sampler.get_action_to_profile(list_params=list_params)\n",
        "        action_sampler.update_vars(action_to_profile)\n",
        "\n",
        "        # Check the updated variables for action_default\n",
        "        default_action = action_sampler.get_action(action_default)\n",
        "        rand_var = Var(var_type='rand_number', source={'params': {'choices': list(range(1, 11))}, 'sample': 'categorical'})\n",
        "        rand_var._dist = [1, 1, 3]\n",
        "        self.assertEqual(default_action.sig_dict, {'rand_number': rand_var}, msg=f\"default_action.sig_dict: {default_action.sig_dict}\")\n",
        "\n",
        "        # Check the updated variables for action_dropout\n",
        "        dropout_action = action_sampler.get_action(action_dropout)\n",
        "        activation_var = Var(var_type='activation', source={'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]}, 'sample': 'categorical'})\n",
        "        activation_var._dist = [1, 2]\n",
        "        dropout_p_var = Var(var_type='dropout_p', source={'params': {'low': 0.0, 'high': 1.0}, 'sample': 'float'})\n",
        "        dropout_p_var._dist = {'low': 0.123, 'high': 0.78}\n",
        "        self.assertTrue(dropout_action.get_var('activation') == activation_var,\n",
        "                        msg=f\"dropout_action['activation']: {dropout_action.get_var('activation')} != \\nactivation_var: {activation_var}\")\n",
        "        self.assertTrue(dropout_action.get_var('dropout_p') == dropout_p_var,\n",
        "                        msg=f\"dropout_action['dropout_p']: {dropout_action.get_var('dropout_p')} != \\ndropout_p_var: {dropout_p_var}\")\n",
        "\n",
        "    def mock_wrapper_init(self, trial, default_dict, sampler, device):\n",
        "        action = default_dict['action_func']\n",
        "        self.assertIsInstance(action, Action)\n",
        "        self.assertIsNotNone(action.params)\n",
        "        self.assertIsNone(action.action_state)\n",
        "        self.assertIsNotNone(action._model_loader)\n",
        "\n",
        "        # Create the model after checking action is valid\n",
        "        model = action(device=device)\n",
        "        self.assertIsInstance(model, nn.Module)\n",
        "        self.assertEqual(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "        trainer = Mock()\n",
        "        trainer.side_effect = lambda: [param.data.fill_(0) for param in model.parameters()]\n",
        "\n",
        "        execution_set = Mock()\n",
        "        execution_set.yield_execution_set.return_value = (trainer, model)\n",
        "\n",
        "        return execution_set\n",
        "\n",
        "    def produce_saved_bools(self, action_sampler: ActionSampler):\n",
        "        dropout_action = action_sampler.get_action(action_dropout)\n",
        "        default_action = action_sampler.get_action(action_default)\n",
        "        default_saved = default_action.action_state is not None\n",
        "        dropout_saved = dropout_action.action_state is not None\n",
        "\n",
        "        if default_saved:\n",
        "            for param_tensor in default_action.action_state.values():\n",
        "                if param_tensor.numel() > 0:  # Check tensor is not empty\n",
        "                    default_saved &= torch.all(param_tensor == 0).item()\n",
        "        if dropout_saved:\n",
        "            for param_tensor in dropout_action.action_state.values():\n",
        "                if param_tensor.numel() > 0:  # Check tensor is not empty\n",
        "                    dropout_saved &= torch.all(param_tensor == 0).item()\n",
        "        return default_saved, dropout_saved\n",
        "\n",
        "    def test_update_states(self):\n",
        "        param_sets = [\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-2, 'n_epoch': 12},\n",
        "                    {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20},\n",
        "                    {'action_func': action_default, 'rand_number': 3, 'lr': 2e-3, 'n_epoch': 1},\n",
        "                ],\n",
        "                'model_train_window': 1,\n",
        "                'xy': (False, True)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-2, 'n_epoch': 12},\n",
        "                    {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "                    {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20},\n",
        "                    {'action_func': action_default, 'rand_number': 3, 'lr': 2e-3, 'n_epoch': 1},\n",
        "                ],\n",
        "                'model_train_window': 1,\n",
        "                'xy': (True, False)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-2, 'n_epoch': 12},\n",
        "                    {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20},\n",
        "                    {'action_func': action_default, 'rand_number': 3, 'lr': 2e-3, 'n_epoch': 1},\n",
        "                ],\n",
        "                'model_train_window': 2,\n",
        "                'xy': (True, True)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "                    {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20}\n",
        "                ],\n",
        "                'model_train_window': 2,\n",
        "                'xy': (True, True)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': action_dropout, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 10},\n",
        "                    {'action_func': action_dropout, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 14},\n",
        "                    {'action_func': action_default, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 20}\n",
        "                ],\n",
        "                'model_train_window': 0,\n",
        "                'xy': (False, False)\n",
        "            }\n",
        "        ]\n",
        "\n",
        "        for params in param_sets:\n",
        "            action_sampler = ActionSampler(INIT_ACTION_DICT=self.INIT_ACTION_DICT)\n",
        "            Wrapper.side_effect = self.mock_wrapper_init\n",
        "            list_params, model_train_window, xy_label = params['params'], params['model_train_window'], params['xy']\n",
        "\n",
        "            action_to_profile = action_sampler.get_action_to_profile(list_params=list_params)\n",
        "            action_sampler.update_vars(action_to_profile)\n",
        "            action_sampler.update_states(action_to_profile, model_train_window, torch.device('cpu'))\n",
        "\n",
        "            xy = self.produce_saved_bools(action_sampler)\n",
        "            self.assertEqual(xy, xy_label)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp90cX_XVmsQ",
        "outputId": "29397fd7-4940-490d-f424-65f311012b18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 18:31:39,689] A new study created in memory with name: no-name-9e234d3b-75ea-42e8-847a-97c4b65fdc30\n",
            ".[I 2024-09-19 18:31:39,706] A new study created in memory with name: no-name-d4b0df41-f48e-4483-9c79-299bad775dcb\n",
            ".[I 2024-09-19 18:31:39,714] A new study created in memory with name: no-name-e9b7534d-8f53-4668-a2fc-bab72e6a1903\n",
            ".[I 2024-09-19 18:31:39,724] A new study created in memory with name: no-name-4e4d8457-f988-4ff8-bedc-86df201b9d78\n",
            ".[I 2024-09-19 18:31:39,734] A new study created in memory with name: no-name-43dcca95-26f9-412f-99c9-aabc08a77cd0\n",
            ".[I 2024-09-19 18:31:39,752] A new study created in memory with name: no-name-bb216d04-0cc3-4631-b211-8e7aa69efc61\n",
            ".[I 2024-09-19 18:31:39,757] A new study created in memory with name: no-name-ce51d104-bc0c-4cd2-9694-37327a23803b\n",
            ".[I 2024-09-19 18:31:39,780] A new study created in memory with name: no-name-47df1a3f-e1ac-47a3-9238-ecefa5e7452c\n",
            ".[I 2024-09-19 18:31:39,786] A new study created in memory with name: no-name-795c3230-7e2f-4d69-801d-d6a10b4e77f2\n",
            ".[I 2024-09-19 18:31:39,796] A new study created in memory with name: no-name-6dc58618-ef3e-4f8b-8091-84ae054b5c5d\n",
            "[I 2024-09-19 18:31:39,799] A new study created in memory with name: no-name-7786e6d8-686a-4d86-b5cf-36ee12e5c954\n",
            "[I 2024-09-19 18:31:39,804] A new study created in memory with name: no-name-80d5bd52-3143-4c90-947e-091f829fc160\n",
            ".[I 2024-09-19 18:31:39,813] A new study created in memory with name: no-name-c54ba005-163e-4c59-b5e0-ccfa4f13f975\n",
            ".[I 2024-09-19 18:31:39,818] A new study created in memory with name: no-name-f3782f3e-a0e2-428b-a44c-543b8175bab7\n",
            "[I 2024-09-19 18:31:39,823] A new study created in memory with name: no-name-41d22678-0bac-42c3-865e-6b8e3dfb67a5\n",
            "[I 2024-09-19 18:31:39,835] A new study created in memory with name: no-name-412b09fb-9d55-441e-9921-7a7b4a16d259\n",
            ".[I 2024-09-19 18:31:39,847] A new study created in memory with name: no-name-c51d8a7d-c27d-4682-a2b2-a76c89f9d7e9\n",
            ".[I 2024-09-19 18:31:39,856] A new study created in memory with name: no-name-0add9c73-c815-4f72-b1d4-7f9ff5c31449\n",
            ".[I 2024-09-19 18:31:39,930] A new study created in memory with name: no-name-a50e2279-fc25-4f61-99b5-bc1b8737e7dd\n",
            "...........[I 2024-09-19 18:31:40,012] A new study created in memory with name: no-name-eba75738-44d7-432a-bd03-6602b731ed8e\n",
            "..[I 2024-09-19 18:31:40,035] A new study created in memory with name: no-name-04d5115d-4fe1-4c53-9025-283a677fcf32\n",
            ".....\n",
            "----------------------------------------------------------------------\n",
            "Ran 32 tests in 0.387s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: TrainSampler"
      ],
      "metadata": {
        "id": "EqVpt_tceM-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainSampler:\n",
        "    def __init__(self, INIT_TRAIN_DICT: dict):\n",
        "        if not all(isinstance(var,Var) for var in INIT_TRAIN_DICT.values()):\n",
        "            raise ValueError(f\"Input dictionary for initializing object 'TrainSampler' has a non-Var value in it. Input dictionary: {INIT_TRAIN_DICT}\")\n",
        "        self.sample_dict = {cat:val for cat,val in INIT_TRAIN_DICT.items()}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_dict)\n",
        "\n",
        "    def __eq__(self, other: TrainSampler):\n",
        "        return isinstance(other, TrainSampler) and self.sample_dict == other.sample_dict\n",
        "\n",
        "    def __str__(self):\n",
        "        output = \"**********TrainSampler**********\\n\"\n",
        "        output += \"\".join([f\"{var}\\n\" for var in self.sample_dict.values()])\n",
        "        return output\n",
        "\n",
        "    def get_var(self, var_type):\n",
        "        if var_type not in self.keys():\n",
        "            raise KeyError(f\"Requested 'var_type': {var_type} is not in train keys: {self.keys()}.\")\n",
        "        return self.sample_dict[var_type]\n",
        "\n",
        "    def keys(self):\n",
        "        return self.sample_dict.keys()\n",
        "\n",
        "    def values(self):\n",
        "        return self.sample_dict.values()\n",
        "\n",
        "    def items(self):\n",
        "        return self.sample_dict.items()\n",
        "\n",
        "    def is_fixed(self):\n",
        "        return all(var.fixed for var in self.values())\n",
        "\n",
        "    def get_evaluated_params(self, source):\n",
        "        if not isinstance(source, (Trial, FrozenTrial, dict)):\n",
        "            raise ValueError(f\"Input 'source' must be of type in (optuna::Trial, optuna::FrozenTrial, dict) but found: {source}\")\n",
        "\n",
        "        source = source if isinstance(source, dict) else source.params\n",
        "\n",
        "        #return source | {var_type:self.get_var(var_type).convert_idx_to_val(source[var_type]) for var_type in self.keys()&source.keys()}\n",
        "        return source | {var_type:self.get_var(var_type).convert_idx_to_val(idx) for var_type,idx in source.items() if var_type in self.keys()}\n",
        "\n",
        "    def sample(self, var_type: str, trial):\n",
        "        if trial is not None and not isinstance(trial, (Trial, FrozenTrial)):\n",
        "            raise ValueError(f\"Input 'trial' should be an instance of optuna::Trial OR optuna::FrozenTrial but found: {trial}\")\n",
        "        if trial is None:\n",
        "            raise ValueError(\"Input 'trial' CANNOT be 'None'. Make sure to throw in optuna::Trial OR optuna::FrozenTrial\")\n",
        "        if var_type not in self.keys():\n",
        "            raise ValueError(f\"Requested var_type: {var_type} does NOT exist in the called TrainSampler!\")\n",
        "\n",
        "        #sampled_val <- value (of category 'var_type') sampled from 'sample_dict' with trial 'trial'.\n",
        "        sampled_val = self.get_var(var_type).sample(trial=trial)\n",
        "\n",
        "        return sampled_val\n",
        "\n",
        "    def update_vars(self, top_k_trials: list):\n",
        "        #Acc over the list of trials for each parameter key.\n",
        "        for key,var in self.items():\n",
        "            var.update(vals=[trial.params[key] for trial in top_k_trials if key in trial.params.keys()])"
      ],
      "metadata": {
        "id": "rIdylV13-qhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: Sampler"
      ],
      "metadata": {
        "id": "aT-F4CO5z0CH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sampler:\n",
        "    def __init__(self, INIT_DICT: dict):\n",
        "        #Preprocessing:\n",
        "        init_keys = set(INIT_DICT.keys())\n",
        "        self._sig_keys = set()\n",
        "        INIT_ACTION_DICT = dict()\n",
        "\n",
        "        for action_func in set(INIT_DICT['action_func']['params']['choices']):\n",
        "            sig = set(signature(action_func).parameters.keys()) - {'device'}\n",
        "            leftovers = sig - init_keys\n",
        "            if leftovers:\n",
        "                raise ValueError(f\"Missing keys for parameterizing '{action_func.__name__}': [{leftovers}]. Required keys: {sig}, provided keys: {init_keys}.\")\n",
        "            #INIT_ACTION_DICT[action_func] <- Dictionary of mappings (var_type->Var ) for every var_type in 'sig'.\n",
        "            INIT_ACTION_DICT[action_func] = {var_type:Var(var_type=var_type,source=INIT_DICT[var_type]) for var_type in sig}\n",
        "            #self.sig_keys <- Union(self.action_keys, sig)\n",
        "            self._sig_keys |= sig\n",
        "\n",
        "        #INIT_TRAIN_DICT <- {(var_type->Var )|var_type NOT IN action_keys}\n",
        "        INIT_TRAIN_DICT = {var_type:Var(var_type=var_type,source=INIT_DICT[var_type]) for var_type in init_keys-self._sig_keys}\n",
        "\n",
        "        #train_keys <- all the keys that belong to the TrainSampler's space.\n",
        "        train_keys = set(INIT_TRAIN_DICT.keys())\n",
        "\n",
        "        #Make sure that 'action_func' is in 'INIT_DICT_TRAIN'.\n",
        "        if 'action_func' not in train_keys:\n",
        "            raise ValueError(\"Reconstructed 'INIT_TRAIN_DICT' must have 'action_func' as a valid key but not found.\")\n",
        "\n",
        "        #Declare two Samplers, after pre-processing is done.\n",
        "        self.action_sampler = ActionSampler(INIT_ACTION_DICT=INIT_ACTION_DICT)\n",
        "        self.train_sampler = TrainSampler(INIT_TRAIN_DICT=INIT_TRAIN_DICT)\n",
        "        #Fix the hidden_keys\n",
        "        self._sig_keys = frozenset(self._sig_keys)\n",
        "\n",
        "    def __str__(self):\n",
        "        output = \"Sampler:\\n\"\n",
        "        output += f\"{self.action_sampler}\\n\"\n",
        "        return output + f\"{self.train_sampler}\\n\"\n",
        "\n",
        "    def get_action(self, action_func) -> Action:\n",
        "        action_func_var = self.get_var('action_func')\n",
        "        action_func = action_func_var.convert_idx_to_val(action_func) if isinstance(action_func, int) else action_func\n",
        "        return self.action_sampler.get_action(action_func)\n",
        "\n",
        "    def get_var(self, var_type, sig_var_type=None) -> Var:\n",
        "        #sig_var_type is None <-> var_type in self.train_sampler.keys()\n",
        "        if sig_var_type is None:\n",
        "            return self.train_sampler.get_var(var_type)\n",
        "\n",
        "        action = self.get_action(action_func=var_type)  # Get the associated action\n",
        "        return action.get_var(var_type=sig_var_type)\n",
        "\n",
        "    ###Inherited Methods:\n",
        "    def convert_idx_to_val(self, var_type, sig_var_type_or_idx, idx=None):\n",
        "        if idx is None:\n",
        "            return self.get_var(var_type).convert_idx_to_val(idx=sig_var_type_or_idx)\n",
        "        return self.get_var(var_type, sig_var_type_or_idx).convert_idx_to_val(idx=idx)\n",
        "\n",
        "    def convert_val_to_idx(self, var_type, sig_var_type_or_val, val=None):\n",
        "        if val is None:\n",
        "            return self.get_var(var_type).convert_val_to_idx(val=sig_var_type_or_val)\n",
        "        return self.get_var(var_type, sig_var_type_or_val).convert_val_to_idx(val=val)\n",
        "\n",
        "    def contain_idx(self, var_type, sig_var_type_or_idx, idx=None):\n",
        "        if idx is None:\n",
        "            return self.get_var(var_type).contain_idx(sig_var_type_or_idx)\n",
        "        return self.get_var(var_type, sig_var_type_or_idx).contain_idx(idx)\n",
        "\n",
        "    def contain_val(self, var_type, sig_var_type_or_val, val=None):\n",
        "        if val is None:\n",
        "            return self.get_var(var_type).contain_val(sig_var_type_or_val)\n",
        "        return self.get_var(var_type,sig_var_type_or_val).contain_val(val)\n",
        "    ###Inherited Methods:\n",
        "\n",
        "    def sig_keys(self):\n",
        "        return self._sig_keys\n",
        "\n",
        "    def train_keys(self):\n",
        "        return self.train_sampler.keys()\n",
        "\n",
        "    def action_funcs(self):\n",
        "        return self.action_sampler.keys()\n",
        "\n",
        "    def is_fixed(self):\n",
        "        action_func = self.get_var('action_func').distribution()[0]\n",
        "        action = self.get_action(action_func)\n",
        "        return self.train_sampler.is_fixed() and action.is_fixed()\n",
        "\n",
        "    def sample(self, var_type: str, trial: Trial, default_val = None):\n",
        "        \"\"\"\n",
        "        For the sampling to be done properly, the trial == optuna::Trial\n",
        "        (IF trial==None, THEN default_val will be returned)\n",
        "        \"\"\"\n",
        "        train_keys = self.train_keys()\n",
        "        action_funcs = self.action_funcs()\n",
        "        var = self.get_var(var_type)\n",
        "        valid_trial = trial is not None and isinstance(trial, (Trial, FrozenTrial))\n",
        "        #NOTE: Any 'default_val' that gets passed into Sampler.sample MUST be in its current distribution.\n",
        "        if not valid_trial and not var.contain_val(default_val):\n",
        "            raise ValueError(f\"Var of type: {var_type} CANNOT produce the given 'default_val': {default_val} since its current distribution is: {var.distribution()}\")\n",
        "        if not valid_trial:\n",
        "            #IF NOT valid_trial YET 'default_val' IS in the Var:var_type's distribution,\n",
        "            #THEN return 'default_val'\n",
        "            return default_val\n",
        "\n",
        "        #sampled_val <- sampled value of type: var_type from: self.train_sampler\n",
        "        sampled_val = self.train_sampler.sample(var_type=var_type, trial=trial)\n",
        "        #IF 'sampled_val' is NOT one of the action_func(s), THEN return the sampled result.\n",
        "        if sampled_val not in action_funcs:\n",
        "            return sampled_val\n",
        "        #ELSE, sample from internal action sampler. This will return a fully parameterized Action object.\n",
        "        return self.action_sampler.sample(action_func=sampled_val, trial=trial)\n",
        "\n",
        "    def get_action_to_profile(self, top_k_trials: list):\n",
        "        list_params = [self.train_sampler.get_evaluated_params(source=trial) for trial in top_k_trials]\n",
        "        action_to_profile = self.action_sampler.get_action_to_profile(list_params=list_params)\n",
        "        return action_to_profile\n",
        "\n",
        "    def update(self, top_k_trials: list, model_train_window: int, device: torch.device):\n",
        "        #UPDATE: train_sampler\n",
        "        self.train_sampler.update_vars(top_k_trials=top_k_trials)\n",
        "\n",
        "        #PRODUCE: action_to_profile\n",
        "        #UPDATE: action_sampler Var(s) WITH: action_to_profile\n",
        "        action_to_profile = self.get_action_to_profile(top_k_trials=top_k_trials)\n",
        "        self.action_sampler.update_vars(action_to_profile=action_to_profile)\n",
        "\n",
        "        #UPDATE: action_sampler WITH: action_to_profile\n",
        "        self.action_sampler.update_states(\n",
        "            action_to_profile=action_to_profile,\n",
        "            model_train_window=min(model_train_window, len(action_to_profile)),\n",
        "            device=device\n",
        "        )"
      ],
      "metadata": {
        "id": "3Q2iknmxznF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test: Sampler\n",
        "\n"
      ],
      "metadata": {
        "id": "YbHQetChF_yV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelDefault(nn.Module):\n",
        "    def __init__(self, rand_number: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Linear(16,10)\n",
        "        self.rand_number = torch.tensor(rand_number)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x) + self.rand_number\n",
        "\n",
        "class ModelDropout(nn.Module):\n",
        "    def __init__(self, activation: nn.Module, dropout_p: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=16,out_features=10),\n",
        "            activation(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "            nn.Linear(in_features=10,out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class ModelDropoutVariant(nn.Module):\n",
        "    \"\"\"\n",
        "    Same parameters as ModelDropout. This model will be used in the test\n",
        "    to check the independence of signature Var(s).\n",
        "    i.e. IF different values were thrown into .update() of ModelDropout VS ModelDropoutVariant,\n",
        "         THEN their signature Var(s), though they have the same var_type, ._frozen_dist, they WILL BE TREATED AS DIFFERENT/INDEPENDENT objects.\n",
        "    \"\"\"\n",
        "    def __init__(self, activation: nn.Module, dropout_p: int):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=16,out_features=10),\n",
        "            activation(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "            nn.Linear(in_features=10,out_features=10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "def action_default(rand_number: int, device: torch.device):\n",
        "    return ModelDefault(rand_number=rand_number).to(device)\n",
        "\n",
        "def action_dropout(activation, dropout_p, device: torch.device):\n",
        "    #model_dropout := Class header of 'ModelDropout'\n",
        "    return ModelDropout(activation=activation, dropout_p=dropout_p).to(device)\n",
        "\n",
        "def action_dropout_variant(activation, dropout_p, device: torch.device):\n",
        "    #model_dropout := Class header of 'ModelDropout'\n",
        "    return ModelDropout(activation=activation, dropout_p=dropout_p).to(device)\n",
        "\n",
        "#To be used in the next cell, to imitate the list of frozen optuna.Trial(s).\n",
        "optimized_study = Mock()"
      ],
      "metadata": {
        "id": "A26isaxcoXe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestSampler(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.INIT_DICT = {\n",
        "            'action_func': {\n",
        "                'params': {\n",
        "                    'choices': [action_default, action_dropout, action_dropout_variant]\n",
        "                },\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'rand_number': {\n",
        "                'params': {\n",
        "                    'choices': list(range(1, 11))\n",
        "                },\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'activation': {\n",
        "                'params': {\n",
        "                    'choices': [nn.ReLU, nn.PReLU, nn.SiLU]\n",
        "                },\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'dropout_p': {\n",
        "                'params': {\n",
        "                    'low': 0.0,\n",
        "                    'high': 1.0\n",
        "                },\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'lr': {\n",
        "                'params': {\n",
        "                    'low': 1e-4,\n",
        "                    'high': 1e-2,\n",
        "                    'log': True\n",
        "                },\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'wd': {\n",
        "                'params': {\n",
        "                    'low': 1e-4,\n",
        "                    'high': 1e-1,\n",
        "                    'log': True\n",
        "                },\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'batch_size': {\n",
        "                'params': {\n",
        "                    'choices': [32, 64, 128, 256]\n",
        "                },\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'n_epoch': {\n",
        "                'params': {\n",
        "                    'choices': [5, 10, 15]\n",
        "                },\n",
        "                'sample': 'categorical'\n",
        "            }\n",
        "        }\n",
        "        self.trial = optuna.create_study(direction='minimize').ask()\n",
        "\n",
        "    def test_initialization(self):\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "\n",
        "        # Check keys and contents after initialization\n",
        "        self.assertEqual(sampler.sig_keys(), frozenset(['rand_number', 'activation', 'dropout_p']))\n",
        "        self.assertEqual(sampler.action_funcs(), set([action_default, action_dropout, action_dropout_variant]))\n",
        "        self.assertEqual(sampler.train_keys(), set(['action_func', 'lr', 'wd', 'batch_size', 'n_epoch']))\n",
        "\n",
        "        #Check action sampler\n",
        "        expected_action_sampler = self.make_action_sampler(\n",
        "            rand_choices=list(range(1, 11)),\n",
        "            activation_choices=[nn.ReLU, nn.PReLU, nn.SiLU],\n",
        "            dropout_tuple=(0.0, 1.0)\n",
        "        )\n",
        "        self.assertEqual(sampler.action_sampler, expected_action_sampler)\n",
        "\n",
        "        #Check train sampler\n",
        "        expected_train_sampler = self.make_train_sampler(\n",
        "            action_func_choices=[action_default, action_dropout, action_dropout_variant],\n",
        "            lr_tuple=(1e-4, 1e-2),\n",
        "            wd_tuple=(1e-4, 1e-1),\n",
        "            batch_size_choices=[32, 64, 128, 256],\n",
        "            n_epoch_choices=[5, 10, 15]\n",
        "        )\n",
        "        self.assertEqual(sampler.train_sampler, expected_train_sampler)\n",
        "\n",
        "    def test_sample(self):\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        self.assertTrue(sampler.sig_keys() == frozenset(['rand_number', 'activation', 'dropout_p']))\n",
        "        self.assertTrue(sampler.action_funcs() == set([action_default, action_dropout, action_dropout_variant]))\n",
        "        self.assertTrue(sampler.train_keys() == set(['action_func', 'lr', 'wd', 'batch_size', 'n_epoch']))\n",
        "\n",
        "        for key in sampler.sig_keys():\n",
        "            with self.assertRaises(KeyError):\n",
        "                sampler.sample(var_type=key, trial=self.trial, default_val=None)\n",
        "\n",
        "        for key in sampler.train_keys():\n",
        "            with self.assertRaises(ValueError):\n",
        "                #ValueError due to 'default_val' NOT belonging to the distribution of each var_type\n",
        "                sampler.sample(var_type=key, trial=None, default_val=None)\n",
        "            var = sampler.get_var(key)\n",
        "            self.assertIsInstance(var, Var)\n",
        "            self.assertTrue(var.var_type==key)\n",
        "            dist = var.distribution()\n",
        "            default_val = dist['low'] if var.sample_method!='categorical' else random.choices(dist)[0]\n",
        "            self.assertTrue(var.contain_val(default_val),\n",
        "                            msg=f\"default_val: {default_val} NOT in distribution: {dist} of Var: {var.var_type}\")\n",
        "            sampled_val = sampler.sample(var_type=key, trial=None, default_val=default_val)\n",
        "            self.assertEqual(sampled_val, default_val)\n",
        "\n",
        "        for key in sampler.train_keys():\n",
        "            sampled_val = sampler.sample(var_type=key, trial=self.trial, default_val=None)\n",
        "            var = sampler.get_var(key)\n",
        "            self.assertTrue(var.contain_val(sampled_val),\n",
        "                            msg=f\"sampled_val: {sampled_val} NOT in distribution: {var.distribution()}\")\n",
        "\n",
        "    def make_action_sampler(self, rand_choices, activation_choices, dropout_tuple):\n",
        "        INIT_ACTION_DICT = {\n",
        "            'rand_number': Var(var_type='rand_number', source={'params': {'choices': rand_choices}, 'sample': 'categorical'}),\n",
        "            'activation': Var(var_type='activation', source={'params': {'choices': activation_choices}, 'sample': 'categorical'}),\n",
        "            'dropout_p': Var(var_type='dropout_p', source={'params': {'low': dropout_tuple[0], 'high': dropout_tuple[1]}, 'sample': 'float'})\n",
        "        }\n",
        "        action_to_sig = {func: set(signature(func).parameters.keys()) - {'device'} for func in [action_default, action_dropout, action_dropout_variant]}\n",
        "        INIT_ACTION_DICT = {func: {key: INIT_ACTION_DICT[key] for key in sig} for func, sig in action_to_sig.items()}\n",
        "        return ActionSampler(INIT_ACTION_DICT=INIT_ACTION_DICT)\n",
        "\n",
        "    def make_train_sampler(self, action_func_choices, lr_tuple, wd_tuple, batch_size_choices, n_epoch_choices):\n",
        "        INIT_TRAIN_DICT = {\n",
        "            'action_func': Var(var_type='action_func', source={'params': {'choices': action_func_choices}, 'sample': 'categorical'}),\n",
        "            'lr': Var(var_type='lr', source={'params': {'low': lr_tuple[0], 'high': lr_tuple[1], 'log': True}, 'sample': 'float'}),\n",
        "            'wd': Var(var_type='wd', source={'params': {'low': wd_tuple[0], 'high': wd_tuple[1], 'log': True}, 'sample': 'float'}),\n",
        "            'batch_size': Var(var_type='batch_size', source={'params': {'choices': batch_size_choices}, 'sample': 'categorical'}),\n",
        "            'n_epoch': Var(var_type='n_epoch', source={'params': {'choices': n_epoch_choices}, 'sample': 'categorical'})\n",
        "        }\n",
        "        return TrainSampler(INIT_TRAIN_DICT=INIT_TRAIN_DICT)\n",
        "\n",
        "    def mock_wrapper_init(self, trial, default_dict, sampler, device):\n",
        "        action = default_dict['action_func']\n",
        "        model = action(device=device)\n",
        "\n",
        "        self.assertIsInstance(model, nn.Module)\n",
        "        self.assertEqual(model(torch.randn(size=[10, 16])).shape, torch.Size([10, 10]))\n",
        "\n",
        "        #Mock trainer that will update all the parameters to zero\n",
        "        trainer = Mock()\n",
        "        trainer.side_effect = lambda: [param.data.fill_(0) for param in model.parameters()]\n",
        "\n",
        "        #Ensure the model's state dict gets updated with zeros\n",
        "        for param in model.parameters():\n",
        "            param.data.fill_(0)\n",
        "\n",
        "        execution_set = Mock()\n",
        "        execution_set.yield_execution_set.return_value = (trainer, model)\n",
        "\n",
        "        #Return the execution set\n",
        "        return execution_set\n",
        "\n",
        "    def test_update(self):\n",
        "        param_sets = self.construct_mock_trials()\n",
        "        for i,param_set in enumerate(param_sets):\n",
        "            sampler = Sampler(INIT_DICT=self.get_init_dict())\n",
        "            top_k_trials = []\n",
        "            model_train_window = param_set['model_train_window']\n",
        "            distributions = param_set['distributions']\n",
        "            xyz = param_set['xyz']\n",
        "            for params in param_set['params']:\n",
        "                trial = Mock(spec=FrozenTrial)\n",
        "                trial.params = params\n",
        "                top_k_trials.append(trial)\n",
        "            #Mock the wrapper\n",
        "            Wrapper = Mock()\n",
        "            Wrapper.side_effect = self.mock_wrapper_init\n",
        "            sampler.update(top_k_trials=top_k_trials,\n",
        "                           model_train_window=model_train_window,\n",
        "                           device=None)\n",
        "            for var_type in sampler.train_keys():\n",
        "                var = sampler.get_var(var_type)\n",
        "                self.assertEqual(\n",
        "                    var.distribution(), distributions[var_type],\n",
        "                    msg = f\"{i}th param_set: {var.var_type}.distribution(): {var.distribution()} != \\nExpected distribution for {var_type}: {distributions[var_type]}\"\n",
        "                )\n",
        "            for action_func in sampler.action_funcs():\n",
        "                action = sampler.get_action(action_func)\n",
        "                assert isinstance(action, Action), f\"{i}th param_set: action: {action} != An instance of 'Action'\"\n",
        "                for var_type in action.keys():\n",
        "                    var_retrieved_from_sampler = sampler.get_var(action_func, var_type)\n",
        "                    var = action.get_var(var_type)\n",
        "                    self.assertEqual(\n",
        "                        var_retrieved_from_sampler, var,\n",
        "                        msg = f\"{i}th param_set: sampler.get_var(action_func, var_type): {var_retrieved_from_sampler} != \\n action[var_type]: {var}\"\n",
        "                    )\n",
        "                    #Since 'var_type' is from 'action.keys(), it may NOT be in distributions.\n",
        "                    #IF SO, then continue.\n",
        "                    if var_type not in distributions.keys():\n",
        "                        continue\n",
        "                    try:\n",
        "                        distribution = distributions[var_type].get(action_func, None)\n",
        "                    except Exception as e:\n",
        "                        print(f\"distributions: {distributions}, distributions[var_type]: {distributions[var_type]} Exception: {e}\")\n",
        "                    if distribution is None:\n",
        "                        continue\n",
        "                    self.assertEqual(\n",
        "                        var.distribution(), distribution,\n",
        "                        msg = f\"{i}th param_set::{action_func}:: {var.var_type}.distribution(): {var.distribution()} != \\nExpected distribution: {distribution}\"\n",
        "                    )\n",
        "            self.assertEqual(self.produce_saved_bools(sampler), param_set['xyz'])\n",
        "            self.assertEqual(sampler.is_fixed(), param_set.get('fixed', False))\n",
        "\n",
        "    def produce_saved_bools(self, sampler: Sampler):\n",
        "        action_sampler = sampler.action_sampler\n",
        "        default_action = action_sampler.get_action(action_default)\n",
        "        dropout_action = action_sampler.get_action(action_dropout)\n",
        "        dropout_variant_action = action_sampler.get_action(action_dropout_variant)\n",
        "        default_saved = default_action.action_state is not None\n",
        "        dropout_saved = dropout_action.action_state is not None\n",
        "        dropout_variant_saved = dropout_variant_action.action_state is not None\n",
        "\n",
        "        if default_saved:\n",
        "            for param_tensor in default_action.action_state.values():\n",
        "                if param_tensor.numel() > 0:  # Check tensor is not empty\n",
        "                    default_saved &= torch.all(param_tensor == 0).item()\n",
        "        if dropout_saved:\n",
        "            for param_tensor in dropout_action.action_state.values():\n",
        "                if param_tensor.numel() > 0:  # Check tensor is not empty\n",
        "                    dropout_saved &= torch.all(param_tensor == 0).item()\n",
        "\n",
        "        if dropout_variant_saved:\n",
        "            for param_tensor in dropout_variant_action.action_state.values():\n",
        "                if param_tensor.numel() > 0:  # Check tensor is not empty\n",
        "                    dropout_variant_saved &= torch.all(param_tensor == 0).item()\n",
        "\n",
        "        return (default_saved, dropout_saved, dropout_variant_saved)\n",
        "\n",
        "    def construct_mock_trials(self):\n",
        "        #Constructs a list of mock trials based on the provided param_sets structure\n",
        "        param_sets = [\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': 1, 'activation': 1, 'dropout_p': 0.78, 'lr': 1e-1, 'n_epoch': 9, 'wd': 1e-2, 'batch_size': 6},\n",
        "                    {'action_func': 0, 'rand_number': 1, 'lr': 1e-2, 'n_epoch': 11, 'wd': 5e-2, 'batch_size': 7},\n",
        "                    {'action_func': 1, 'activation': 2, 'dropout_p': 0.123, 'lr': 1e-3, 'n_epoch': 13, 'wd': 1e-3, 'batch_size': 5},\n",
        "                    {'action_func': 0, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 19, 'wd': 2e-2, 'batch_size': 8},\n",
        "                    {'action_func': 0, 'rand_number': 3, 'lr': 2e-3, 'n_epoch': 0, 'wd': 4e-2, 'batch_size': 6},\n",
        "                    #Addendum.\n",
        "                    {'action_func': 2, 'activation': 0, 'dropout_p': 0.0, 'lr': 1e-3, 'n_epoch': 13, 'wd': 1e-3, 'batch_size': 5}\n",
        "                ],\n",
        "                'distributions': {\n",
        "                    'action_func': [action_default, action_default, action_default, action_dropout, action_dropout, action_dropout_variant],\n",
        "                    'rand_number': {action_default: [2, 2, 4]},\n",
        "                    'activation': {action_dropout: [nn.PReLU, nn.SiLU], action_dropout_variant: [nn.ReLU]},\n",
        "                    'batch_size': [2 ** exp for exp in [5, 5, 6, 6, 7, 8]],\n",
        "                    'n_epoch': [1, 10, 12, 14, 14, 20],\n",
        "                    'dropout_p': {action_dropout: {'low': 0.123, 'high': 0.78}, action_dropout_variant: {'low': 0.0, 'high': 0.0}},\n",
        "                    'lr': {'low': 1e-9, 'high': 1e-1, 'log': True},\n",
        "                    'wd': {'low': 1e-3, 'high': 5e-2, 'log': True}\n",
        "                },\n",
        "                'model_train_window': 1,\n",
        "                'xyz': (False, True, False)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': 0, 'rand_number': 3, 'lr': 1e-2, 'n_epoch': 11, 'wd': 1e-2, 'batch_size': 0},\n",
        "\n",
        "                    #Addendum\n",
        "                    {'action_func': 2, 'activation': 1, 'dropout_p': 0.13, 'lr': 1e-3, 'n_epoch': 13, 'wd': 3e-2, 'batch_size': 8},\n",
        "\n",
        "                    {'action_func': 1, 'activation': 0, 'dropout_p': 0.012, 'lr': 5e-1, 'n_epoch': 9, 'wd': 1e-1, 'batch_size': 1},\n",
        "                    {'action_func': 1, 'activation': 2, 'dropout_p': 0.13, 'lr': 1e-3, 'n_epoch': 13, 'wd': 3e-2, 'batch_size': 8},\n",
        "                    {'action_func': 0, 'rand_number': 7, 'lr': 1e-3, 'n_epoch': 19, 'wd': 4e-4, 'batch_size': 3},\n",
        "                    {'action_func': 0, 'rand_number': 9, 'lr': 2e-3, 'n_epoch': 4, 'wd': 5e-3, 'batch_size': 4},\n",
        "                ],\n",
        "                'distributions': {\n",
        "                    'action_func': [action_default, action_default, action_default, action_dropout, action_dropout, action_dropout_variant],\n",
        "                    'rand_number': {action_default: [4, 8, 10]},\n",
        "                    'activation': {action_dropout: [nn.ReLU, nn.SiLU], action_dropout_variant: [nn.PReLU]},\n",
        "                    'batch_size': [2 ** exp for exp in [0, 1, 3, 4, 8, 8]],\n",
        "                    'n_epoch': [5, 10, 12, 14, 14, 20],\n",
        "                    'dropout_p': {action_dropout: {'low': 0.012, 'high': 0.13}, action_dropout_variant: {'low': 0.13, 'high': 0.13}},\n",
        "                    'lr': {'low': 1e-3, 'high': 5e-1, 'log': True},\n",
        "                    'wd': {'low': 4e-4, 'high': 1e-1, 'log': True}\n",
        "                },\n",
        "                'model_train_window': 1,\n",
        "                'xyz': (True, False, False)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': 1, 'activation': 0, 'dropout_p': 0.532, 'lr': 3e-1, 'n_epoch': 17, 'wd': 6e-5, 'batch_size': 8},\n",
        "                    {'action_func': 0, 'rand_number': 5, 'lr': 3e-1, 'n_epoch': 17, 'wd': 6e-5, 'batch_size': 8},\n",
        "\n",
        "                    #Addendum\n",
        "                    {'action_func': 2, 'activation': 2, 'dropout_p': 0.532, 'lr': 3e-1, 'n_epoch': 17, 'wd': 6e-5, 'batch_size': 8},\n",
        "\n",
        "                    {'action_func': 1, 'activation': 0, 'dropout_p': 0.532, 'lr': 3e-1, 'n_epoch': 17, 'wd': 6e-5, 'batch_size': 8},\n",
        "                    {'action_func': 0, 'rand_number': 5, 'lr': 3e-1, 'n_epoch': 17, 'wd': 6e-5, 'batch_size': 8},\n",
        "                    {'action_func': 0, 'rand_number': 5, 'lr': 3e-1, 'n_epoch': 17, 'wd': 6e-5, 'batch_size': 8},\n",
        "                ],\n",
        "                'distributions': {\n",
        "                    'action_func': [action_default, action_default, action_default, action_dropout, action_dropout, action_dropout_variant],\n",
        "                    'rand_number': {action_default: [6]},\n",
        "                    'activation': {action_dropout: [nn.ReLU], action_dropout_variant: [nn.SiLU]},\n",
        "                    'batch_size': [2 ** 8],\n",
        "                    'n_epoch': [18],\n",
        "                    'dropout_p': {action_dropout: {'low': 0.532, 'high': 0.532}, action_dropout_variant: {'low': 0.532, 'high': 0.532}},\n",
        "                    'lr': {'low': 3e-1, 'high': 3e-1, 'log': True},\n",
        "                    'wd': {'low': 6e-5, 'high': 6e-5, 'log': True}\n",
        "                },\n",
        "                'model_train_window': 3,\n",
        "                'xyz': (True, True, True)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': 1, 'activation': 1, 'dropout_p': 0.176, 'lr': 1e-1, 'n_epoch': 10, 'wd': 5e-2, 'batch_size': 1},\n",
        "\n",
        "                    #Addendum\n",
        "                    {'action_func': 2, 'activation': 1, 'dropout_p': 0.111, 'lr': 1e-1, 'n_epoch': 10, 'wd': 5e-2, 'batch_size': 1},\n",
        "\n",
        "                    {'action_func': 1, 'activation': 0, 'dropout_p': 0.176, 'lr': 1e-3, 'n_epoch': 14, 'wd': 2e-1, 'batch_size': 2},\n",
        "                    {'action_func': 0, 'rand_number': 1, 'lr': 1e-9, 'n_epoch': 19, 'wd': 7e-3, 'batch_size': 3}\n",
        "                ],\n",
        "                'distributions': {\n",
        "                    'action_func': [action_default, action_dropout, action_dropout, action_dropout_variant],\n",
        "                    'rand_number': {action_default: [2]},\n",
        "                    'activation':  {action_dropout: [nn.ReLU, nn.PReLU], action_dropout_variant: [nn.PReLU]},\n",
        "                    'batch_size': [2, 2, 4, 8],\n",
        "                    'n_epoch': [11, 11, 15, 20],\n",
        "                    'dropout_p': {action_dropout: {'low': 0.176, 'high': 0.176}, action_dropout_variant: {'low': 0.111, 'high': 0.111}},\n",
        "                    'lr': {'low': 1e-9, 'high': 1e-1, 'log': True},\n",
        "                    'wd': {'low': 7e-3, 'high': 2e-1, 'log': True}\n",
        "                },\n",
        "                'model_train_window': 2,\n",
        "                'xyz': (False, True, True)\n",
        "            },\n",
        "            {\n",
        "                'params': [\n",
        "                    {'action_func': 1, 'activation': 2, 'dropout_p': 0.85, 'lr': 1e-3, 'n_epoch': 10, 'wd': 1e-4, 'batch_size': 7},\n",
        "                    {'action_func': 1, 'activation': 2, 'dropout_p': 0.85, 'lr': 1e-3, 'n_epoch': 10, 'wd': 1e-4, 'batch_size': 7},\n",
        "                    {'action_func': 1, 'activation': 2, 'dropout_p': 0.85, 'lr': 1e-3, 'n_epoch': 10, 'wd': 1e-4, 'batch_size': 7}\n",
        "                ],\n",
        "                'distributions': {\n",
        "                    'action_func': [action_dropout],\n",
        "                    'activation': {action_dropout: [nn.SiLU]},\n",
        "                    'batch_size': [128],\n",
        "                    'n_epoch': [11],\n",
        "                    'dropout_p': {action_dropout: {'low': 0.85, 'high': 0.85}},\n",
        "                    'lr': {'low': 1e-3, 'high': 1e-3, 'log': True},\n",
        "                    'wd': {'low': 1e-4, 'high': 1e-4, 'log': True}\n",
        "                },\n",
        "                'model_train_window': 100,\n",
        "                'xyz': (False, True, False),\n",
        "                'fixed': True\n",
        "            }\n",
        "        ]\n",
        "        return param_sets\n",
        "\n",
        "    def get_init_dict(self):\n",
        "        action_func_choices = [action_default, action_dropout, action_dropout_variant]\n",
        "        rand_number_choices = list(range(1,11))\n",
        "        activation_choices = [nn.ReLU, nn.PReLU, nn.SiLU]\n",
        "        dropout_p_min = 0.0\n",
        "        dropout_p_max = 1.0\n",
        "        lr_min = 1e-9\n",
        "        lr_max = 5.0\n",
        "        wd_min = 1e-9\n",
        "        wd_max = 1.0\n",
        "        n_epoch_choices = list(range(1,21))\n",
        "        batch_size_choices = [2**exp for exp in range(9)]\n",
        "\n",
        "        # Construct INIT_DICT for each param_set\n",
        "        init_dict = {\n",
        "            'action_func': {\n",
        "                'params': {'choices': action_func_choices},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'rand_number': {\n",
        "                'params': {'choices': rand_number_choices},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'activation': {\n",
        "                'params': {'choices': activation_choices},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'dropout_p': {\n",
        "                'params': {'low': dropout_p_min, 'high': dropout_p_max},\n",
        "                'sample': 'float'\n",
        "             },\n",
        "            'lr': {\n",
        "                'params': {'low': lr_min, 'high': lr_max, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'n_epoch': {\n",
        "                'params': {'choices': n_epoch_choices},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'wd': {\n",
        "                'params': {'low': wd_min, 'high': wd_max, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'batch_size': {\n",
        "                'params': {'choices': batch_size_choices},\n",
        "                'sample': 'categorical'\n",
        "            }\n",
        "        }\n",
        "        return init_dict\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEpP09BT-dRl",
        "outputId": "90925cea-c48c-40dc-f16d-e298a9c9d90b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 18:31:40,532] A new study created in memory with name: no-name-2c6f05f6-6925-440b-8436-5399a0fce1da\n",
            ".[I 2024-09-19 18:31:40,551] A new study created in memory with name: no-name-ef9b2aec-d565-4819-b913-8af75121d3a4\n",
            ".[I 2024-09-19 18:31:40,567] A new study created in memory with name: no-name-063f2fbf-2edb-4569-87ad-5cdafcbc4111\n",
            ".[I 2024-09-19 18:31:40,593] A new study created in memory with name: no-name-d982c9c5-fc7a-48e6-adc5-af4efb9cdd30\n",
            ".[I 2024-09-19 18:31:40,615] A new study created in memory with name: no-name-3df89b58-a54b-4c5a-9622-974b7a8e9890\n",
            ".[I 2024-09-19 18:31:40,629] A new study created in memory with name: no-name-cd64fddb-be12-4d0b-b041-3d8a32bb2f2e\n",
            ".[I 2024-09-19 18:31:40,643] A new study created in memory with name: no-name-f96a7c0a-41e1-42b4-8983-598e6f0e5f31\n",
            ".[I 2024-09-19 18:31:40,696] A new study created in memory with name: no-name-041a10cc-ff3b-4626-b813-41f4c153ad42\n",
            ".[I 2024-09-19 18:31:40,705] A new study created in memory with name: no-name-ce2b9ab1-4acd-4ae2-87e5-663daf735c4c\n",
            ".[I 2024-09-19 18:31:40,716] A new study created in memory with name: no-name-3e11121e-d8ec-491d-ac1c-871d658d2ba7\n",
            "[I 2024-09-19 18:31:40,719] A new study created in memory with name: no-name-126168a7-990e-4d1a-adae-f1408250786d\n",
            "[I 2024-09-19 18:31:40,726] A new study created in memory with name: no-name-1ec206f1-9685-4493-beae-c88481896e24\n",
            ".[I 2024-09-19 18:31:40,741] A new study created in memory with name: no-name-17913ea3-9a06-4271-b9c2-5ece6bbde16d\n",
            ".[I 2024-09-19 18:31:40,749] A new study created in memory with name: no-name-685b4370-2e4f-460b-bd84-048cf8050cb9\n",
            "[I 2024-09-19 18:31:40,754] A new study created in memory with name: no-name-4008365e-8e05-4df2-961d-d1863bb88527\n",
            "[I 2024-09-19 18:31:40,758] A new study created in memory with name: no-name-75a863ea-718f-43b9-8ef5-66f364c30c26\n",
            ".[I 2024-09-19 18:31:40,778] A new study created in memory with name: no-name-da7af812-43d9-49ab-b900-6ce66dbae73d\n",
            ".[I 2024-09-19 18:31:40,781] A new study created in memory with name: no-name-92ef1152-5d26-44c4-90b8-75c912e83a68\n",
            ".[I 2024-09-19 18:31:40,822] A new study created in memory with name: no-name-1f740690-6c81-40d8-8af5-01c12615e1d8\n",
            ".[I 2024-09-19 18:31:40,829] A new study created in memory with name: no-name-e1de2d0d-6d4f-416e-9c7b-f63076c2d34e\n",
            ".[I 2024-09-19 18:31:40,838] A new study created in memory with name: no-name-bb315169-819d-47b6-9ba4-eaa3dba9feeb\n",
            ".[I 2024-09-19 18:31:40,850] A new study created in memory with name: no-name-93092ad0-eab2-4e66-b15e-67d248ae0465\n",
            "...........[I 2024-09-19 18:31:41,008] A new study created in memory with name: no-name-558b8ffb-309a-4020-b415-b15877ac205b\n",
            "..[I 2024-09-19 18:31:41,020] A new study created in memory with name: no-name-c6bcd8a8-bdfd-4c9e-b78b-b244cfbec317\n",
            ".....\n",
            "----------------------------------------------------------------------\n",
            "Ran 35 tests in 0.504s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: Wrapper"
      ],
      "metadata": {
        "id": "lq4j5jcUad_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Wrapper:\n",
        "    def __init__(self, trial, sampler: Sampler, device: torch.device, default_dict: dict = {}):\n",
        "        #Perform general-error checking\n",
        "        self._error_check(trial=trial, sampler=sampler, default_dict=default_dict)\n",
        "\n",
        "        #Initialize all the member variables.\n",
        "        self.trial = trial\n",
        "        self.default_dict = default_dict\n",
        "        self.default_keys = set(default_dict.keys())\n",
        "        self.sampler = sampler\n",
        "        self.train_keys = set(self.sampler.train_keys()) if self.sampler else self.default_keys\n",
        "        self.action_funcs = set(self.sampler.action_funcs()) if self.sampler else set([self.default_dict['action_func'].action_func])\n",
        "        self.sampled_vars = set()\n",
        "        self.device = device if device else torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        #print(\"*************************************************************************************\")\n",
        "        #print(f\"default_dict: {default_dict}\")\n",
        "        #print(\"*************************************************************************************\")\n",
        "\n",
        "    def _error_check(self, trial: Trial, sampler: Sampler, default_dict: dict):\n",
        "        #trial type check:\n",
        "        if trial is not None and not isinstance(trial, (Trial, FrozenTrial)):\n",
        "            raise ValueError(f\"Input 'trial' must either be 'None' or an instance in (optuna::Trial, optuna::FrozenTrial) but found: {trial}\")\n",
        "\n",
        "        #sampler type check:\n",
        "        if sampler is not None and not isinstance(sampler, Sampler):\n",
        "            raise ValueError(f\"Input 'sampler' must either be None of type Sampler but found: {sampler}\")\n",
        "\n",
        "        #Make sure there's something to be sampled:\n",
        "        if not default_dict and not sampler:\n",
        "            raise ValueError(f\"Both default_dict and sampler are empty. Nothing to be sampled.\")\n",
        "\n",
        "        #Make sure that IF 'action_func' exists in 'default_dict',\n",
        "        #               THEN it maps to a properly built & loadable Action object\n",
        "        manual_action = default_dict.get('action_func', None)\n",
        "        manual_action_valid = isinstance(manual_action, Action) and manual_action.is_loadable()\n",
        "        if not sampler and not manual_action:\n",
        "            raise ValueError(\"Input 'sampler' is None but 'action_func' does NOT exist as a key in 'default_dict'. Note that 'action_func' is one parameter required for every Auto-hpo process\")\n",
        "        #IF ('action_func'->obj) exists, THEN check on its value.\n",
        "        if manual_action and not manual_action_valid:\n",
        "            msg = \"which is NOT an Action object\" if not isinstance(manual_action, Action) else \"which is NOT loadable\"\n",
        "            raise ValueError(f\"Input 'default_dict' has 'action_func' as a key but default_dict['action_func']->{manual_action}, {msg}\")\n",
        "\n",
        "    def sample(self, var_type: str, default_val = None):\n",
        "        #ERROR CHECKS\n",
        "        #No double sampling.\n",
        "        var_type_in_default = var_type in self.default_keys\n",
        "        if var_type in self.sampled_vars:\n",
        "            raise ValueError(f\"var_type: {var_type} has already been sampled. Only one sampling per var_type in each trial allowed. Note the following var_type(s) have already been sampled: {self.sampled_vars}\")\n",
        "\n",
        "        sampled_val = None\n",
        "        #IF var_type is in default, THEN sampled_val <- default_dict[var_type]\n",
        "        if var_type in self.default_keys:\n",
        "            sampled_val = self.default_dict[var_type]\n",
        "        elif self.sampler is None or var_type not in self.train_keys:\n",
        "            #IF var_type is NOT in default_dict AND (self.sampler is None OR var_type is NOT in self.sampler),\n",
        "            #THEN sampled_val <- default_val\n",
        "            sampled_val = default_val\n",
        "        else: #All False, THEN sampled_val <- sampled value from self.sampler\n",
        "            sampled_val = self.sampler.sample(var_type=var_type, trial=self.trial, default_val=default_val)\n",
        "\n",
        "        #Add 'var_type' to the set of sampled variables.\n",
        "        self.sampled_vars.add(var_type)\n",
        "\n",
        "        return sampled_val\n",
        "\n",
        "    def yield_execution_set(self):\n",
        "        #Dictionary of (key->default_val) for key among common parameters that appear in 'dls_func'\n",
        "        default_dls_map = {\n",
        "            'batch_size': 64,\n",
        "            'img_size': 224,\n",
        "            'normalize': True,\n",
        "            'summary': True\n",
        "        }\n",
        "        #dls_func <- sampled 'dls_func' from Sampler.\n",
        "        dls_func = self.sample('dls_func')\n",
        "        try:\n",
        "            #dls_sig <- signature parameters of 'dls_func'\n",
        "            dls_sig = set(signature(dls_func).parameters.keys())\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"dls_func: {dls_func}, retrieving the dls_sig from it via 'set(signature(dls_func).parameters.keys())' resulted in the following: {e}\")\n",
        "\n",
        "        #dls <- DataLoaders created from 'dls_func' with sampled signatures\n",
        "        dls = dls_func(\n",
        "            **{key:self.sample(key, default_dls_map[key]) for key in dls_sig}\n",
        "        )\n",
        "\n",
        "        #action <- Action object encapsulating the logic of sampled recipe\n",
        "        action = self.sample('action_func')\n",
        "        #action = self.sample(self.default_dict)\n",
        "        #action_func, action_state <- Useful properties of 'action'.\n",
        "        action_func = action.action_func\n",
        "        action_state = action.action_state\n",
        "        #model <- Model yielded from action. Note it's loaded onto the input 'device'.\n",
        "        model = action(device=self.device)\n",
        "        if not isinstance(model, nn.Module):\n",
        "            raise ValueError(f\"Model generated by Action: {action_func.__name__} must be of type 'nn.Module' but found: {model}\")\n",
        "\n",
        "        loss_func = self.sample('loss_func')\n",
        "        learner = Learner(dls=dls,\n",
        "                          model=model,\n",
        "                          loss_func=loss_func() if isinstance(loss_func, nn.Module) else loss_func,\n",
        "                          #opt_func=self.sample('opt_func'), NOT IMPLEMENTED YET!!!\n",
        "                          metrics=self.sample('metric')\n",
        "                          )\n",
        "\n",
        "        #Sample on whether to freeze the learner or not ONLY WHEN there's no saved 'action_state' for the given action_func\n",
        "        if action_state is None and self.sample('freeze', False):\n",
        "            learner.freeze()\n",
        "        else: #IF (action_state is not None) OR (action_state is None but sampled 'freeze' states False)\n",
        "              #THEN .unfreeze().\n",
        "              learner.unfreeze()\n",
        "\n",
        "        #Barebone cbs list:\n",
        "        cbs = []\n",
        "        #Fill the list:\n",
        "        if self.sample('gradient_clip',False): #Apply Gradient clipping, if exists and is True.\n",
        "            cbs.append(GradientClip(max_norm=self.sample('max_norm', 0.1))) #If exists, then 'max_norm' MUST exist, hence no safety guarantee.\n",
        "        if self.trial is None:\n",
        "            cbs.append(EarlyStoppingCallback(monitor='valid_loss',\n",
        "                                             min_delta=self.sample('min_delta', 0.1),\n",
        "                                             patience=self.sample('patience', 15)))\n",
        "        else: #IF trial is a type of optuna.Trail, then apply PruningCallback.\n",
        "            cbs.append(FastAIPruningCallback(trial=self.trial, monitor='valid_loss'))\n",
        "\n",
        "        #Make the action and return it.\n",
        "        trainer = None\n",
        "        if self.sample('one_cycle', True):\n",
        "            lr_low = self.sample('lr_low', 1e-3)\n",
        "            lr_high = self.sample('lr_high', lr_low)\n",
        "            trainer = partial(learner.fit_one_cycle,\n",
        "                              n_epoch=self.sample('n_epoch', 10),\n",
        "                              lr_max=slice(lr_low, lr_high),\n",
        "                              wd=self.sample('wd', 0.01), pct_start=self.sample('pct_start',0.3),\n",
        "                              cbs=cbs)\n",
        "        else:\n",
        "            trainer = partial(learner.fit,\n",
        "                               n_epoch=self.sample('n_epoch', 10),\n",
        "                               lr=self.sample('lr', 1e-3),\n",
        "                               wd=self.sample('wd', 0.01),\n",
        "                               cbs=cbs)\n",
        "\n",
        "        #Return the execution_set := (trainer, learner)\n",
        "        #NOTE: 'trainer' Executes training on the learer, when called.\n",
        "        return (trainer, learner)"
      ],
      "metadata": {
        "id": "FJE7gRBCagn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test: Wrapper"
      ],
      "metadata": {
        "id": "xAvWWmAD0HvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class PolynomialDataset(Dataset):\n",
        "    def __init__(self, coeffs: torch.tensor, input_min: float, input_max: float, input_size: int):\n",
        "        #coeffs.shape == [degree+1, 1]\n",
        "        self.coeffs = coeffs.clone().detach()\n",
        "        #inputs.shape == [inputs]\n",
        "        self.inputs = torch.empty(size=(input_size,)).uniform_(input_min, input_max)\n",
        "        #Preprocess the output and retrieve it upon request.\n",
        "        self.outputs = self._f(X=self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.outputs[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.inputs.size(0) != self.outputs.size(0):\n",
        "            return ValueError(f\"len(inputs): {self.inputs.size(0)} != len(outputs): {self.outputs.size(0)}\")\n",
        "        return self.inputs.size(0)\n",
        "\n",
        "    def _f(self, X):\n",
        "        #power.shape == [1, degree+1]\n",
        "        powers = torch.arange(self.coeffs.size(0)).unsqueeze(0)\n",
        "        Y = self.inputs.unsqueeze(-1)**powers\n",
        "        return torch.matmul(Y, self.coeffs).squeeze(-1)\n",
        "\n",
        "degree = 6\n",
        "coeffs_min, coeffs_max = -10.0, 10.0\n",
        "coeffs = torch.empty(size=(degree+1,)).uniform_(coeffs_min, coeffs_max)\n",
        "\n",
        "for c in coeffs:\n",
        "    print(f\"c: {c}\")\n",
        "\n",
        "train_dset = PolynomialDataset(coeffs=coeffs, input_min=-100.0, input_max=100.0, input_size=8000)\n",
        "valid_dset = PolynomialDataset(coeffs=coeffs, input_min=-300.12, input_max=500.78, input_size=2000)\n",
        "\n",
        "#Test:\n",
        "print(f\"Number of elements in Dataset; train_dset: {len(train_dset)}, valid_dset: {len(valid_dset)}\")\n",
        "print()\n",
        "\n",
        "print(f\"train first input: {train_dset[0][0]}, train first output: {train_dset[0][1]}\")\n",
        "print()\n",
        "\n",
        "print(f\"valid first input: {valid_dset[0][0]}, valid first output: {valid_dset[0][1]}\")\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6lO0cStOv07",
        "outputId": "18d4369a-3ad6-4ef6-be82-c7fd7b1adb55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c: -1.595369577407837\n",
            "c: 2.8912389278411865\n",
            "c: 5.772222518920898\n",
            "c: -0.3089940547943115\n",
            "c: -0.9646546840667725\n",
            "c: 2.6757192611694336\n",
            "c: 5.911468505859375\n",
            "Number of elements in Dataset; train_dset: 8000, valid_dset: 2000\n",
            "\n",
            "train first input: -29.38094139099121, train first output: 3743389952.0\n",
            "\n",
            "valid first input: 296.79803466796875, valid first output: 4046900453965824.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Action functions:\n",
        "\"\"\"\n",
        "class ModelDefault(nn.Module):\n",
        "    def __init__(self, activation: nn.Module, preprocess: bool, start_neurons: int):\n",
        "        super().__init__()\n",
        "        self.preprocess = preprocess\n",
        "        if self.preprocess: start_neurons = max(start_neurons,degree+1)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=degree+1 if self.preprocess else 1,\n",
        "                      out_features=start_neurons),\n",
        "            nn.BatchNorm1d(num_features=start_neurons),\n",
        "            activation(),\n",
        "            nn.Linear(in_features=start_neurons,out_features=start_neurons*2),\n",
        "            nn.BatchNorm1d(num_features=start_neurons*2),\n",
        "            activation(),\n",
        "            nn.Linear(in_features=start_neurons*2,out_features=1)\n",
        "        )\n",
        "\n",
        "    def _preprocess(self, X):\n",
        "        N = X.size(0)\n",
        "        #X <- [64,1]x[1,7] == [64,7], where each index (i,j) yields X[i]**j.\n",
        "        X = X.unsqueeze(-1)**torch.arange(degree+1).unsqueeze(0)\n",
        "        if X.size() != torch.Size([N,degree+1]):\n",
        "            raise ValueError(f\"X.size() MUST be torch.Size([{N},{degree+1}]) but found X.size()=={X.size()}\")\n",
        "        return X\n",
        "\n",
        "    def forward(self, X):\n",
        "        if X.dim() != 1:\n",
        "            X = X.reshape(-1)\n",
        "\n",
        "        if self.preprocess:\n",
        "            X = self._preprocess(X)\n",
        "        else:\n",
        "            X = X.unsqueeze(-1)\n",
        "        return self.net(X)\n",
        "\n",
        "class ModelDropout(nn.Module):\n",
        "    def __init__(self, activation: nn.Module, dropout_p: int, preprocess: int, start_neurons: Int):\n",
        "        super().__init__()\n",
        "        self.preprocess = preprocess\n",
        "        if self.preprocess: start_neurons = max(start_neurons,degree+1)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=degree+1 if self.preprocess else 1,\n",
        "                      out_features=start_neurons),\n",
        "            nn.BatchNorm1d(num_features=start_neurons),\n",
        "            activation(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "            nn.Linear(in_features=start_neurons,out_features=start_neurons*2),\n",
        "            nn.BatchNorm1d(num_features=start_neurons*2),\n",
        "            activation(),\n",
        "            nn.Linear(in_features=start_neurons*2,out_features=1)\n",
        "        )\n",
        "\n",
        "    def _preprocess(self, X):\n",
        "        N = X.size(0)\n",
        "        #X <- [64,1]x[1,7] == [64,7], where each index (i,j) yields X[i]**j.\n",
        "        X = X.unsqueeze(-1)**torch.arange(degree+1).unsqueeze(0)\n",
        "        if X.size() != torch.Size([N,degree+1]):\n",
        "            raise ValueError(f\"X.size() MUST be torch.Size([{N},{degree+1}]) but found X.size()=={X.size()}\")\n",
        "        return X\n",
        "\n",
        "    def forward(self, X):\n",
        "        if X.dim() != 1:\n",
        "            X = X.reshape(-1)\n",
        "\n",
        "        if self.preprocess:\n",
        "            X = self._preprocess(X)\n",
        "        else:\n",
        "            X = X.unsqueeze(-1)\n",
        "        return self.net(X)\n",
        "\n",
        "def action_default(activation: nn.Module, preprocess: bool, start_neurons: int, device: torch.device):\n",
        "    if start_neurons < 1:\n",
        "        raise ValueError(f\"start_neurons MUST be a positive integer but found start_neurons: {start_neurons}\")\n",
        "    return ModelDefault(activation=activation,\n",
        "                        preprocess=preprocess,\n",
        "                        start_neurons=start_neurons).to(device)\n",
        "\n",
        "def action_dropout(activation: nn.Module, dropout_p: int, preprocess: bool, start_neurons: int, device: torch.device):\n",
        "    if start_neurons < 1:\n",
        "        raise ValueError(f\"start_neurons MUST be a positive integer but found start_neurons: {start_neurons}\")\n",
        "    if dropout_p < 0.0 or dropout_p >= 1.0:\n",
        "        raise ValueError(f\"0.0 <= dropout_p < 1.0 required but found dropout_p: {dropout_p}\")\n",
        "    return ModelDropout(activation=activation,\n",
        "                        dropout_p=dropout_p,\n",
        "                        preprocess=preprocess,\n",
        "                        start_neurons=start_neurons).to(device)"
      ],
      "metadata": {
        "id": "Uh-NmFiBOwf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define DataLoaders and training process\n",
        "def get_dls(batch_size: int):\n",
        "    train_dataloader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
        "    valid_dataloader = DataLoader(valid_dset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    dls = DataLoaders(train_dataloader, valid_dataloader)\n",
        "    return dls\n",
        "\n",
        "def custom_mse(Y_hat, Y):\n",
        "    Y_hat = Y_hat.reshape(-1)\n",
        "    Y = Y.reshape(-1)\n",
        "    if Y_hat.size() != Y.size():\n",
        "        raise ValueError(f\"Y_hat.size(): {Y_hat.size()} != Y.size(): {Y.size()}\")\n",
        "    return nn.MSELoss()(Y_hat, Y)"
      ],
      "metadata": {
        "id": "G6OikbZ-O_ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestWrapper(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.INIT_DICT = {\n",
        "            'dls_func': {\n",
        "                'params': {'choices': [get_dls]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'freeze': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'lr_low': {\n",
        "                'params': {'low': 1e-7, 'high': 9e-4, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'lr_high': {\n",
        "                'params': {'low': 9e-4, 'high': 1e-1, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'lr': {\n",
        "                'params': {'low': 1e-6, 'high': 1e-1, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'wd': {\n",
        "                'params': {'choices': [1e-4, 1e-3, 1e-2, 1e-1]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'gradient_clip': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'max_norm': {\n",
        "                'params': {'low': 0.0, 'high': 15.0, 'log': False},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'one_cycle': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'pct_start': {\n",
        "                'params': {'low': 0.10, 'high': 0.95,  'log': False, 'step': 0.05},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'n_epoch': {\n",
        "                'params': {'choices': [5, 10, 15]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'action_func': {\n",
        "                'params': {'choices': [action_default, action_dropout]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'activation': {\n",
        "                'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'loss_func': {\n",
        "                'params': {'choices': [custom_mse]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'metric': {\n",
        "                'params': {'choices': [custom_mse]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'preprocess': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'start_neurons': {\n",
        "                'params': {'choices': [1, 2, 4, 8, 16, 32]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'dropout_p': {\n",
        "                'params': {'low': 0.01, 'high': 0.95,  'log': False, 'step': 0.05},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'batch_size': {\n",
        "                'params': {'choices': [1, 2, 4, 8, 16, 32, 64]},\n",
        "                'sample': 'categorical'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.trial = optuna.create_study(direction='minimize').ask()\n",
        "        self.device = torch.device('cpu')\n",
        "\n",
        "    def test_initialization(self):\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        self.assertTrue(set(sampler.sig_keys())==set(['activation', 'dropout_p', 'preprocess', 'start_neurons']),\n",
        "                        msg=f\"sampler.sig_keys(): {set(sampler.sig_keys())}\")\n",
        "        self.assertTrue(set(sampler.train_keys())==set(self.INIT_DICT.keys())-set(['activation', 'dropout_p', 'preprocess', 'start_neurons']),\n",
        "                        msg=f\"sampler.train_keys(): {set(sampler.train_keys())}\")\n",
        "        self.assertTrue(set(sampler.action_funcs())==set([action_default, action_dropout]),\n",
        "                        msg=f\"sampler.action_funcs(): {set(sampler.action_funcs())}\")\n",
        "\n",
        "        sampled_dict = dict()\n",
        "        for key in sampler.train_keys():\n",
        "            sampled_dict[key] = sampler.sample(key, self.trial, default_val=None)\n",
        "\n",
        "        wrapper = Wrapper(trial=self.trial, sampler=sampler, device=self.device, default_dict={})\n",
        "        self.assertTrue(sampled_dict, wrapper.default_dict)\n",
        "\n",
        "    def test_yield_execution_set_trial(self):\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        wrapper = Wrapper(trial=self.trial, sampler=sampler, device=self.device, default_dict={})\n",
        "        trainer, learner = wrapper.yield_execution_set()\n",
        "        trainer()\n",
        "        self.assertIsInstance(learner, Learner)\n",
        "        model = learner.model\n",
        "        self.assertIsInstance(model, nn.Module)\n",
        "        self.assertEqual(model(torch.randn(size=[64,1])).shape, torch.Size([64,1]))\n",
        "\n",
        "    def test_yield_execution_set_frozen_trial(self):\n",
        "        #Create a FrozenTrial with all parameters pre-determined\n",
        "        trial_params = {\n",
        "            'dls_func': get_dls,\n",
        "            'freeze': True,\n",
        "            'lr_low': 1e-6,\n",
        "            'lr_high': 1e-2,\n",
        "            'lr': 1e-3,\n",
        "            'wd': 1e-4,\n",
        "            'gradient_clip': False,\n",
        "            'max_norm': 10.0,\n",
        "            'one_cycle': True,\n",
        "            'pct_start': 0.5,\n",
        "            'n_epoch': 10,\n",
        "            'action_func': action_dropout,\n",
        "            'activation': nn.ReLU,\n",
        "            'loss_func': custom_mse,\n",
        "            'metric': custom_mse,\n",
        "            'preprocess': False,\n",
        "            'start_neurons': 16,\n",
        "            'dropout_p': 0.5,\n",
        "            'batch_size': 64\n",
        "        }\n",
        "        frozen_trial = optuna.trial.FrozenTrial(\n",
        "            number=0,\n",
        "            trial_id=0,\n",
        "            state=optuna.trial.TrialState.COMPLETE,\n",
        "            value=None,\n",
        "            datetime_start=None,\n",
        "            datetime_complete=None,\n",
        "            params=trial_params,\n",
        "            distributions={\n",
        "                'dls_func': optuna.distributions.CategoricalDistribution(choices=[0]),\n",
        "                'freeze': optuna.distributions.CategoricalDistribution(choices=[0, 1]),\n",
        "                'lr_low': optuna.distributions.FloatDistribution(low=1e-7, high=9e-4, log=True),\n",
        "                'lr_high': optuna.distributions.FloatDistribution(low=9e-4, high=1e-1, log=True),\n",
        "                'lr': optuna.distributions.FloatDistribution(low=1e-6, high=1e-1, log=True),\n",
        "                'wd': optuna.distributions.CategoricalDistribution(choices=[0, 1, 2, 3]),\n",
        "                'gradient_clip': optuna.distributions.CategoricalDistribution(choices=[0, 1]),\n",
        "                'max_norm': optuna.distributions.FloatDistribution(low=0.0, high=15.0),\n",
        "                'one_cycle': optuna.distributions.CategoricalDistribution(choices=[0, 1]),\n",
        "                'pct_start': optuna.distributions.FloatDistribution(low=0.10, high=0.95, step=0.05),\n",
        "                'n_epoch': optuna.distributions.CategoricalDistribution(choices=[0,1,2]),\n",
        "                'action_func': optuna.distributions.CategoricalDistribution(choices=[0,1]),\n",
        "                'activation': optuna.distributions.CategoricalDistribution(choices=[0,1,2]),\n",
        "                'loss_func': optuna.distributions.CategoricalDistribution(choices=[0]),\n",
        "                'metric': optuna.distributions.CategoricalDistribution(choices=[0]),\n",
        "                'preprocess': optuna.distributions.CategoricalDistribution(choices=[0, 1]),\n",
        "                'start_neurons': optuna.distributions.CategoricalDistribution(choices=[0,1,2,3,4,5]),\n",
        "                'dropout_p': optuna.distributions.FloatDistribution(low=0.01, high=0.95, step=0.05),\n",
        "                'batch_size': optuna.distributions.CategoricalDistribution(choices=[0])\n",
        "            },\n",
        "            user_attrs={},\n",
        "            system_attrs={},\n",
        "            intermediate_values={}\n",
        "        )\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "\n",
        "        copy_params = dict()\n",
        "        #Change all the actual values in frozen_trial.params to indices(if applicable)\n",
        "        for var_type in set(sampler.train_keys())|sampler.sig_keys():\n",
        "            val = frozen_trial.params[var_type]\n",
        "            if var_type in sampler.sig_keys():\n",
        "                copy_params[var_type] = sampler.convert_val_to_idx(1, var_type, val)\n",
        "                var = sampler.get_var(1, var_type)\n",
        "            else:\n",
        "                copy_params[var_type] = sampler.convert_val_to_idx(var_type, val)\n",
        "                var = sampler.get_var(var_type)\n",
        "                self.assertEqual(\n",
        "                    copy_params[var_type],\n",
        "                    var.convert_val_to_idx(val),\n",
        "                    msg=f\"For Var:{var_type}, {var_type}.distribution: {var.distribution()}, copy_params[{var_type}]: {copy_params[var_type]} != \\n{var_type}.convert_val_to_idx({val}): {var.convert_val_to_idx(val)}\"\n",
        "                )\n",
        "                self.assertEqual(\n",
        "                    val,\n",
        "                    var.convert_idx_to_val(copy_params[var_type]),\n",
        "                    msg=f\"For Var:{var_type}, {var_type}.distribution: {var.distribution(indices=True)}, frozen_trial.params[{var_type}]: {val} != \\n{var_type}.convert_idx_to_val({copy_params[var_type]}): {var.convert_idx_to_val(copy_params[var_type])}\"\n",
        "                )\n",
        "\n",
        "        #Overwrite all the params of frozen_trial\n",
        "        frozen_trial.params |= copy_params\n",
        "\n",
        "        #CHECK: frozen_trial.params ONLY contain values that are either int or float\n",
        "        for var_type,idx in frozen_trial.params.items():\n",
        "            if not isinstance(idx, (int,float)):\n",
        "                raise ValueError(f\"var_type:{var_type}->idx:{idx} BUT type(idx):{type(idx)}!=(int,float)\")\n",
        "\n",
        "        #Initialize the Wrapper with the pre-determined FrozenTrial\n",
        "        wrapper = Wrapper(trial=frozen_trial, sampler=sampler, device=self.device, default_dict={})\n",
        "\n",
        "        #Generate the trainer and learner, and execute the trainer\n",
        "        trainer, learner = wrapper.yield_execution_set()\n",
        "        trainer()\n",
        "\n",
        "        #Verify that the frozen trial parameters are used without modification\n",
        "        self.assertEqual(frozen_trial.params, copy_params, msg=f\"Frozen_trial.params: {frozen_trial.params} != \\n original_frozen_trial_params: {copy_params}\")\n",
        "\n",
        "        #Update sampler with output of frozen trial\n",
        "        sampler.update(top_k_trials=[frozen_trial], model_train_window=1, device=self.device)\n",
        "\n",
        "        #ONLY one action_func shall be available.\n",
        "        action_func_var = sampler.get_var('action_func')\n",
        "        self.assertEqual(action_func_var.distribution(), [action_dropout],\n",
        "                        msg=f\"action_func_var.distribution(): {action_func_var.distribution()} != [action_dropout]\"\n",
        "        )\n",
        "\n",
        "        action = sampler.get_action(action_dropout)\n",
        "        action_compare_to = sampler.get_action(1)\n",
        "        action_compare_to_two = sampler.action_sampler.get_action(action_dropout)\n",
        "        self.assertEqual(action, action_compare_to)\n",
        "        self.assertEqual(action, action_compare_to_two)\n",
        "\n",
        "        #Go through each distribution of each var object, compare it against the value(s) from copy_params\n",
        "        for var_type in sampler.train_keys():\n",
        "            var = sampler.get_var(var_type)\n",
        "            distribution = var.distribution()\n",
        "            compare_to = [var.convert_idx_to_val(copy_params[var_type])] if var.sample_method == 'categorical' else distribution | {'low': copy_params[var_type], 'high': copy_params[var_type]}\n",
        "            self.assertEqual(\n",
        "                distribution,\n",
        "                compare_to,\n",
        "                msg=f\"{var_type}.distribution: {distribution} differs from expected distribution: {compare_to}\"\n",
        "            )\n",
        "\n",
        "        for var_type in action.keys():\n",
        "            var = action.get_var(var_type)\n",
        "            compare_to_var = sampler.get_var(action.action_func, var_type)\n",
        "            self.assertEqual(var, compare_to_var)\n",
        "            distribution = var.distribution()\n",
        "            compare_to = [var.convert_idx_to_val(copy_params[var_type])] if var.sample_method == 'categorical' else distribution | {'low': copy_params[var_type], 'high': copy_params[var_type]}\n",
        "            self.assertEqual(\n",
        "                distribution,\n",
        "                compare_to,\n",
        "                msg=f\"action_func: {action.action_func}::{var_type}.distribution: {distribution} differs from expected distribution: {compare_to}\"\n",
        "            )\n",
        "\n",
        "    def test_initialization_errors(self):\n",
        "        study = optuna.create_study(direction='minimize')\n",
        "\n",
        "        #Error Test Case 1: Invalid trial type\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        with self.assertRaises(ValueError) as context:\n",
        "            Wrapper(trial=\"invalid_trial_type\", sampler=sampler, device=self.device)\n",
        "        self.assertIn(\"Input 'trial' must either be 'None' or an instance in (optuna::Trial, optuna::FrozenTrial)\", str(context.exception),\n",
        "                    msg=str(context.exception))\n",
        "\n",
        "        #Error Test Case 2: Invalid sampler type\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        with self.assertRaises(ValueError) as context:\n",
        "            Wrapper(trial=study.ask(), sampler=\"invalid_sampler_type\", device=self.device)\n",
        "        self.assertIn(\"Input 'sampler' must either be None of type Sampler\", str(context.exception),\n",
        "                    msg=str(context.exception))\n",
        "\n",
        "        #Error Test Case 3: Both default_dict and sampler are empty\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        with self.assertRaises(ValueError) as context:\n",
        "            Wrapper(trial=None, sampler=None, device=self.device, default_dict={})\n",
        "        self.assertIn(\"Both default_dict and sampler are empty. Nothing to be sampled.\", str(context.exception),\n",
        "                    msg=str(context.exception))\n",
        "\n",
        "        #Error Test Case 4: 'action_func' in default_dict is not a valid Action object\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        with self.assertRaises(ValueError) as context:\n",
        "            Wrapper(trial=study.ask(), sampler=sampler, device=self.device, default_dict={'action_func': 'invalid_action'})\n",
        "        self.assertIn(\"Input 'default_dict' has 'action_func' as a key\", str(context.exception),\n",
        "                    msg=str(context.exception))\n",
        "        self.assertIn(\"which is NOT an Action object\", str(context.exception),\n",
        "                    msg=str(context.exception))\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "id": "ykSuK-Gi0I6z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff05f56e-8fc0-4fd5-ea74-9e20ea6eaad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 19:51:20,371] A new study created in memory with name: no-name-cbc5fad4-dd1a-4df7-b4ee-2603c725d399\n",
            ".[I 2024-09-19 19:51:20,425] A new study created in memory with name: no-name-681d4e28-1050-41c8-be32-8e0f5aebc92c\n",
            "[I 2024-09-19 19:51:20,431] A new study created in memory with name: no-name-a2be2871-bf46-4570-aa9c-66992d706150\n",
            ".[I 2024-09-19 19:51:20,439] A new study created in memory with name: no-name-64fd1678-262d-435d-aee9-8bb661ceadb3\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:689: UserWarning: The distribution is specified by [0.01, 0.95] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2724361874066887803928576.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2727161167480073228386304.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2769671977428313041797120.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2761854881396702467588096.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2652712990702342995181568.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2718289436502123540905984.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2798251748606012171485184.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2806612447127044874043392.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2716531519437974250979328.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2783320838660601199722496.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2868458903629046118088704.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2774076137575911197245440.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2797939018647887564242944.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2787453485793864442707968.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2802936933370358245883904.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2706616970959107670409216.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2690323019564875253809152.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2731968561923907628564480.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2722945798228854444130304.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2710269426285702161629184.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".[I 2024-09-19 19:51:39,861] A new study created in memory with name: no-name-d2d85240-95b2-452d-9a22-2c91ca5000d2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2840047458991019588059136.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2746955100331915880693760.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2703500335901779211321344.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2540461670710058856480768.000000</td>\n",
              "      <td>429408207360795078103885460537344.000000</td>\n",
              "      <td>429408207360795078103885460537344.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2637044210993983641354240.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2850551150358740267433984.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2757526237607656060616704.000000</td>\n",
              "      <td>429408246046421305772019051134976.000000</td>\n",
              "      <td>429408246046421305772019051134976.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2906254264623443927367680.000000</td>\n",
              "      <td>429408246046421305772019051134976.000000</td>\n",
              "      <td>429408246046421305772019051134976.000000</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2768611289644074742579200.000000</td>\n",
              "      <td>429408478160178671780820594720768.000000</td>\n",
              "      <td>429408478160178671780820594720768.000000</td>\n",
              "      <td>00:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2925093578469472110379008.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 50.033s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: HpoTrainer"
      ],
      "metadata": {
        "id": "Ebi8cz_iT8jS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HpoTrainer:\n",
        "    def __init__(self, sampler: Sampler, n_trials: int, device: torch.device, prev_top_k_trials: list = [],\n",
        "                 pruner: optuna.pruners = None, timeout: int = 14400, eta: int = 2, learner_bar: bool = False, learner_logging: bool = False):\n",
        "        \"\"\"\n",
        "        Class Explanation: HpoTrainer is a TEMPORARY wrapper for running a single HPO process.\n",
        "        \"\"\"\n",
        "        self.sampler = sampler\n",
        "        self.device = device\n",
        "        self.eta = eta\n",
        "        self.timeout = timeout\n",
        "        self.learner_bar = learner_bar\n",
        "        self.learner_logging = learner_logging\n",
        "\n",
        "        #Enqueue ALL the previous_top_k_trials.\n",
        "        #NOTE: This allows the optimizer to efficiently search the new space.\n",
        "        self.prior_trials = prev_top_k_trials\n",
        "\n",
        "        # Use the user-defined n_trials for new trials (ignore the prior trial count)\n",
        "        self.n_trials = n_trials\n",
        "\n",
        "        # Select a pruner if not specified\n",
        "        choices = (optuna.pruners.HyperbandPruner, optuna.pruners.SuccessiveHalvingPruner)\n",
        "        self.pruner = random.choice(choices) if pruner is None else pruner\n",
        "\n",
        "    def run(self):\n",
        "        print(\"*****************RUNNING: HPO PROCESS*****************\")\n",
        "\n",
        "        # To get logging info on the HPO process:\n",
        "        optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
        "\n",
        "        # Create the study object with pruner\n",
        "        study = optuna.create_study(\n",
        "            direction='minimize',\n",
        "            pruner=self.pruner(reduction_factor=self.eta)\n",
        "        )\n",
        "\n",
        "        # Enqueue the prior trials (these will run first)\n",
        "        for trial in self.prior_trials:\n",
        "            study.enqueue_trial(trial.params)\n",
        "\n",
        "        # Run the optimization for the user-defined n_trials (new trials only)\n",
        "        study.optimize(func=self.objective, n_trials=self.n_trials, timeout=self.timeout)\n",
        "\n",
        "        # Return the optimized study\n",
        "        return study\n",
        "\n",
        "    def objective(self, trial):\n",
        "        # Sanity check\n",
        "        if not isinstance(trial, (Trial, FrozenTrial)):\n",
        "            raise ValueError(f\"Input 'trial' MUST be an instance of optuna::Trial OR optuna::FrozenTrial but found trial: {trial}. \"\n",
        "                             f\"NOTE: FrozenTrial is NOT allowed for optimization via HpoTrainer!\")\n",
        "\n",
        "        #Initialize a wrapper with the trial and sampler\n",
        "        sample_wrapper = Wrapper(trial=trial, sampler=self.sampler, device=self.device)\n",
        "\n",
        "        #Unpack the execution set yielded by the 'text_vars'\n",
        "        trainer, learner = sample_wrapper.yield_execution_set()\n",
        "\n",
        "        #Run the trainer with logging and progress bar management\n",
        "        if not self.learner_bar and not self.learner_logging:\n",
        "            with learner.no_bar(), learner.no_logging():\n",
        "                trainer()\n",
        "        elif not self.learner_bar:\n",
        "            with learner.no_bar():\n",
        "                trainer()\n",
        "        elif not self.learner_logging:\n",
        "            with learner.no_logging():\n",
        "                trainer()\n",
        "        else:\n",
        "            trainer()\n",
        "\n",
        "        #Return the validation loss (index 0 of learner.validate())\n",
        "        return learner.validate()[0]"
      ],
      "metadata": {
        "id": "6aLuEwSsLsO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test: HpoTrainer"
      ],
      "metadata": {
        "id": "npIqWHWz127V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestHpoTrainer(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.INIT_DICT = {\n",
        "            'dls_func': {\n",
        "                'params': {'choices': [get_dls]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'freeze': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'lr_low': {\n",
        "                'params': {'low': 1e-7, 'high': 9e-4, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'lr_high': {\n",
        "                'params': {'low': 9e-4, 'high': 1e-1, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'lr': {\n",
        "                'params': {'low': 1e-6, 'high': 1e-1, 'log': True},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'wd': {\n",
        "                'params': {'choices': [1e-4, 1e-3, 1e-2, 1e-1]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'gradient_clip': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'max_norm': {\n",
        "                'params': {'low': 0.0, 'high': 15.0, 'log': False},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'one_cycle': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'pct_start': {\n",
        "                'params': {'low': 0.10, 'high': 0.95,  'log': False, 'step': 0.05},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'n_epoch': {\n",
        "                'params': {'choices': list(range(1,11))},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'action_func': {\n",
        "                'params': {'choices': [action_default, action_dropout]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'activation': {\n",
        "                'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'loss_func': {\n",
        "                'params': {'choices': [custom_mse]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'metric': {\n",
        "                'params': {'choices': [custom_mse]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'preprocess': {\n",
        "                'params': {'choices': [True, False]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'start_neurons': {\n",
        "                'params': {'choices': [1, 2, 4, 8, 16, 32]},\n",
        "                'sample': 'categorical'\n",
        "            },\n",
        "            'dropout_p': {\n",
        "                'params': {'low': 0.01, 'high': 0.95,  'log': False, 'step': 0.05},\n",
        "                'sample': 'float'\n",
        "            },\n",
        "            'batch_size': {\n",
        "                'params': {'choices': [64]},\n",
        "                'sample': 'categorical'\n",
        "            }\n",
        "        }\n",
        "        self.device = torch.device('cpu')\n",
        "\n",
        "    def test_initialization(self):\n",
        "        sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "        hpo_trainer = HpoTrainer(\n",
        "            sampler = sampler,\n",
        "            n_trials = 2,\n",
        "            device = self.device\n",
        "        )\n",
        "        self.assertIsInstance(hpo_trainer, HpoTrainer)\n",
        "        self.assertIsInstance(hpo_trainer.sampler, Sampler)\n",
        "        self.assertEqual(hpo_trainer.n_trials, 2)\n",
        "        self.assertEqual(hpo_trainer.device, self.device)\n",
        "        self.assertEqual(hpo_trainer.eta, 2)\n",
        "        self.assertEqual(hpo_trainer.timeout, 14400)\n",
        "        self.assertEqual(hpo_trainer.eta, 2)\n",
        "        self.assertEqual(hpo_trainer.learner_bar, False)\n",
        "        self.assertEqual(hpo_trainer.learner_logging, False)\n",
        "\n",
        "    def test_run(self):\n",
        "        n_trials = [4, 2, 1]\n",
        "        top_ks = random.choices(list(range(1,10)), k=len(n_trials))\n",
        "        for n,k in zip(n_trials,top_ks):\n",
        "            sampler = Sampler(INIT_DICT=self.INIT_DICT)\n",
        "            hpo_trainer = HpoTrainer(\n",
        "                sampler = sampler,\n",
        "                n_trials = n,\n",
        "                device = self.device\n",
        "            )\n",
        "            study = hpo_trainer.run()\n",
        "            prev_trials = study.trials\n",
        "            top_k = min(len(prev_trials), k)\n",
        "            top_k_trials = sorted(\n",
        "                prev_trials,\n",
        "                key=lambda trial: trial.value if trial.value is not None else float('inf')\n",
        "            )[:top_k]\n",
        "            sampler.update(\n",
        "                top_k_trials=top_k_trials,\n",
        "                model_train_window=2,\n",
        "                device=self.device\n",
        "        )\n",
        "        print(\"****************************************\")\n",
        "        print(sampler)\n",
        "        print(\"****************************************\")\n",
        "        print()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ezJYciEa17Y8",
        "outputId": "e84f04da-8e9f-4dd1-c1db-7e0ec9d8a32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".[I 2024-09-19 21:34:44,149] A new study created in memory with name: no-name-1f36d19e-51f3-4006-b436-e29a57e1ca8c\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-1f36d19e-51f3-4006-b436-e29a57e1ca8c\n",
            "A new study created in memory with name: no-name-1f36d19e-51f3-4006-b436-e29a57e1ca8c\n",
            "A new study created in memory with name: no-name-1f36d19e-51f3-4006-b436-e29a57e1ca8c\n",
            "A new study created in memory with name: no-name-1f36d19e-51f3-4006-b436-e29a57e1ca8c\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 21:34:50,001] Trial 0 finished with value: 4.294084007889262e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'start_neurons': 0, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 6.133469454308796, 'one_cycle': 1, 'n_epoch': 7, 'lr': 5.867481325497264e-06, 'wd': 3}. Best is trial 0 with value: 4.294084007889262e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 4.294084007889262e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'start_neurons': 0, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 6.133469454308796, 'one_cycle': 1, 'n_epoch': 7, 'lr': 5.867481325497264e-06, 'wd': 3}. Best is trial 0 with value: 4.294084007889262e+32.\n",
            "Trial 0 finished with value: 4.294084007889262e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'start_neurons': 0, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 6.133469454308796, 'one_cycle': 1, 'n_epoch': 7, 'lr': 5.867481325497264e-06, 'wd': 3}. Best is trial 0 with value: 4.294084007889262e+32.\n",
            "Trial 0 finished with value: 4.294084007889262e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'start_neurons': 0, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 6.133469454308796, 'one_cycle': 1, 'n_epoch': 7, 'lr': 5.867481325497264e-06, 'wd': 3}. Best is trial 0 with value: 4.294084007889262e+32.\n",
            "Trial 0 finished with value: 4.294084007889262e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'start_neurons': 0, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 6.133469454308796, 'one_cycle': 1, 'n_epoch': 7, 'lr': 5.867481325497264e-06, 'wd': 3}. Best is trial 0 with value: 4.294084007889262e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 21:34:51,451] Trial 1 finished with value: 4.294083621033e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 0, 'start_neurons': 5, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 2.4954292622107316e-05, 'wd': 2}. Best is trial 1 with value: 4.294083621033e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 finished with value: 4.294083621033e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 0, 'start_neurons': 5, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 2.4954292622107316e-05, 'wd': 2}. Best is trial 1 with value: 4.294083621033e+32.\n",
            "Trial 1 finished with value: 4.294083621033e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 0, 'start_neurons': 5, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 2.4954292622107316e-05, 'wd': 2}. Best is trial 1 with value: 4.294083621033e+32.\n",
            "Trial 1 finished with value: 4.294083621033e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 0, 'start_neurons': 5, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 2.4954292622107316e-05, 'wd': 2}. Best is trial 1 with value: 4.294083621033e+32.\n",
            "Trial 1 finished with value: 4.294083621033e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 0, 'start_neurons': 5, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 2.4954292622107316e-05, 'wd': 2}. Best is trial 1 with value: 4.294083621033e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 21:34:59,161] Trial 2 finished with value: 4.294084007889262e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'start_neurons': 4, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 14.807734883811637, 'one_cycle': 1, 'n_epoch': 8, 'lr': 7.679114738413127e-06, 'wd': 3}. Best is trial 1 with value: 4.294083621033e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 finished with value: 4.294084007889262e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'start_neurons': 4, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 14.807734883811637, 'one_cycle': 1, 'n_epoch': 8, 'lr': 7.679114738413127e-06, 'wd': 3}. Best is trial 1 with value: 4.294083621033e+32.\n",
            "Trial 2 finished with value: 4.294084007889262e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'start_neurons': 4, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 14.807734883811637, 'one_cycle': 1, 'n_epoch': 8, 'lr': 7.679114738413127e-06, 'wd': 3}. Best is trial 1 with value: 4.294083621033e+32.\n",
            "Trial 2 finished with value: 4.294084007889262e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'start_neurons': 4, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 14.807734883811637, 'one_cycle': 1, 'n_epoch': 8, 'lr': 7.679114738413127e-06, 'wd': 3}. Best is trial 1 with value: 4.294083621033e+32.\n",
            "Trial 2 finished with value: 4.294084007889262e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'start_neurons': 4, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 14.807734883811637, 'one_cycle': 1, 'n_epoch': 8, 'lr': 7.679114738413127e-06, 'wd': 3}. Best is trial 1 with value: 4.294083621033e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/optuna/distributions.py:689: UserWarning: The distribution is specified by [0.01, 0.95] and step=0.05, but the range is not divisible by `step`. It will be replaced by [0.01, 0.91].\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 21:35:03,670] Trial 3 finished with value: 4.2940832341767376e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.16000000000000003, 'start_neurons': 5, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 12.919424450523847, 'one_cycle': 1, 'n_epoch': 5, 'lr': 0.0007645088859693863, 'wd': 1}. Best is trial 3 with value: 4.2940832341767376e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 finished with value: 4.2940832341767376e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.16000000000000003, 'start_neurons': 5, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 12.919424450523847, 'one_cycle': 1, 'n_epoch': 5, 'lr': 0.0007645088859693863, 'wd': 1}. Best is trial 3 with value: 4.2940832341767376e+32.\n",
            "Trial 3 finished with value: 4.2940832341767376e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.16000000000000003, 'start_neurons': 5, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 12.919424450523847, 'one_cycle': 1, 'n_epoch': 5, 'lr': 0.0007645088859693863, 'wd': 1}. Best is trial 3 with value: 4.2940832341767376e+32.\n",
            "Trial 3 finished with value: 4.2940832341767376e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.16000000000000003, 'start_neurons': 5, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 12.919424450523847, 'one_cycle': 1, 'n_epoch': 5, 'lr': 0.0007645088859693863, 'wd': 1}. Best is trial 3 with value: 4.2940832341767376e+32.\n",
            "Trial 3 finished with value: 4.2940832341767376e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.16000000000000003, 'start_neurons': 5, 'activation': 2, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 12.919424450523847, 'one_cycle': 1, 'n_epoch': 5, 'lr': 0.0007645088859693863, 'wd': 1}. Best is trial 3 with value: 4.2940832341767376e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2652061590052240126640128.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2777272900677809832198144.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2678884597087294573248512.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2641326161462093471023104.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2733847247515664485711872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2729334424516257134936064.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2732278121347894566977536.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2760901991773144908562432.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 21:35:11,953] A new study created in memory with name: no-name-5cba12c3-d738-4dd9-9295-933581443c9e\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-5cba12c3-d738-4dd9-9295-933581443c9e\n",
            "A new study created in memory with name: no-name-5cba12c3-d738-4dd9-9295-933581443c9e\n",
            "A new study created in memory with name: no-name-5cba12c3-d738-4dd9-9295-933581443c9e\n",
            "A new study created in memory with name: no-name-5cba12c3-d738-4dd9-9295-933581443c9e\n",
            "A new study created in memory with name: no-name-5cba12c3-d738-4dd9-9295-933581443c9e\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 21:35:17,834] Trial 0 finished with value: 4.294083621033e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.26, 'start_neurons': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 8, 'lr': 0.00302753994817211, 'wd': 0}. Best is trial 0 with value: 4.294083621033e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 4.294083621033e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.26, 'start_neurons': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 8, 'lr': 0.00302753994817211, 'wd': 0}. Best is trial 0 with value: 4.294083621033e+32.\n",
            "Trial 0 finished with value: 4.294083621033e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.26, 'start_neurons': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 8, 'lr': 0.00302753994817211, 'wd': 0}. Best is trial 0 with value: 4.294083621033e+32.\n",
            "Trial 0 finished with value: 4.294083621033e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.26, 'start_neurons': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 8, 'lr': 0.00302753994817211, 'wd': 0}. Best is trial 0 with value: 4.294083621033e+32.\n",
            "Trial 0 finished with value: 4.294083621033e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.26, 'start_neurons': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 8, 'lr': 0.00302753994817211, 'wd': 0}. Best is trial 0 with value: 4.294083621033e+32.\n",
            "Trial 0 finished with value: 4.294083621033e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.26, 'start_neurons': 1, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 8, 'lr': 0.00302753994817211, 'wd': 0}. Best is trial 0 with value: 4.294083621033e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 21:35:26,691] Trial 1 finished with value: 4.294081299895426e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.91, 'start_neurons': 3, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 7.527898183985028, 'one_cycle': 1, 'n_epoch': 9, 'lr': 0.0542571351045265, 'wd': 2}. Best is trial 1 with value: 4.294081299895426e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 finished with value: 4.294081299895426e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.91, 'start_neurons': 3, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 7.527898183985028, 'one_cycle': 1, 'n_epoch': 9, 'lr': 0.0542571351045265, 'wd': 2}. Best is trial 1 with value: 4.294081299895426e+32.\n",
            "Trial 1 finished with value: 4.294081299895426e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.91, 'start_neurons': 3, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 7.527898183985028, 'one_cycle': 1, 'n_epoch': 9, 'lr': 0.0542571351045265, 'wd': 2}. Best is trial 1 with value: 4.294081299895426e+32.\n",
            "Trial 1 finished with value: 4.294081299895426e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.91, 'start_neurons': 3, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 7.527898183985028, 'one_cycle': 1, 'n_epoch': 9, 'lr': 0.0542571351045265, 'wd': 2}. Best is trial 1 with value: 4.294081299895426e+32.\n",
            "Trial 1 finished with value: 4.294081299895426e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.91, 'start_neurons': 3, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 7.527898183985028, 'one_cycle': 1, 'n_epoch': 9, 'lr': 0.0542571351045265, 'wd': 2}. Best is trial 1 with value: 4.294081299895426e+32.\n",
            "Trial 1 finished with value: 4.294081299895426e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 1, 'preprocess': 0, 'dropout_p': 0.91, 'start_neurons': 3, 'activation': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 7.527898183985028, 'one_cycle': 1, 'n_epoch': 9, 'lr': 0.0542571351045265, 'wd': 2}. Best is trial 1 with value: 4.294081299895426e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2770028806633988860936192.000000</td>\n",
              "      <td>429408439474552444112687004123136.000000</td>\n",
              "      <td>429408439474552444112687004123136.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2729653783773033231548416.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2766928600708101049417728.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2737683882052619920736256.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2708759387345043343802368.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2729379388454936801968128.000000</td>\n",
              "      <td>429408207360795078103885460537344.000000</td>\n",
              "      <td>429408207360795078103885460537344.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2760393841619989440757760.000000</td>\n",
              "      <td>429408246046421305772019051134976.000000</td>\n",
              "      <td>429408246046421305772019051134976.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2727853785073965791707136.000000</td>\n",
              "      <td>429408168675168850435751869939712.000000</td>\n",
              "      <td>429408168675168850435751869939712.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2693435042936185285509120.000000</td>\n",
              "      <td>429408052618290167431351098146816.000000</td>\n",
              "      <td>429408052618290167431351098146816.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2667543308246477019545600.000000</td>\n",
              "      <td>429408091303916395099484688744448.000000</td>\n",
              "      <td>429408091303916395099484688744448.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 21:35:36,799] A new study created in memory with name: no-name-f3ee6def-463e-4a90-8ea1-778912a24f40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-f3ee6def-463e-4a90-8ea1-778912a24f40\n",
            "A new study created in memory with name: no-name-f3ee6def-463e-4a90-8ea1-778912a24f40\n",
            "A new study created in memory with name: no-name-f3ee6def-463e-4a90-8ea1-778912a24f40\n",
            "A new study created in memory with name: no-name-f3ee6def-463e-4a90-8ea1-778912a24f40\n",
            "A new study created in memory with name: no-name-f3ee6def-463e-4a90-8ea1-778912a24f40\n",
            "A new study created in memory with name: no-name-f3ee6def-463e-4a90-8ea1-778912a24f40\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 21:35:43,085] Trial 0 finished with value: 4.2940832341767376e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 0, 'start_neurons': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 2.5488489244988584, 'one_cycle': 0, 'lr_low': 1.2206942053765318e-05, 'lr_high': 0.07580090066969246, 'n_epoch': 7, 'wd': 3, 'pct_start': 0.55}. Best is trial 0 with value: 4.2940832341767376e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 4.2940832341767376e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 0, 'start_neurons': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 2.5488489244988584, 'one_cycle': 0, 'lr_low': 1.2206942053765318e-05, 'lr_high': 0.07580090066969246, 'n_epoch': 7, 'wd': 3, 'pct_start': 0.55}. Best is trial 0 with value: 4.2940832341767376e+32.\n",
            "Trial 0 finished with value: 4.2940832341767376e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 0, 'start_neurons': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 2.5488489244988584, 'one_cycle': 0, 'lr_low': 1.2206942053765318e-05, 'lr_high': 0.07580090066969246, 'n_epoch': 7, 'wd': 3, 'pct_start': 0.55}. Best is trial 0 with value: 4.2940832341767376e+32.\n",
            "Trial 0 finished with value: 4.2940832341767376e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 0, 'start_neurons': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 2.5488489244988584, 'one_cycle': 0, 'lr_low': 1.2206942053765318e-05, 'lr_high': 0.07580090066969246, 'n_epoch': 7, 'wd': 3, 'pct_start': 0.55}. Best is trial 0 with value: 4.2940832341767376e+32.\n",
            "Trial 0 finished with value: 4.2940832341767376e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 0, 'start_neurons': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 2.5488489244988584, 'one_cycle': 0, 'lr_low': 1.2206942053765318e-05, 'lr_high': 0.07580090066969246, 'n_epoch': 7, 'wd': 3, 'pct_start': 0.55}. Best is trial 0 with value: 4.2940832341767376e+32.\n",
            "Trial 0 finished with value: 4.2940832341767376e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 0, 'start_neurons': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 2.5488489244988584, 'one_cycle': 0, 'lr_low': 1.2206942053765318e-05, 'lr_high': 0.07580090066969246, 'n_epoch': 7, 'wd': 3, 'pct_start': 0.55}. Best is trial 0 with value: 4.2940832341767376e+32.\n",
            "Trial 0 finished with value: 4.2940832341767376e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 0, 'start_neurons': 0, 'activation': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 0, 'max_norm': 2.5488489244988584, 'one_cycle': 0, 'lr_low': 1.2206942053765318e-05, 'lr_high': 0.07580090066969246, 'n_epoch': 7, 'wd': 3, 'pct_start': 0.55}. Best is trial 0 with value: 4.2940832341767376e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2814136124635733005697024.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2704818413411920989126656.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2819779387170407369932800.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2821498104903400027062272.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2773578363716297191063552.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2798667088578046788108288.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2656933836330708661960704.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2846471825845065091121152.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".[I 2024-09-19 21:35:51,669] A new study created in memory with name: no-name-37e7533e-8fca-4a31-8266-73bdc73ae6e4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "****************************************\n",
            "Sampler:\n",
            "**********ActionSampler**********\n",
            "Action of func: action_default\n",
            "Signature Vars:\n",
            "Var of type: preprocess\n",
            "Configuration Space:\n",
            "'choices' = [True]\n",
            " Var of type: start_neurons\n",
            "Configuration Space:\n",
            "'choices' = [1]\n",
            " Var of type: activation\n",
            "Configuration Space:\n",
            "'choices' = [<class 'torch.nn.modules.activation.ReLU'>]\n",
            "\n",
            "Model loader parameters: preprocess=True start_neurons=1 activation=<class 'torch.nn.modules.activation.ReLU'>\n",
            "\n",
            "Action of func: action_dropout\n",
            "Signature Vars:\n",
            "Var of type: preprocess\n",
            "Configuration Space:\n",
            "'choices' = [True, False]\n",
            " Var of type: dropout_p\n",
            "Configuration Space:\n",
            "'low': 0.01, 'high': 0.95, 'log': False, 'step': 0.05\n",
            " Var of type: start_neurons\n",
            "Configuration Space:\n",
            "'choices' = [1, 2, 4, 8, 16, 32]\n",
            " Var of type: activation\n",
            "Configuration Space:\n",
            "'choices' = [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.PReLU'>, <class 'torch.nn.modules.activation.SiLU'>]\n",
            "\n",
            "\n",
            "\n",
            "**********TrainSampler**********\n",
            "Var of type: loss_func\n",
            "Configuration Space:\n",
            "'choices' = [<function custom_mse at 0x7d49f8259c60>]\n",
            "\n",
            "Var of type: lr_high\n",
            "Configuration Space:\n",
            "'low': 0.07580090066969246, 'high': 0.07580090066969246, 'log': True, 'step': unspecified\n",
            "\n",
            "Var of type: lr_low\n",
            "Configuration Space:\n",
            "'low': 1.2206942053765318e-05, 'high': 1.2206942053765318e-05, 'log': True, 'step': unspecified\n",
            "\n",
            "Var of type: gradient_clip\n",
            "Configuration Space:\n",
            "'choices' = [True]\n",
            "\n",
            "Var of type: pct_start\n",
            "Configuration Space:\n",
            "'low': 0.55, 'high': 0.55, 'log': False, 'step': 0.05\n",
            "\n",
            "Var of type: wd\n",
            "Configuration Space:\n",
            "'choices' = [0.1]\n",
            "\n",
            "Var of type: freeze\n",
            "Configuration Space:\n",
            "'choices' = [False]\n",
            "\n",
            "Var of type: max_norm\n",
            "Configuration Space:\n",
            "'low': 2.5488489244988584, 'high': 2.5488489244988584, 'log': False, 'step': unspecified\n",
            "\n",
            "Var of type: batch_size\n",
            "Configuration Space:\n",
            "'choices' = [64]\n",
            "\n",
            "Var of type: dls_func\n",
            "Configuration Space:\n",
            "'choices' = [<function get_dls at 0x7d49f8259bd0>]\n",
            "\n",
            "Var of type: action_func\n",
            "Configuration Space:\n",
            "'choices' = [<function action_default at 0x7d49f8259990>]\n",
            "\n",
            "Var of type: metric\n",
            "Configuration Space:\n",
            "'choices' = [<function custom_mse at 0x7d49f8259c60>]\n",
            "\n",
            "Var of type: n_epoch\n",
            "Configuration Space:\n",
            "'choices' = [8]\n",
            "\n",
            "Var of type: one_cycle\n",
            "Configuration Space:\n",
            "'choices' = [True]\n",
            "\n",
            "Var of type: lr\n",
            "Configuration Space:\n",
            "'low': 1e-06, 'high': 0.1, 'log': True, 'step': unspecified\n",
            "\n",
            "\n",
            "\n",
            "****************************************\n",
            "\n",
            "A new study created in memory with name: no-name-37e7533e-8fca-4a31-8266-73bdc73ae6e4\n",
            "A new study created in memory with name: no-name-37e7533e-8fca-4a31-8266-73bdc73ae6e4\n",
            "A new study created in memory with name: no-name-37e7533e-8fca-4a31-8266-73bdc73ae6e4\n",
            "A new study created in memory with name: no-name-37e7533e-8fca-4a31-8266-73bdc73ae6e4\n",
            "A new study created in memory with name: no-name-37e7533e-8fca-4a31-8266-73bdc73ae6e4\n",
            "A new study created in memory with name: no-name-37e7533e-8fca-4a31-8266-73bdc73ae6e4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".[I 2024-09-19 21:35:51,689] A new study created in memory with name: no-name-f0a53066-893e-40f1-a71c-93aa481e12f9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A new study created in memory with name: no-name-f0a53066-893e-40f1-a71c-93aa481e12f9\n",
            "A new study created in memory with name: no-name-f0a53066-893e-40f1-a71c-93aa481e12f9\n",
            "A new study created in memory with name: no-name-f0a53066-893e-40f1-a71c-93aa481e12f9\n",
            "A new study created in memory with name: no-name-f0a53066-893e-40f1-a71c-93aa481e12f9\n",
            "A new study created in memory with name: no-name-f0a53066-893e-40f1-a71c-93aa481e12f9\n",
            "A new study created in memory with name: no-name-f0a53066-893e-40f1-a71c-93aa481e12f9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 21:35:51,704] A new study created in memory with name: no-name-6e0598af-2366-469b-b9a7-dd2989dc15d4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A new study created in memory with name: no-name-6e0598af-2366-469b-b9a7-dd2989dc15d4\n",
            "A new study created in memory with name: no-name-6e0598af-2366-469b-b9a7-dd2989dc15d4\n",
            "A new study created in memory with name: no-name-6e0598af-2366-469b-b9a7-dd2989dc15d4\n",
            "A new study created in memory with name: no-name-6e0598af-2366-469b-b9a7-dd2989dc15d4\n",
            "A new study created in memory with name: no-name-6e0598af-2366-469b-b9a7-dd2989dc15d4\n",
            "A new study created in memory with name: no-name-6e0598af-2366-469b-b9a7-dd2989dc15d4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".[I 2024-09-19 21:35:51,724] A new study created in memory with name: no-name-bd89378e-0ad4-473c-89fa-06cc41fd10a1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A new study created in memory with name: no-name-bd89378e-0ad4-473c-89fa-06cc41fd10a1\n",
            "A new study created in memory with name: no-name-bd89378e-0ad4-473c-89fa-06cc41fd10a1\n",
            "A new study created in memory with name: no-name-bd89378e-0ad4-473c-89fa-06cc41fd10a1\n",
            "A new study created in memory with name: no-name-bd89378e-0ad4-473c-89fa-06cc41fd10a1\n",
            "A new study created in memory with name: no-name-bd89378e-0ad4-473c-89fa-06cc41fd10a1\n",
            "A new study created in memory with name: no-name-bd89378e-0ad4-473c-89fa-06cc41fd10a1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2710343213261996999835648.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2665655975743435611045888.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2745225718075005610229760.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2805064938237486333689856.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2841103535089239459889152.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2737920230961064324366336.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2612834300549120613416960.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2788320482765328791633920.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2811615838226662438207488.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2737172273134950632390656.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2634617887687538531893248.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2668278007475287732781056.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2733152324078762708697088.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2776938265211097694863360.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2661025266520182210166784.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2778590401727199306579968.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2863524111358952661319680.000000</td>\n",
              "      <td>429408439474552444112687004123136.000000</td>\n",
              "      <td>429408439474552444112687004123136.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2841761853268369969512448.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2707418251404809429057536.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2835124195935972199759872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".[I 2024-09-19 21:36:09,971] A new study created in memory with name: no-name-05c6e5f3-bbcc-4b91-b305-9e0eba84d29d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A new study created in memory with name: no-name-05c6e5f3-bbcc-4b91-b305-9e0eba84d29d\n",
            "A new study created in memory with name: no-name-05c6e5f3-bbcc-4b91-b305-9e0eba84d29d\n",
            "A new study created in memory with name: no-name-05c6e5f3-bbcc-4b91-b305-9e0eba84d29d\n",
            "A new study created in memory with name: no-name-05c6e5f3-bbcc-4b91-b305-9e0eba84d29d\n",
            "A new study created in memory with name: no-name-05c6e5f3-bbcc-4b91-b305-9e0eba84d29d\n",
            "A new study created in memory with name: no-name-05c6e5f3-bbcc-4b91-b305-9e0eba84d29d\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2781728077601986840625152.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2716885754570264704712704.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2840393911903153945575424.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2626207613541807734915072.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2867272835631181824262144.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>429408362103299988776419822927872.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2729752646792053268676608.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2690246926745571201908736.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2755478072554721996963840.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>429408400788926216444553413525504.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2666461579644779645370368.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>429408284732047533440152641732608.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2517051887789392980344832.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>429408323417673761108286232330240.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".\n",
            "----------------------------------------------------------------------\n",
            "Ran 6 tests in 102.832s\n",
            "\n",
            "OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class: Auto"
      ],
      "metadata": {
        "id": "TbbIOisFWDBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Auto:\n",
        "    def __init__(self, INIT_DICT: dict, storage_dir: str = '/content/trial_storage/'):\n",
        "        self.sampler = Sampler(INIT_DICT=INIT_DICT)\n",
        "        if self.sampler.is_fixed():\n",
        "            raise ValueError(\"Input 'INIT_DICT' is completely determined from the beginning. Nothing to optimize for\")\n",
        "\n",
        "        self.prev_top_k_trials = []\n",
        "        self.storage_dir = storage_dir\n",
        "        os.makedirs(self.storage_dir, exist_ok=True)\n",
        "        self._n_study = None\n",
        "\n",
        "    def optimize(self, n_auto: int, top_k: int, model_train_window: int, device: torch.device):\n",
        "        list_n_trials = self._get_list_n_trials(n_auto=n_auto)\n",
        "        print(\"*****************************************************************\")\n",
        "        print(f\"n_auto: {n_auto}, list_n_trials: {list_n_trials}\")\n",
        "        print()\n",
        "\n",
        "        for idx, n_trials in enumerate(list_n_trials):\n",
        "            hpo_pointer = HpoTrainer(\n",
        "                sampler=self.sampler,\n",
        "                n_trials=n_trials,\n",
        "                device=device,\n",
        "                prev_top_k_trials=self.prev_top_k_trials\n",
        "            )\n",
        "            optimized_study = hpo_pointer.run()\n",
        "            self._update(\n",
        "                idx=idx,\n",
        "                optimized_study=optimized_study,\n",
        "                top_k=top_k,\n",
        "                model_train_window=model_train_window,\n",
        "                device=device\n",
        "            )\n",
        "            self._n_study = len(list_n_trials)\n",
        "\n",
        "    def num_study(self):\n",
        "        return self._n_study\n",
        "\n",
        "    def get_study(self, idx: int):\n",
        "        if self._n_study is None:\n",
        "            raise SyntaxError(\".visualization_trials is requested w/o saved data. Call .optimize() first and once it's finished, request visualization again.\")\n",
        "        if idx < 0 or idx >= self._n_study:\n",
        "            raise ValueError(f\"Input 'idx':{idx} must satisfy 0 <= idx < {self._n_study} but failed.\")\n",
        "\n",
        "        return self._load_study_from_pickle(idx)\n",
        "\n",
        "    def _get_list_n_trials(self, n_auto: int):\n",
        "        \"\"\"\n",
        "        ACCEPTS:\n",
        "        n_auto := Positive integer power of 2. IF n_auto <= 1, THEN n_auto <- 2\n",
        "                                               IF n_auto > 1 but NOT a power of 2, THEN n_auto <- (nearest power of 2) - 1.\n",
        "        RETURNS:\n",
        "        Exponential distribution of [2^m, 2^(m-1), ..., 2^1, 2^0] + (n_auto==power of 2)*[2^0] trials returned.\n",
        "        \"\"\"\n",
        "        n_auto = max(n_auto, 2)\n",
        "        pow2 = n_auto & (n_auto-1) == 0\n",
        "\n",
        "        output = [1<<e for e in range(math.ceil(math.log2(n_auto)) - 1, -1, -1)]\n",
        "\n",
        "        if pow2:\n",
        "            output.append(1)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def _update(self, idx: int, optimized_study: optuna.study, top_k: int, model_train_window: int, device: torch.device):\n",
        "        prev_trials = optimized_study.trials\n",
        "        top_k = min(top_k, len(prev_trials))\n",
        "        model_train_window = min(model_train_window, top_k)\n",
        "\n",
        "        top_k_trials = sorted(prev_trials, key=lambda trial: trial.value if trial.value is not None else float('inf'))[:top_k]\n",
        "\n",
        "        #Save the whole study, not just top_k_trials\n",
        "        self._save_study_to_pickle(idx, optimized_study)\n",
        "        self.prev_top_k_trials = top_k_trials\n",
        "\n",
        "        self.sampler.update(\n",
        "            top_k_trials=top_k_trials,\n",
        "            model_train_window=model_train_window,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "    def _save_study_to_pickle(self, idx: int, study: optuna.study):\n",
        "        save_path = os.path.join(self.storage_dir, f'study_{idx}.pkl')\n",
        "        with gzip.open(save_path, 'wb') as f:\n",
        "            pickle.dump(study, f)\n",
        "        print(f\"Saved study to: {save_path}\")\n",
        "\n",
        "    def _load_study_from_pickle(self, idx: int):\n",
        "        load_path = os.path.join(self.storage_dir, f'study_{idx}.pkl')\n",
        "        if not os.path.exists(load_path):\n",
        "            raise FileNotFoundError(f\"No study found at: {load_path}\")\n",
        "\n",
        "        with gzip.open(load_path, 'rb') as f:\n",
        "            study = pickle.load(f)\n",
        "        print(f\"Loaded study from: {load_path}\")\n",
        "        return study"
      ],
      "metadata": {
        "id": "XuQD5DRKelm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prep: FINAL_TEST"
      ],
      "metadata": {
        "id": "vDa7V_pjgwS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class PolynomialDataset(Dataset):\n",
        "    def __init__(self, coeffs: torch.tensor, input_min: float, input_max: float, input_size: int):\n",
        "        #coeffs.shape == [degree+1, 1]\n",
        "        self.coeffs = coeffs.clone().detach()\n",
        "        #inputs.shape == [inputs]\n",
        "        self.inputs = torch.empty(size=(input_size,)).uniform_(input_min, input_max)\n",
        "        #Preprocess the output and retrieve it upon request.\n",
        "        self.outputs = self._f(X=self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.inputs[idx], self.outputs[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        if self.inputs.size(0) != self.outputs.size(0):\n",
        "            return ValueError(f\"len(inputs): {self.inputs.size(0)} != len(outputs): {self.outputs.size(0)}\")\n",
        "        return self.inputs.size(0)\n",
        "\n",
        "    def _f(self, X):\n",
        "        #power.shape == [1, degree+1]\n",
        "        powers = torch.arange(self.coeffs.size(0)).unsqueeze(0)\n",
        "        Y = self.inputs.unsqueeze(-1)**powers\n",
        "        return torch.matmul(Y, self.coeffs).squeeze(-1)\n",
        "\n",
        "degree = 6\n",
        "coeffs_min, coeffs_max = -10.0, 10.0\n",
        "coeffs = torch.empty(size=(degree+1,)).uniform_(coeffs_min, coeffs_max)\n",
        "\n",
        "for c in coeffs:\n",
        "    print(f\"c: {c}\")\n",
        "\n",
        "train_dset = PolynomialDataset(coeffs=coeffs, input_min=-100.0, input_max=100.0, input_size=8000)\n",
        "valid_dset = PolynomialDataset(coeffs=coeffs, input_min=-300.12, input_max=500.78, input_size=2000)\n",
        "\n",
        "#Test:\n",
        "print(f\"Number of elements in Dataset; train_dset: {len(train_dset)}, valid_dset: {len(valid_dset)}\")\n",
        "print()\n",
        "\n",
        "print(f\"train first input: {train_dset[0][0]}, train first output: {train_dset[0][1]}\")\n",
        "print()\n",
        "\n",
        "print(f\"valid first input: {valid_dset[0][0]}, valid first output: {valid_dset[0][1]}\")\n",
        "print()"
      ],
      "metadata": {
        "id": "ObeKjyVhLgvX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f94b0e9-6389-4a66-9ae8-391999587e37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c: 5.824830532073975\n",
            "c: -9.791574478149414\n",
            "c: -5.3719482421875\n",
            "c: -4.224552154541016\n",
            "c: 6.264415740966797\n",
            "c: 5.379673004150391\n",
            "c: 6.184241771697998\n",
            "Number of elements in Dataset; train_dset: 8000, valid_dset: 2000\n",
            "\n",
            "train first input: -57.08179473876953, train first output: 210737332224.0\n",
            "\n",
            "valid first input: -246.2458953857422, valid first output: 1373949569007616.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Action functions:\n",
        "\"\"\"\n",
        "class ModelDefault(nn.Module):\n",
        "    def __init__(self, activation: nn.Module, preprocess: bool, start_neurons: int):\n",
        "        super().__init__()\n",
        "        self.preprocess = preprocess\n",
        "        if self.preprocess: start_neurons = max(start_neurons,degree+1)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=degree+1 if self.preprocess else 1,\n",
        "                      out_features=start_neurons),\n",
        "            nn.BatchNorm1d(num_features=start_neurons),\n",
        "            activation(),\n",
        "            nn.Linear(in_features=start_neurons,out_features=start_neurons*2),\n",
        "            nn.BatchNorm1d(num_features=start_neurons*2),\n",
        "            activation(),\n",
        "            nn.Linear(in_features=start_neurons*2,out_features=1)\n",
        "        )\n",
        "\n",
        "    def _preprocess(self, X):\n",
        "        N = X.size(0)\n",
        "        #X <- [64,1]x[1,7] == [64,7], where each index (i,j) yields X[i]**j.\n",
        "        X = X.unsqueeze(-1)**torch.arange(degree+1).unsqueeze(0)\n",
        "        if X.size() != torch.Size([N,degree+1]):\n",
        "            raise ValueError(f\"X.size() MUST be torch.Size([{N},{degree+1}]) but found X.size()=={X.size()}\")\n",
        "        return X\n",
        "\n",
        "    def forward(self, X):\n",
        "        if X.dim() != 1:\n",
        "            raise ValueError(f\"X.dim() MUST be 1 but found X.dim()=={X.dim()}\")\n",
        "\n",
        "        if self.preprocess:\n",
        "            X = self._preprocess(X)\n",
        "        else:\n",
        "            X = X.unsqueeze(-1)\n",
        "        return self.net(X)\n",
        "\n",
        "class ModelDropout(nn.Module):\n",
        "    def __init__(self, activation: nn.Module, dropout_p: int, preprocess: int, start_neurons: Int):\n",
        "        super().__init__()\n",
        "        self.preprocess = preprocess\n",
        "        if self.preprocess: start_neurons = max(start_neurons,degree+1)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_features=degree+1 if self.preprocess else 1,\n",
        "                      out_features=start_neurons),\n",
        "            nn.BatchNorm1d(num_features=start_neurons),\n",
        "            activation(),\n",
        "            nn.Dropout(p=dropout_p),\n",
        "            nn.Linear(in_features=start_neurons,out_features=start_neurons*2),\n",
        "            nn.BatchNorm1d(num_features=start_neurons*2),\n",
        "            activation(),\n",
        "            nn.Linear(in_features=start_neurons*2,out_features=1)\n",
        "        )\n",
        "\n",
        "    def _preprocess(self, X):\n",
        "        N = X.size(0)\n",
        "        #X <- [64,1]x[1,7] == [64,7], where each index (i,j) yields X[i]**j.\n",
        "        X = X.unsqueeze(-1)**torch.arange(degree+1).unsqueeze(0)\n",
        "        if X.size() != torch.Size([N,degree+1]):\n",
        "            raise ValueError(f\"X.size() MUST be torch.Size([{N},{degree+1}]) but found X.size()=={X.size()}\")\n",
        "        return X\n",
        "\n",
        "    def forward(self, X):\n",
        "        if X.dim() != 1:\n",
        "            raise ValueError(f\"X.dim() MUST be 1 but found X.dim()=={X.dim()}\")\n",
        "\n",
        "        if self.preprocess:\n",
        "            X = self._preprocess(X)\n",
        "        else:\n",
        "            X = X.unsqueeze(-1)\n",
        "        return self.net(X)\n",
        "\n",
        "def action_default(activation: nn.Module, preprocess: bool, start_neurons: int, device: torch.device):\n",
        "    if start_neurons < 1:\n",
        "        raise ValueError(f\"start_neurons MUST be a positive integer but found start_neurons: {start_neurons}\")\n",
        "    return ModelDefault(activation=activation,\n",
        "                        preprocess=preprocess,\n",
        "                        start_neurons=start_neurons).to(device)\n",
        "\n",
        "def action_dropout(activation: nn.Module, dropout_p: int, preprocess: bool, start_neurons: int, device: torch.device):\n",
        "    if start_neurons < 1:\n",
        "        raise ValueError(f\"start_neurons MUST be a positive integer but found start_neurons: {start_neurons}\")\n",
        "    if dropout_p < 0.0 or dropout_p >= 1.0:\n",
        "        raise ValueError(f\"0.0 <= dropout_p < 1.0 required but found dropout_p: {dropout_p}\")\n",
        "    return ModelDropout(activation=activation,\n",
        "                        dropout_p=dropout_p,\n",
        "                        preprocess=preprocess,\n",
        "                        start_neurons=start_neurons).to(device)"
      ],
      "metadata": {
        "id": "3LF3NkjfxEPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define DataLoaders and training process\n",
        "def get_dls(batch_size: int):\n",
        "    train_dataloader = DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
        "    valid_dataloader = DataLoader(valid_dset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    dls = DataLoaders(train_dataloader, valid_dataloader)\n",
        "    return dls\n",
        "\n",
        "# Now you can use this DataLoaders object with Learner\n",
        "# Example usage:\n",
        "train_dls, valid_dls = get_dls(batch_size=64)\n",
        "\n",
        "print(f\"len(train_dls): {len(train_dls)}\")\n",
        "print(f\"len(valid_dls): {len(valid_dls)}\")\n",
        "print()\n",
        "\n",
        "print(\"*****CHECKING data integrity of returned 'dls'******\")\n",
        "for blob in iter(train_dls):\n",
        "    if not isinstance(blob, tuple):\n",
        "        raise ValueError(f\"Sampled 'blob' from 'iter(train_dls)' MUST have a type 'tuple' but found: {type(blob)}\")\n",
        "    inputs, outputs = blob\n",
        "    if inputs.size() != outputs.size():\n",
        "        raise ValueError(f\"train_dls contains (inputs,outputs) where inputs.size(): {inputs.size()} != outputs.size(): {outputs.size()}\")\n",
        "\n",
        "for blob in iter(valid_dls):\n",
        "    if not isinstance(blob, tuple):\n",
        "        raise ValueError(f\"Sampled 'blob' from 'iter(valid_dls)' MUST have a type 'tuple' but found: {type(blob)}\")\n",
        "    inputs, outputs = blob\n",
        "    if inputs.size() != outputs.size():\n",
        "        raise ValueError(f\"valid_dls contains (inputs,outputs) where inputs.size(): {inputs.size()} != outputs.size(): {outputs.size()}\")\n",
        "\n",
        "inputs, _ = next(iter(train_dls))\n",
        "print(inputs.size())\n",
        "inputs, _ = next(iter(valid_dls))\n",
        "print(inputs.size())"
      ],
      "metadata": {
        "id": "-uD1yXhJd-Hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf61b608-1305-48b2-d83e-d56db740b116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_dls): 125\n",
            "len(valid_dls): 32\n",
            "\n",
            "*****CHECKING data integrity of returned 'dls'******\n",
            "torch.Size([64])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_default = ModelDefault(activation=nn.ReLU, preprocess=False, start_neurons=7)\n",
        "model_dropout = ModelDropout(activation=nn.ReLU, dropout_p=0.5, preprocess=False, start_neurons=7)\n",
        "\n",
        "print(\"*********************model_default*********************\")\n",
        "print(model_default)\n",
        "print()\n",
        "print(\"*********************model_dropout*********************\")\n",
        "print(model_dropout)\n",
        "print()"
      ],
      "metadata": {
        "id": "Wxsxaaj64Nrj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c3697f-427a-4f7f-cef7-d59daf6aedf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*********************model_default*********************\n",
            "ModelDefault(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=1, out_features=7, bias=True)\n",
            "    (1): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=7, out_features=14, bias=True)\n",
            "    (4): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=14, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "*********************model_dropout*********************\n",
            "ModelDropout(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=1, out_features=7, bias=True)\n",
            "    (1): BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU()\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=7, out_features=14, bias=True)\n",
            "    (5): BatchNorm1d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): Linear(in_features=14, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learner = Learner(\n",
        "    dls=get_dls(batch_size=64),\n",
        "    model=ModelDefault(activation=nn.ReLU, preprocess=False, start_neurons=7),\n",
        "    loss_func=custom_mse,\n",
        "    metrics=[custom_mse]\n",
        ")\n",
        "learner.fit_one_cycle(n_epoch=10, lr_max=slice(1e-6,1e-3), pct_start=0.3, wd=0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "2MAZrSDCG9C8",
        "outputId": "37c06326-0080-49f2-a48e-520ae77c3b2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'custom_mse' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-14d55ae1a578>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_dls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModelDefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_neurons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_mse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcustom_mse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;31mNameError\u001b[0m: name 'custom_mse' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_mse(Y_hat, Y):\n",
        "    Y_hat = Y_hat.reshape(-1)\n",
        "    Y = Y.reshape(-1)\n",
        "    if Y_hat.size() != Y.size():\n",
        "        raise ValueError(f\"Y_hat.size(): {Y_hat.size()} != Y.size(): {Y.size()}\")\n",
        "    return nn.MSELoss()(Y_hat, Y)\n",
        "\n",
        "INIT_DICT = {\n",
        "    'dls_func': {\n",
        "        'params': {'choices': [get_dls]},\n",
        "        'sample': 'categorical'\n",
        "    },\n",
        "    'freeze': {\n",
        "        'params': {'choices': [True, False]},\n",
        "        'sample': 'categorical'\n",
        "    },\n",
        "    'lr_low': {\n",
        "        'params': {'low': 1e-7, 'high': 9e-4, 'log': True},\n",
        "        'sample': 'float'\n",
        "    },\n",
        "    'lr_high': {\n",
        "        'params': {'low': 9e-4, 'high': 1e-1, 'log': True},\n",
        "        'sample': 'float'\n",
        "    },\n",
        "    'lr': {\n",
        "        'params': {'low': 1e-6, 'high': 1e-1, 'log': True},\n",
        "        'sample': 'float'\n",
        "    },\n",
        "    'wd': {\n",
        "        'params': {'choices': [1e-4, 1e-3, 1e-2, 1e-1]},\n",
        "        'sample': 'categorical'\n",
        "    },\n",
        "    'gradient_clip': {\n",
        "        'params': {'choices': [True, False]},\n",
        "        'sample': 'categorical'\n",
        "    },\n",
        "    'max_norm': {\n",
        "        'params': {'low': 0.0, 'high': 15.0, 'log': False},\n",
        "        'sample': 'float'\n",
        "    },\n",
        "    'one_cycle': {\n",
        "        'params': {'choices': [True, False]},\n",
        "        'sample': 'categorical'\n",
        "    },\n",
        "    'pct_start': {\n",
        "        'params': {'low': 0.10, 'high': 0.95,  'log': False, 'step': 0.05},\n",
        "        'sample': 'float'\n",
        "    },\n",
        "    'n_epoch': {\n",
        "        'params': {'choices': [5, 10, 15]},\n",
        "        'sample': 'categorical'\n",
        "    },\n",
        "    'action_func': {\n",
        "        'params': {'choices': [action_default, action_dropout]},\n",
        "        'sample': 'categorical'\n",
        "    },\n",
        "    'activation': {\n",
        "        'params': {'choices': [nn.ReLU, nn.PReLU, nn.SiLU]},\n",
        "        'sample': 'categorical'\n",
        "    },\n",
        "    'loss_func': {\n",
        "        'params': {'choices': [custom_mse]},\n",
        "        'sample': 'categorical'\n",
        "    },\n",
        "    'metric': {\n",
        "        'params': {'choices': [custom_mse]},\n",
        "        'sample': 'categorical'\n",
        "    },\n",
        "    'preprocess': {\n",
        "        'params': {'choices': [True, False]},\n",
        "        'sample': 'categorical'\n",
        "    },\n",
        "    'start_neurons': {\n",
        "        'params': {'choices': [1, 2, 4, 8, 16, 32,]},\n",
        "        'sample': 'categorical'\n",
        "    },\n",
        "    'dropout_p': {\n",
        "        'params': {'low': 0.05, 'high': 0.95,  'log': False, 'step': 0.05},\n",
        "        'sample': 'float'\n",
        "    },\n",
        "    'batch_size': {\n",
        "        'params': {'choices': [32, 64, 128]},\n",
        "        'sample': 'categorical'\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "xsIcM8kI8eWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FINAL_TEST"
      ],
      "metadata": {
        "id": "jDCVotsAbqxV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auto = Auto(INIT_DICT=INIT_DICT)\n",
        "auto.optimize(n_auto=10, top_k=2, model_train_window=2, device=torch.device('cpu'))\n",
        "\n",
        "#Print out the optimized sampler.\n",
        "print()\n",
        "print(\"*****************************************************************\")\n",
        "print()\n",
        "print(auto.sampler)\n",
        "print()\n",
        "print(\"*****************************************************************\")\n",
        "print()"
      ],
      "metadata": {
        "id": "7bBSlC_p-gIR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66bb6303-7773-4fce-f4c4-ed4a20b1a8aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:03:57,202] A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************************************************************\n",
            "n_auto: 10, list_n_trials: [8, 4, 2, 1]\n",
            "\n",
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n",
            "A new study created in memory with name: no-name-a25f12df-417c-400c-a585-93a487ffee72\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:04:08,737] Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 0 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'dropout_p': 0.7500000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0583457091809098e-05, 'lr_high': 0.002188443602619709, 'n_epoch': 1, 'wd': 0, 'pct_start': 0.65}. Best is trial 0 with value: 4.934887421262324e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:04:14,348] Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 1, 'preprocess': 0, 'activation': 2, 'start_neurons': 1, 'dropout_p': 0.55, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 14.18901061428435, 'one_cycle': 1, 'n_epoch': 0, 'lr': 0.009988882599542686, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:04:27,458] Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n",
            "Trial 2 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 1, 'lr': 3.2496174514454297e-06, 'wd': 1}. Best is trial 0 with value: 4.934887421262324e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:04:36,796] Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 3 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 2, 'action_func': 0, 'preprocess': 1, 'activation': 0, 'start_neurons': 3, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 0, 'max_norm': 10.534920492325114, 'one_cycle': 0, 'lr_low': 0.00027581626431573105, 'lr_high': 0.0011414330792736754, 'n_epoch': 2, 'wd': 3, 'pct_start': 0.25}. Best is trial 3 with value: 4.9348870344060614e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:04:39,659] Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 4 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 1, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.6070831958129308e-05, 'lr_high': 0.0030659910568462, 'n_epoch': 1, 'wd': 3, 'pct_start': 0.15000000000000002}. Best is trial 3 with value: 4.9348870344060614e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:04:42,131] Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n",
            "Trial 5 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 1, 'action_func': 1, 'preprocess': 1, 'activation': 2, 'start_neurons': 5, 'dropout_p': 0.6000000000000001, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 0, 'lr_low': 1.0754634610046388e-07, 'lr_high': 0.06892607849612234, 'n_epoch': 0, 'wd': 1, 'pct_start': 0.2}. Best is trial 3 with value: 4.9348870344060614e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:05:01,037] Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 6 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 1, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:05:03,774] Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Trial 7 finished with value: 4.934886647549799e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'preprocess': 1, 'activation': 2, 'start_neurons': 0, 'loss_func': 0, 'metric': 0, 'freeze': 1, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 4.051312453653896e-05, 'wd': 0}. Best is trial 6 with value: 4.934886647549799e+32.\n",
            "Saved study to: /content/trial_storage/study_0.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2960017588456646567264256.000000</td>\n",
              "      <td>493488819497484819649362955075584.000000</td>\n",
              "      <td>493488819497484819649362955075584.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3086008850480082804801536.000000</td>\n",
              "      <td>493488858183111047317496545673216.000000</td>\n",
              "      <td>493488858183111047317496545673216.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2904739902227142833864704.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2913487982373723437006848.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3023775588813285963595776.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3104027284214830912765952.000000</td>\n",
              "      <td>493488819497484819649362955075584.000000</td>\n",
              "      <td>493488819497484819649362955075584.000000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3037549253798447812706304.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2997691316232308354187264.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>3014136012113268116029440.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2840574920579377220550656.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2993228357087975249543168.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>3016523712549308896116736.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>3000860120987720273100800.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>3021831763156518819594240.000000</td>\n",
              "      <td>493488626069353681308695002087424.000000</td>\n",
              "      <td>493488626069353681308695002087424.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>3156425548986579045842944.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:05:46,944] A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n",
            "A new study created in memory with name: no-name-c9df4e25-760c-40f0-961c-7dc8e37de60f\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:06:10,075] Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.6795856582664895e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:06:29,209] Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n",
            "Trial 1 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.8070347037979564e-05, 'wd': 0}. Best is trial 1 with value: 4.934887421262324e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:06:47,595] Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 2 finished with value: 4.9348858738372745e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:07:06,742] Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Trial 3 finished with value: 4.934887421262324e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.968027896545426e-05, 'wd': 0}. Best is trial 2 with value: 4.9348858738372745e+32.\n",
            "Saved study to: /content/trial_storage/study_1.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2976619946353361315430400.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3015474553980116665368576.000000</td>\n",
              "      <td>493488819497484819649362955075584.000000</td>\n",
              "      <td>493488819497484819649362955075584.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3006278563828996302176256.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2973615432912355872210944.000000</td>\n",
              "      <td>493488819497484819649362955075584.000000</td>\n",
              "      <td>493488819497484819649362955075584.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2782509470151734131163136.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2933293732670988309495808.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3086831171743243638407168.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2839133768698618661830656.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2934072819377726386339840.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2973268403539469211271168.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>3074449947705270708731904.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>3132290866669891614670848.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2817935000993412566482944.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>3061798940035219776864256.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>3006718979843756117721088.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:07:28,073] A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n",
            "A new study created in memory with name: no-name-5a738547-ca08-4312-a918-888199864d26\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:07:47,441] Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.7901822897215425e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:08:07,286] Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Trial 1 finished with value: 4.9348870344060614e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 1 with value: 4.9348870344060614e+32.\n",
            "Saved study to: /content/trial_storage/study_2.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2866628640740482748514304.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2892611744459431107100672.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2942417088767318441328640.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3043312131939225137315840.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>3099556831080717863616512.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2868498102960202750885888.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3078147655200921018695680.000000</td>\n",
              "      <td>493488819497484819649362955075584.000000</td>\n",
              "      <td>493488819497484819649362955075584.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2934772930961398894166016.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>3041074887759535550758912.000000</td>\n",
              "      <td>493488626069353681308695002087424.000000</td>\n",
              "      <td>493488626069353681308695002087424.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2989636718370748769501184.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2804080055042175934660608.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>2799126239567256464916480.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2946379391748276022673408.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>2923552987108941211107328.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2834293804222279118225408.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:08:29,966] A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*****************RUNNING: HPO PROCESS*****************\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n",
            "A new study created in memory with name: no-name-8ecc39d5-d7ba-4787-957e-bb1e271894e4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-19 23:08:48,182] Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Trial 0 finished with value: 4.934887808118586e+32 and parameters: {'dls_func': 0, 'batch_size': 0, 'action_func': 0, 'loss_func': 0, 'metric': 0, 'gradient_clip': 1, 'one_cycle': 1, 'n_epoch': 2, 'lr': 3.791527600358147e-05, 'wd': 0}. Best is trial 0 with value: 4.934887808118586e+32.\n",
            "Saved study to: /content/trial_storage/study_3.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>custom_mse</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>2939227819655199750881280.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2944857247131818832953344.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2959032993491712319946752.000000</td>\n",
              "      <td>493488626069353681308695002087424.000000</td>\n",
              "      <td>493488626069353681308695002087424.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3136981527811384571592704.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2736400392187616348340224.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>493488780811858591981229364477952.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2980407869956747111170048.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3130903613869473426046976.000000</td>\n",
              "      <td>493488858183111047317496545673216.000000</td>\n",
              "      <td>493488858183111047317496545673216.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3001068223319301808979968.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>3013684643344214535438336.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>2851737218356604561260544.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>2928459821032547951837184.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>493488664754979908976828592685056.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>3051847209837829625479168.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>2992321584324601964396544.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>3137610158261771454906368.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>493488742126232364313095773880320.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>2966248552728294271746048.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>493488703440606136644962183282688.000000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "*****************************************************************\n",
            "\n",
            "Sampler:\n",
            "**********ActionSampler**********\n",
            "Action of func: action_default\n",
            "Signature Vars:\n",
            "Var of type: preprocess\n",
            "Configuration Space:\n",
            "'choices' = [False]\n",
            " Var of type: activation\n",
            "Configuration Space:\n",
            "'choices' = [<class 'torch.nn.modules.activation.PReLU'>, <class 'torch.nn.modules.activation.SiLU'>]\n",
            " Var of type: start_neurons\n",
            "Configuration Space:\n",
            "'choices' = [1]\n",
            "\n",
            "Model loader parameters: preprocess=False activation=<class 'torch.nn.modules.activation.PReLU'> start_neurons=1\n",
            "\n",
            "Action of func: action_dropout\n",
            "Signature Vars:\n",
            "Var of type: preprocess\n",
            "Configuration Space:\n",
            "'choices' = [True, False]\n",
            " Var of type: activation\n",
            "Configuration Space:\n",
            "'choices' = [<class 'torch.nn.modules.activation.ReLU'>, <class 'torch.nn.modules.activation.PReLU'>, <class 'torch.nn.modules.activation.SiLU'>]\n",
            " Var of type: start_neurons\n",
            "Configuration Space:\n",
            "'choices' = [1, 2, 4, 8, 16, 32]\n",
            " Var of type: dropout_p\n",
            "Configuration Space:\n",
            "'low': 0.05, 'high': 0.95, 'log': False, 'step': 0.05\n",
            "\n",
            "Model loader parameters: preprocess=False activation=<class 'torch.nn.modules.activation.SiLU'> start_neurons=32 dropout_p=0.6000000000000001\n",
            "\n",
            "\n",
            "**********TrainSampler**********\n",
            "Var of type: action_func\n",
            "Configuration Space:\n",
            "'choices' = [<function action_default at 0x7d763f79f910>]\n",
            "\n",
            "Var of type: max_norm\n",
            "Configuration Space:\n",
            "'low': 0.0, 'high': 15.0, 'log': False, 'step': unspecified\n",
            "\n",
            "Var of type: gradient_clip\n",
            "Configuration Space:\n",
            "'choices' = [False]\n",
            "\n",
            "Var of type: lr\n",
            "Configuration Space:\n",
            "'low': 3.791527600358147e-05, 'high': 3.791527600358147e-05, 'log': True, 'step': unspecified\n",
            "\n",
            "Var of type: n_epoch\n",
            "Configuration Space:\n",
            "'choices' = [15]\n",
            "\n",
            "Var of type: lr_low\n",
            "Configuration Space:\n",
            "'low': 1e-07, 'high': 0.0009, 'log': True, 'step': unspecified\n",
            "\n",
            "Var of type: batch_size\n",
            "Configuration Space:\n",
            "'choices' = [32]\n",
            "\n",
            "Var of type: one_cycle\n",
            "Configuration Space:\n",
            "'choices' = [False]\n",
            "\n",
            "Var of type: pct_start\n",
            "Configuration Space:\n",
            "'low': 0.1, 'high': 0.95, 'log': False, 'step': 0.05\n",
            "\n",
            "Var of type: freeze\n",
            "Configuration Space:\n",
            "'choices' = [True, False]\n",
            "\n",
            "Var of type: dls_func\n",
            "Configuration Space:\n",
            "'choices' = [<function get_dls at 0x7d754f1bf7f0>]\n",
            "\n",
            "Var of type: loss_func\n",
            "Configuration Space:\n",
            "'choices' = [<function custom_mse at 0x7d7550c552d0>]\n",
            "\n",
            "Var of type: wd\n",
            "Configuration Space:\n",
            "'choices' = [0.0001]\n",
            "\n",
            "Var of type: lr_high\n",
            "Configuration Space:\n",
            "'low': 0.0009, 'high': 0.1, 'log': True, 'step': unspecified\n",
            "\n",
            "Var of type: metric\n",
            "Configuration Space:\n",
            "'choices' = [<function custom_mse at 0x7d7550c552d0>]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "*****************************************************************\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST: Optuna's visualization capabilities\n",
        "print(auto.num_study())\n",
        "study = auto.get_study(2)\n",
        "#One can now perform all the optuna visualizations as one sees fit\n",
        "optuna.visualization.plot_optimization_history(study)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "gZLyxLg6cSLk",
        "outputId": "7ad9d5d0-07da-4bd7-8922-c9824c24ea72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "Loaded study from: /content/trial_storage/study_2.pkl\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"f5f521b8-1574-4981-a1fe-a59de7edf50b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f5f521b8-1574-4981-a1fe-a59de7edf50b\")) {                    Plotly.newPlot(                        \"f5f521b8-1574-4981-a1fe-a59de7edf50b\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1],\"y\":[4.934887808118586e+32,4.9348870344060614e+32],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Best Value\",\"x\":[0,1],\"y\":[4.934887808118586e+32,4.9348870344060614e+32],\"type\":\"scatter\"},{\"marker\":{\"color\":\"#cccccc\"},\"mode\":\"markers\",\"name\":\"Infeasible Trial\",\"showlegend\":false,\"x\":[],\"y\":[],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"Trial\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f5f521b8-1574-4981-a1fe-a59de7edf50b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pR8T-aQygQ0l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}